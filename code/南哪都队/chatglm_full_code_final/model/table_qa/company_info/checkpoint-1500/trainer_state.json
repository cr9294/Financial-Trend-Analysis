{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.617977528089888,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 0.009973333333333332,
      "loss": 1.178,
      "step": 4
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.009946666666666668,
      "loss": 0.6116,
      "step": 8
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00992,
      "loss": 0.4402,
      "step": 12
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.009893333333333334,
      "loss": 0.3568,
      "step": 16
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.009866666666666668,
      "loss": 0.3357,
      "step": 20
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00984,
      "loss": 0.2936,
      "step": 24
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.009813333333333334,
      "loss": 0.2368,
      "step": 28
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.009786666666666667,
      "loss": 0.1735,
      "step": 32
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00976,
      "loss": 0.1891,
      "step": 36
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.009733333333333333,
      "loss": 0.1474,
      "step": 40
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.009706666666666667,
      "loss": 0.1632,
      "step": 44
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00968,
      "loss": 0.119,
      "step": 48
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.009653333333333333,
      "loss": 0.0807,
      "step": 52
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.009626666666666667,
      "loss": 0.0628,
      "step": 56
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0096,
      "loss": 0.0566,
      "step": 60
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.009573333333333335,
      "loss": 0.0714,
      "step": 64
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.009546666666666667,
      "loss": 0.0834,
      "step": 68
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.009519999999999999,
      "loss": 0.0602,
      "step": 72
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.009493333333333335,
      "loss": 0.0676,
      "step": 76
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.009466666666666667,
      "loss": 0.0597,
      "step": 80
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00944,
      "loss": 0.053,
      "step": 84
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.009413333333333334,
      "loss": 0.0308,
      "step": 88
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.009386666666666666,
      "loss": 0.0293,
      "step": 92
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00936,
      "loss": 0.0496,
      "step": 96
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.009333333333333334,
      "loss": 0.0488,
      "step": 100
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.009306666666666666,
      "loss": 0.0374,
      "step": 104
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00928,
      "loss": 0.0336,
      "step": 108
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.009253333333333334,
      "loss": 0.0437,
      "step": 112
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.009226666666666666,
      "loss": 0.053,
      "step": 116
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0092,
      "loss": 0.0396,
      "step": 120
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.009173333333333334,
      "loss": 0.0535,
      "step": 124
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.009146666666666666,
      "loss": 0.0299,
      "step": 128
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.009120000000000001,
      "loss": 0.0574,
      "step": 132
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.009093333333333333,
      "loss": 0.038,
      "step": 136
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.009066666666666666,
      "loss": 0.0191,
      "step": 140
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.009040000000000001,
      "loss": 0.0305,
      "step": 144
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.009013333333333333,
      "loss": 0.0229,
      "step": 148
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.008986666666666667,
      "loss": 0.0252,
      "step": 152
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.008960000000000001,
      "loss": 0.0191,
      "step": 156
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.008933333333333333,
      "loss": 0.0289,
      "step": 160
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.008906666666666667,
      "loss": 0.0257,
      "step": 164
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00888,
      "loss": 0.0351,
      "step": 168
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.008853333333333333,
      "loss": 0.0271,
      "step": 172
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.008826666666666667,
      "loss": 0.0332,
      "step": 176
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0088,
      "loss": 0.0266,
      "step": 180
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.008773333333333333,
      "loss": 0.0336,
      "step": 184
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.008746666666666666,
      "loss": 0.0221,
      "step": 188
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00872,
      "loss": 0.0102,
      "step": 192
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.008693333333333332,
      "loss": 0.0264,
      "step": 196
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.008666666666666668,
      "loss": 0.0328,
      "step": 200
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00864,
      "loss": 0.0382,
      "step": 204
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.008613333333333332,
      "loss": 0.0251,
      "step": 208
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.008586666666666668,
      "loss": 0.0214,
      "step": 212
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00856,
      "loss": 0.0183,
      "step": 216
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.008533333333333334,
      "loss": 0.021,
      "step": 220
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.008506666666666668,
      "loss": 0.018,
      "step": 224
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00848,
      "loss": 0.0164,
      "step": 228
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.008453333333333334,
      "loss": 0.0194,
      "step": 232
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.008426666666666667,
      "loss": 0.0107,
      "step": 236
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0084,
      "loss": 0.0176,
      "step": 240
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.008373333333333333,
      "loss": 0.0182,
      "step": 244
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.008346666666666667,
      "loss": 0.0361,
      "step": 248
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00832,
      "loss": 0.0132,
      "step": 252
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.008293333333333333,
      "loss": 0.0126,
      "step": 256
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.008266666666666667,
      "loss": 0.0164,
      "step": 260
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.008239999999999999,
      "loss": 0.0107,
      "step": 264
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.008213333333333333,
      "loss": 0.0161,
      "step": 268
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.008186666666666667,
      "loss": 0.0138,
      "step": 272
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.008159999999999999,
      "loss": 0.0104,
      "step": 276
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.008133333333333334,
      "loss": 0.0237,
      "step": 280
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.008106666666666667,
      "loss": 0.0215,
      "step": 284
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00808,
      "loss": 0.0183,
      "step": 288
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.008053333333333334,
      "loss": 0.0206,
      "step": 292
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.008026666666666666,
      "loss": 0.0113,
      "step": 296
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.008,
      "loss": 0.012,
      "step": 300
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.007973333333333334,
      "loss": 0.0206,
      "step": 304
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.007946666666666666,
      "loss": 0.0165,
      "step": 308
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00792,
      "loss": 0.0123,
      "step": 312
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.007893333333333334,
      "loss": 0.0116,
      "step": 316
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.007866666666666666,
      "loss": 0.0136,
      "step": 320
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00784,
      "loss": 0.0103,
      "step": 324
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.007813333333333334,
      "loss": 0.0201,
      "step": 328
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0077866666666666666,
      "loss": 0.0082,
      "step": 332
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00776,
      "loss": 0.0162,
      "step": 336
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.007733333333333333,
      "loss": 0.0195,
      "step": 340
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.007706666666666667,
      "loss": 0.0072,
      "step": 344
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00768,
      "loss": 0.0089,
      "step": 348
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.007653333333333333,
      "loss": 0.0085,
      "step": 352
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.007626666666666667,
      "loss": 0.0104,
      "step": 356
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0076,
      "loss": 0.007,
      "step": 360
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.007573333333333333,
      "loss": 0.0062,
      "step": 364
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.007546666666666668,
      "loss": 0.0133,
      "step": 368
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00752,
      "loss": 0.0159,
      "step": 372
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.007493333333333333,
      "loss": 0.0119,
      "step": 376
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0074666666666666675,
      "loss": 0.0101,
      "step": 380
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00744,
      "loss": 0.011,
      "step": 384
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.007413333333333333,
      "loss": 0.0075,
      "step": 388
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.007386666666666667,
      "loss": 0.0093,
      "step": 392
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00736,
      "loss": 0.0123,
      "step": 396
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.007333333333333333,
      "loss": 0.0067,
      "step": 400
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.007306666666666667,
      "loss": 0.0137,
      "step": 404
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00728,
      "loss": 0.0122,
      "step": 408
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.007253333333333334,
      "loss": 0.0065,
      "step": 412
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.007226666666666667,
      "loss": 0.0142,
      "step": 416
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0072,
      "loss": 0.0121,
      "step": 420
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.007173333333333334,
      "loss": 0.0124,
      "step": 424
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.007146666666666667,
      "loss": 0.0118,
      "step": 428
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00712,
      "loss": 0.0149,
      "step": 432
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0070933333333333334,
      "loss": 0.0103,
      "step": 436
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.007066666666666666,
      "loss": 0.0118,
      "step": 440
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.007039999999999999,
      "loss": 0.0109,
      "step": 444
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.007013333333333334,
      "loss": 0.0106,
      "step": 448
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.006986666666666667,
      "loss": 0.0131,
      "step": 452
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00696,
      "loss": 0.011,
      "step": 456
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.006933333333333334,
      "loss": 0.0245,
      "step": 460
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.006906666666666667,
      "loss": 0.0112,
      "step": 464
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00688,
      "loss": 0.0176,
      "step": 468
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.006853333333333334,
      "loss": 0.0104,
      "step": 472
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.006826666666666667,
      "loss": 0.0075,
      "step": 476
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0068000000000000005,
      "loss": 0.0097,
      "step": 480
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0067733333333333335,
      "loss": 0.0083,
      "step": 484
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0067466666666666664,
      "loss": 0.0162,
      "step": 488
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00672,
      "loss": 0.0142,
      "step": 492
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.006693333333333333,
      "loss": 0.0179,
      "step": 496
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.006666666666666666,
      "loss": 0.0113,
      "step": 500
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00664,
      "loss": 0.0102,
      "step": 504
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.006613333333333333,
      "loss": 0.017,
      "step": 508
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.006586666666666666,
      "loss": 0.0092,
      "step": 512
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.006560000000000001,
      "loss": 0.0211,
      "step": 516
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.006533333333333334,
      "loss": 0.0133,
      "step": 520
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.006506666666666667,
      "loss": 0.0075,
      "step": 524
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0064800000000000005,
      "loss": 0.007,
      "step": 528
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0064533333333333335,
      "loss": 0.0088,
      "step": 532
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.006426666666666667,
      "loss": 0.0085,
      "step": 536
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0064,
      "loss": 0.0081,
      "step": 540
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.006373333333333333,
      "loss": 0.0081,
      "step": 544
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.006346666666666667,
      "loss": 0.0054,
      "step": 548
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00632,
      "loss": 0.0057,
      "step": 552
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.006293333333333333,
      "loss": 0.0043,
      "step": 556
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.006266666666666667,
      "loss": 0.0053,
      "step": 560
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00624,
      "loss": 0.0047,
      "step": 564
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.006213333333333333,
      "loss": 0.0079,
      "step": 568
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.006186666666666667,
      "loss": 0.0119,
      "step": 572
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00616,
      "loss": 0.0057,
      "step": 576
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.006133333333333333,
      "loss": 0.006,
      "step": 580
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.006106666666666667,
      "loss": 0.0047,
      "step": 584
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00608,
      "loss": 0.0052,
      "step": 588
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.006053333333333333,
      "loss": 0.0065,
      "step": 592
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.006026666666666667,
      "loss": 0.0087,
      "step": 596
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.006,
      "loss": 0.0091,
      "step": 600
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.005973333333333334,
      "loss": 0.0094,
      "step": 604
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.005946666666666667,
      "loss": 0.0087,
      "step": 608
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00592,
      "loss": 0.0053,
      "step": 612
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.005893333333333334,
      "loss": 0.0123,
      "step": 616
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.005866666666666667,
      "loss": 0.0092,
      "step": 620
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00584,
      "loss": 0.0067,
      "step": 624
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0058133333333333335,
      "loss": 0.0056,
      "step": 628
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0057866666666666665,
      "loss": 0.012,
      "step": 632
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0057599999999999995,
      "loss": 0.009,
      "step": 636
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.005733333333333333,
      "loss": 0.0047,
      "step": 640
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.005706666666666666,
      "loss": 0.0062,
      "step": 644
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.005679999999999999,
      "loss": 0.0067,
      "step": 648
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.005653333333333334,
      "loss": 0.0076,
      "step": 652
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.005626666666666667,
      "loss": 0.0065,
      "step": 656
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.005600000000000001,
      "loss": 0.0067,
      "step": 660
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.005573333333333334,
      "loss": 0.0042,
      "step": 664
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.005546666666666667,
      "loss": 0.0064,
      "step": 668
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.005520000000000001,
      "loss": 0.0067,
      "step": 672
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.005493333333333334,
      "loss": 0.0074,
      "step": 676
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0054666666666666665,
      "loss": 0.0047,
      "step": 680
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00544,
      "loss": 0.0046,
      "step": 684
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.005413333333333333,
      "loss": 0.0045,
      "step": 688
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.005386666666666666,
      "loss": 0.0158,
      "step": 692
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00536,
      "loss": 0.0083,
      "step": 696
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.005333333333333333,
      "loss": 0.0069,
      "step": 700
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.005306666666666666,
      "loss": 0.0122,
      "step": 704
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00528,
      "loss": 0.0064,
      "step": 708
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.005253333333333333,
      "loss": 0.0089,
      "step": 712
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.005226666666666666,
      "loss": 0.0072,
      "step": 716
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.005200000000000001,
      "loss": 0.0153,
      "step": 720
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.005173333333333334,
      "loss": 0.0105,
      "step": 724
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0051466666666666674,
      "loss": 0.006,
      "step": 728
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00512,
      "loss": 0.0047,
      "step": 732
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.005093333333333333,
      "loss": 0.0057,
      "step": 736
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.005066666666666667,
      "loss": 0.0053,
      "step": 740
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00504,
      "loss": 0.0045,
      "step": 744
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.005013333333333333,
      "loss": 0.0044,
      "step": 748
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.004986666666666666,
      "loss": 0.0045,
      "step": 752
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00496,
      "loss": 0.0052,
      "step": 756
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.004933333333333334,
      "loss": 0.0126,
      "step": 760
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.004906666666666667,
      "loss": 0.0079,
      "step": 764
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00488,
      "loss": 0.0058,
      "step": 768
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.004853333333333334,
      "loss": 0.0149,
      "step": 772
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.004826666666666667,
      "loss": 0.0051,
      "step": 776
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0048,
      "loss": 0.006,
      "step": 780
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.004773333333333333,
      "loss": 0.0059,
      "step": 784
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.004746666666666667,
      "loss": 0.0065,
      "step": 788
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00472,
      "loss": 0.0046,
      "step": 792
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.004693333333333333,
      "loss": 0.0034,
      "step": 796
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.004666666666666667,
      "loss": 0.0071,
      "step": 800
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00464,
      "loss": 0.0044,
      "step": 804
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.004613333333333333,
      "loss": 0.005,
      "step": 808
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.004586666666666667,
      "loss": 0.0054,
      "step": 812
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.004560000000000001,
      "loss": 0.0054,
      "step": 816
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.004533333333333333,
      "loss": 0.0053,
      "step": 820
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.004506666666666667,
      "loss": 0.0031,
      "step": 824
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0044800000000000005,
      "loss": 0.0042,
      "step": 828
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0044533333333333334,
      "loss": 0.0044,
      "step": 832
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.004426666666666666,
      "loss": 0.0054,
      "step": 836
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0044,
      "loss": 0.0036,
      "step": 840
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.004373333333333333,
      "loss": 0.0051,
      "step": 844
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.004346666666666666,
      "loss": 0.0046,
      "step": 848
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00432,
      "loss": 0.0105,
      "step": 852
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.004293333333333334,
      "loss": 0.0036,
      "step": 856
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.004266666666666667,
      "loss": 0.0061,
      "step": 860
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00424,
      "loss": 0.0082,
      "step": 864
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.004213333333333334,
      "loss": 0.0059,
      "step": 868
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.004186666666666667,
      "loss": 0.0052,
      "step": 872
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00416,
      "loss": 0.0119,
      "step": 876
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0041333333333333335,
      "loss": 0.0045,
      "step": 880
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0041066666666666665,
      "loss": 0.0071,
      "step": 884
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.004079999999999999,
      "loss": 0.0047,
      "step": 888
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.004053333333333333,
      "loss": 0.0021,
      "step": 892
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.004026666666666667,
      "loss": 0.0042,
      "step": 896
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.004,
      "loss": 0.0048,
      "step": 900
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.003973333333333333,
      "loss": 0.0052,
      "step": 904
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.003946666666666667,
      "loss": 0.0086,
      "step": 908
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00392,
      "loss": 0.0062,
      "step": 912
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0038933333333333333,
      "loss": 0.0042,
      "step": 916
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.0038666666666666667,
      "loss": 0.0059,
      "step": 920
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00384,
      "loss": 0.0052,
      "step": 924
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0038133333333333335,
      "loss": 0.0042,
      "step": 928
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0037866666666666665,
      "loss": 0.0063,
      "step": 932
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00376,
      "loss": 0.0044,
      "step": 936
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0037333333333333337,
      "loss": 0.0061,
      "step": 940
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0037066666666666667,
      "loss": 0.0057,
      "step": 944
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00368,
      "loss": 0.0047,
      "step": 948
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0036533333333333335,
      "loss": 0.0049,
      "step": 952
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.003626666666666667,
      "loss": 0.0044,
      "step": 956
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0036,
      "loss": 0.0052,
      "step": 960
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0035733333333333333,
      "loss": 0.0057,
      "step": 964
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0035466666666666667,
      "loss": 0.003,
      "step": 968
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0035199999999999997,
      "loss": 0.0038,
      "step": 972
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0034933333333333335,
      "loss": 0.0051,
      "step": 976
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.003466666666666667,
      "loss": 0.0043,
      "step": 980
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00344,
      "loss": 0.0067,
      "step": 984
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0034133333333333333,
      "loss": 0.0036,
      "step": 988
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0033866666666666667,
      "loss": 0.0052,
      "step": 992
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00336,
      "loss": 0.0052,
      "step": 996
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.003333333333333333,
      "loss": 0.0036,
      "step": 1000
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0033066666666666665,
      "loss": 0.0048,
      "step": 1004
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0032800000000000004,
      "loss": 0.0077,
      "step": 1008
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0032533333333333333,
      "loss": 0.0041,
      "step": 1012
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0032266666666666667,
      "loss": 0.0032,
      "step": 1016
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0032,
      "loss": 0.0045,
      "step": 1020
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0031733333333333336,
      "loss": 0.0044,
      "step": 1024
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0031466666666666665,
      "loss": 0.0055,
      "step": 1028
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00312,
      "loss": 0.0053,
      "step": 1032
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0030933333333333334,
      "loss": 0.0025,
      "step": 1036
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.0030666666666666663,
      "loss": 0.0054,
      "step": 1040
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00304,
      "loss": 0.0074,
      "step": 1044
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0030133333333333336,
      "loss": 0.0027,
      "step": 1048
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.002986666666666667,
      "loss": 0.0056,
      "step": 1052
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00296,
      "loss": 0.0043,
      "step": 1056
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0029333333333333334,
      "loss": 0.0049,
      "step": 1060
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.0029066666666666668,
      "loss": 0.0046,
      "step": 1064
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0028799999999999997,
      "loss": 0.0046,
      "step": 1068
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.002853333333333333,
      "loss": 0.0037,
      "step": 1072
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.002826666666666667,
      "loss": 0.0042,
      "step": 1076
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0028000000000000004,
      "loss": 0.0038,
      "step": 1080
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.0027733333333333334,
      "loss": 0.0068,
      "step": 1084
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.002746666666666667,
      "loss": 0.0042,
      "step": 1088
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00272,
      "loss": 0.0036,
      "step": 1092
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.002693333333333333,
      "loss": 0.0062,
      "step": 1096
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.0026666666666666666,
      "loss": 0.0072,
      "step": 1100
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00264,
      "loss": 0.0033,
      "step": 1104
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.002613333333333333,
      "loss": 0.0038,
      "step": 1108
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.002586666666666667,
      "loss": 0.0042,
      "step": 1112
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00256,
      "loss": 0.005,
      "step": 1116
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.0025333333333333336,
      "loss": 0.0053,
      "step": 1120
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0025066666666666666,
      "loss": 0.0034,
      "step": 1124
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00248,
      "loss": 0.0053,
      "step": 1128
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.0024533333333333334,
      "loss": 0.0029,
      "step": 1132
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.002426666666666667,
      "loss": 0.005,
      "step": 1136
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.0024,
      "loss": 0.0035,
      "step": 1140
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.0023733333333333336,
      "loss": 0.0042,
      "step": 1144
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.0023466666666666666,
      "loss": 0.0053,
      "step": 1148
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00232,
      "loss": 0.0038,
      "step": 1152
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.0022933333333333334,
      "loss": 0.0036,
      "step": 1156
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.0022666666666666664,
      "loss": 0.0037,
      "step": 1160
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.0022400000000000002,
      "loss": 0.0035,
      "step": 1164
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.002213333333333333,
      "loss": 0.0038,
      "step": 1168
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.0021866666666666666,
      "loss": 0.0044,
      "step": 1172
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00216,
      "loss": 0.0035,
      "step": 1176
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.0021333333333333334,
      "loss": 0.0067,
      "step": 1180
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.002106666666666667,
      "loss": 0.002,
      "step": 1184
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00208,
      "loss": 0.0026,
      "step": 1188
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.0020533333333333332,
      "loss": 0.0022,
      "step": 1192
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.0020266666666666666,
      "loss": 0.004,
      "step": 1196
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.002,
      "loss": 0.0034,
      "step": 1200
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.0019733333333333334,
      "loss": 0.0029,
      "step": 1204
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.0019466666666666666,
      "loss": 0.0051,
      "step": 1208
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00192,
      "loss": 0.0026,
      "step": 1212
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.0018933333333333332,
      "loss": 0.0049,
      "step": 1216
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.0018666666666666669,
      "loss": 0.0047,
      "step": 1220
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00184,
      "loss": 0.0025,
      "step": 1224
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0018133333333333335,
      "loss": 0.0053,
      "step": 1228
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.0017866666666666667,
      "loss": 0.0051,
      "step": 1232
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.0017599999999999998,
      "loss": 0.0035,
      "step": 1236
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.0017333333333333335,
      "loss": 0.0036,
      "step": 1240
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.0017066666666666667,
      "loss": 0.0022,
      "step": 1244
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00168,
      "loss": 0.0054,
      "step": 1248
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0016533333333333333,
      "loss": 0.0043,
      "step": 1252
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.0016266666666666667,
      "loss": 0.003,
      "step": 1256
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.0016,
      "loss": 0.0034,
      "step": 1260
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.0015733333333333333,
      "loss": 0.0045,
      "step": 1264
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.0015466666666666667,
      "loss": 0.0051,
      "step": 1268
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00152,
      "loss": 0.0051,
      "step": 1272
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.0014933333333333335,
      "loss": 0.0051,
      "step": 1276
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.0014666666666666667,
      "loss": 0.0021,
      "step": 1280
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.0014399999999999999,
      "loss": 0.0048,
      "step": 1284
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.0014133333333333335,
      "loss": 0.005,
      "step": 1288
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.0013866666666666667,
      "loss": 0.0025,
      "step": 1292
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00136,
      "loss": 0.0032,
      "step": 1296
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0013333333333333333,
      "loss": 0.0054,
      "step": 1300
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.0013066666666666665,
      "loss": 0.0039,
      "step": 1304
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00128,
      "loss": 0.0045,
      "step": 1308
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.0012533333333333333,
      "loss": 0.0027,
      "step": 1312
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.0012266666666666667,
      "loss": 0.0035,
      "step": 1316
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.0012,
      "loss": 0.0074,
      "step": 1320
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.0011733333333333333,
      "loss": 0.0055,
      "step": 1324
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.0011466666666666667,
      "loss": 0.0082,
      "step": 1328
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.0011200000000000001,
      "loss": 0.0048,
      "step": 1332
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.0010933333333333333,
      "loss": 0.0036,
      "step": 1336
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.0010666666666666667,
      "loss": 0.0037,
      "step": 1340
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00104,
      "loss": 0.0034,
      "step": 1344
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.0010133333333333333,
      "loss": 0.0026,
      "step": 1348
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.0009866666666666667,
      "loss": 0.0049,
      "step": 1352
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00096,
      "loss": 0.0026,
      "step": 1356
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.0009333333333333334,
      "loss": 0.0036,
      "step": 1360
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.0009066666666666667,
      "loss": 0.004,
      "step": 1364
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.0008799999999999999,
      "loss": 0.0026,
      "step": 1368
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.0008533333333333333,
      "loss": 0.0031,
      "step": 1372
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.0008266666666666666,
      "loss": 0.0038,
      "step": 1376
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.0008,
      "loss": 0.0042,
      "step": 1380
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.0007733333333333333,
      "loss": 0.0053,
      "step": 1384
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.0007466666666666667,
      "loss": 0.0048,
      "step": 1388
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.0007199999999999999,
      "loss": 0.0042,
      "step": 1392
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.0006933333333333333,
      "loss": 0.0055,
      "step": 1396
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.0006666666666666666,
      "loss": 0.0027,
      "step": 1400
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.00064,
      "loss": 0.0034,
      "step": 1404
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.0006133333333333334,
      "loss": 0.0036,
      "step": 1408
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.0005866666666666667,
      "loss": 0.0032,
      "step": 1412
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.0005600000000000001,
      "loss": 0.0056,
      "step": 1416
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.0005333333333333334,
      "loss": 0.0031,
      "step": 1420
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0005066666666666667,
      "loss": 0.0047,
      "step": 1424
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.00048,
      "loss": 0.0038,
      "step": 1428
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00045333333333333337,
      "loss": 0.0029,
      "step": 1432
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.00042666666666666667,
      "loss": 0.0032,
      "step": 1436
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.0004,
      "loss": 0.0047,
      "step": 1440
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.0003733333333333334,
      "loss": 0.0029,
      "step": 1444
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.00034666666666666667,
      "loss": 0.0026,
      "step": 1448
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00032,
      "loss": 0.0052,
      "step": 1452
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.0002933333333333333,
      "loss": 0.0033,
      "step": 1456
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.0044,
      "step": 1460
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.00024,
      "loss": 0.0064,
      "step": 1464
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00021333333333333333,
      "loss": 0.0023,
      "step": 1468
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.0001866666666666667,
      "loss": 0.0031,
      "step": 1472
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00016,
      "loss": 0.0029,
      "step": 1476
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.0034,
      "step": 1480
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.0033,
      "step": 1484
    },
    {
      "epoch": 5.57,
      "learning_rate": 8e-05,
      "loss": 0.0036,
      "step": 1488
    },
    {
      "epoch": 5.59,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.0035,
      "step": 1492
    },
    {
      "epoch": 5.6,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0056,
      "step": 1496
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.0,
      "loss": 0.0063,
      "step": 1500
    }
  ],
  "max_steps": 1500,
  "num_train_epochs": 6,
  "total_flos": 1.22050572189696e+18,
  "trial_name": null,
  "trial_params": null
}
