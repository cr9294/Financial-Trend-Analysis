{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.7340067340067336,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 0.009933333333333334,
      "loss": 2.0441,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.009866666666666668,
      "loss": 0.8943,
      "step": 20
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0098,
      "loss": 0.572,
      "step": 30
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.009733333333333333,
      "loss": 0.4341,
      "step": 40
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.009666666666666667,
      "loss": 0.2328,
      "step": 50
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0096,
      "loss": 0.1629,
      "step": 60
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.009533333333333335,
      "loss": 0.1283,
      "step": 70
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.009466666666666667,
      "loss": 0.1022,
      "step": 80
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0094,
      "loss": 0.0694,
      "step": 90
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.009333333333333334,
      "loss": 0.0613,
      "step": 100
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.009266666666666666,
      "loss": 0.0508,
      "step": 110
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0092,
      "loss": 0.0479,
      "step": 120
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.009133333333333334,
      "loss": 0.0388,
      "step": 130
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.009066666666666666,
      "loss": 0.0321,
      "step": 140
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.009000000000000001,
      "loss": 0.0283,
      "step": 150
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.008933333333333333,
      "loss": 0.0331,
      "step": 160
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.008866666666666667,
      "loss": 0.0255,
      "step": 170
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0088,
      "loss": 0.0209,
      "step": 180
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.008733333333333333,
      "loss": 0.0199,
      "step": 190
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.008666666666666668,
      "loss": 0.0225,
      "step": 200
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0086,
      "loss": 0.021,
      "step": 210
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.008533333333333334,
      "loss": 0.0168,
      "step": 220
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.008466666666666667,
      "loss": 0.0169,
      "step": 230
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0084,
      "loss": 0.0173,
      "step": 240
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.008333333333333333,
      "loss": 0.0161,
      "step": 250
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.008266666666666667,
      "loss": 0.0191,
      "step": 260
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.008199999999999999,
      "loss": 0.013,
      "step": 270
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.008133333333333334,
      "loss": 0.0157,
      "step": 280
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.008066666666666666,
      "loss": 0.0154,
      "step": 290
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.008,
      "loss": 0.0105,
      "step": 300
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.007933333333333334,
      "loss": 0.0144,
      "step": 310
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.007866666666666666,
      "loss": 0.0111,
      "step": 320
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0078000000000000005,
      "loss": 0.0148,
      "step": 330
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.007733333333333333,
      "loss": 0.011,
      "step": 340
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.007666666666666667,
      "loss": 0.0137,
      "step": 350
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0076,
      "loss": 0.0102,
      "step": 360
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.007533333333333333,
      "loss": 0.0101,
      "step": 370
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0074666666666666675,
      "loss": 0.0098,
      "step": 380
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0074,
      "loss": 0.0106,
      "step": 390
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.007333333333333333,
      "loss": 0.0086,
      "step": 400
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.007266666666666667,
      "loss": 0.0089,
      "step": 410
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0072,
      "loss": 0.0092,
      "step": 420
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0071333333333333335,
      "loss": 0.01,
      "step": 430
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.007066666666666666,
      "loss": 0.0086,
      "step": 440
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.006999999999999999,
      "loss": 0.0092,
      "step": 450
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.006933333333333334,
      "loss": 0.0119,
      "step": 460
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.006866666666666667,
      "loss": 0.0064,
      "step": 470
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0068000000000000005,
      "loss": 0.0098,
      "step": 480
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.006733333333333333,
      "loss": 0.0087,
      "step": 490
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.006666666666666666,
      "loss": 0.0085,
      "step": 500
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.006600000000000001,
      "loss": 0.0063,
      "step": 510
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.006533333333333334,
      "loss": 0.0072,
      "step": 520
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.006466666666666667,
      "loss": 0.0074,
      "step": 530
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0064,
      "loss": 0.0081,
      "step": 540
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.006333333333333333,
      "loss": 0.0064,
      "step": 550
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.006266666666666667,
      "loss": 0.0052,
      "step": 560
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0062,
      "loss": 0.0071,
      "step": 570
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.006133333333333333,
      "loss": 0.006,
      "step": 580
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.006066666666666667,
      "loss": 0.0079,
      "step": 590
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.006,
      "loss": 0.0056,
      "step": 600
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.005933333333333334,
      "loss": 0.0088,
      "step": 610
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.005866666666666667,
      "loss": 0.0094,
      "step": 620
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0058,
      "loss": 0.0076,
      "step": 630
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.005733333333333333,
      "loss": 0.0069,
      "step": 640
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.005666666666666666,
      "loss": 0.0055,
      "step": 650
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.005600000000000001,
      "loss": 0.0063,
      "step": 660
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.005533333333333334,
      "loss": 0.0059,
      "step": 670
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0054666666666666665,
      "loss": 0.0055,
      "step": 680
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0054,
      "loss": 0.0055,
      "step": 690
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.005333333333333333,
      "loss": 0.0063,
      "step": 700
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.005266666666666666,
      "loss": 0.0075,
      "step": 710
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.005200000000000001,
      "loss": 0.0055,
      "step": 720
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0051333333333333335,
      "loss": 0.0055,
      "step": 730
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.005066666666666667,
      "loss": 0.0054,
      "step": 740
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.005,
      "loss": 0.0076,
      "step": 750
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.004933333333333334,
      "loss": 0.0055,
      "step": 760
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.004866666666666667,
      "loss": 0.0039,
      "step": 770
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0048,
      "loss": 0.0059,
      "step": 780
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.004733333333333333,
      "loss": 0.0049,
      "step": 790
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.004666666666666667,
      "loss": 0.0057,
      "step": 800
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0046,
      "loss": 0.0053,
      "step": 810
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.004533333333333333,
      "loss": 0.0059,
      "step": 820
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0044666666666666665,
      "loss": 0.0064,
      "step": 830
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0044,
      "loss": 0.0071,
      "step": 840
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.004333333333333334,
      "loss": 0.005,
      "step": 850
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.004266666666666667,
      "loss": 0.0039,
      "step": 860
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0042,
      "loss": 0.0046,
      "step": 870
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0041333333333333335,
      "loss": 0.005,
      "step": 880
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.004066666666666667,
      "loss": 0.007,
      "step": 890
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.004,
      "loss": 0.0032,
      "step": 900
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.003933333333333333,
      "loss": 0.0049,
      "step": 910
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0038666666666666667,
      "loss": 0.0046,
      "step": 920
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0038,
      "loss": 0.0048,
      "step": 930
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0037333333333333337,
      "loss": 0.0038,
      "step": 940
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0036666666666666666,
      "loss": 0.0035,
      "step": 950
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0036,
      "loss": 0.0041,
      "step": 960
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.003533333333333333,
      "loss": 0.0038,
      "step": 970
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.003466666666666667,
      "loss": 0.0051,
      "step": 980
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0034000000000000002,
      "loss": 0.0039,
      "step": 990
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.003333333333333333,
      "loss": 0.0041,
      "step": 1000
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.003266666666666667,
      "loss": 0.0046,
      "step": 1010
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0032,
      "loss": 0.0044,
      "step": 1020
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0031333333333333335,
      "loss": 0.004,
      "step": 1030
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0030666666666666663,
      "loss": 0.0037,
      "step": 1040
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.003,
      "loss": 0.0048,
      "step": 1050
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0029333333333333334,
      "loss": 0.0026,
      "step": 1060
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0028666666666666667,
      "loss": 0.0041,
      "step": 1070
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0028000000000000004,
      "loss": 0.0033,
      "step": 1080
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0027333333333333333,
      "loss": 0.0038,
      "step": 1090
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0026666666666666666,
      "loss": 0.0036,
      "step": 1100
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0026000000000000003,
      "loss": 0.0029,
      "step": 1110
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0025333333333333336,
      "loss": 0.0038,
      "step": 1120
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.002466666666666667,
      "loss": 0.0032,
      "step": 1130
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0024,
      "loss": 0.005,
      "step": 1140
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0023333333333333335,
      "loss": 0.0029,
      "step": 1150
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0022666666666666664,
      "loss": 0.0031,
      "step": 1160
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0022,
      "loss": 0.0036,
      "step": 1170
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0021333333333333334,
      "loss": 0.0038,
      "step": 1180
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0020666666666666667,
      "loss": 0.0035,
      "step": 1190
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.002,
      "loss": 0.0042,
      "step": 1200
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0019333333333333333,
      "loss": 0.0039,
      "step": 1210
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0018666666666666669,
      "loss": 0.0053,
      "step": 1220
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0018,
      "loss": 0.0044,
      "step": 1230
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0017333333333333335,
      "loss": 0.0043,
      "step": 1240
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0016666666666666666,
      "loss": 0.0032,
      "step": 1250
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0016,
      "loss": 0.0034,
      "step": 1260
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0015333333333333332,
      "loss": 0.0031,
      "step": 1270
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0014666666666666667,
      "loss": 0.0045,
      "step": 1280
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0014000000000000002,
      "loss": 0.0022,
      "step": 1290
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0013333333333333333,
      "loss": 0.0031,
      "step": 1300
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0012666666666666668,
      "loss": 0.0044,
      "step": 1310
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0012,
      "loss": 0.0048,
      "step": 1320
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0011333333333333332,
      "loss": 0.0035,
      "step": 1330
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0010666666666666667,
      "loss": 0.0037,
      "step": 1340
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.001,
      "loss": 0.0039,
      "step": 1350
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009333333333333334,
      "loss": 0.0033,
      "step": 1360
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0008666666666666667,
      "loss": 0.0043,
      "step": 1370
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0008,
      "loss": 0.0028,
      "step": 1380
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0007333333333333333,
      "loss": 0.0033,
      "step": 1390
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0006666666666666666,
      "loss": 0.0034,
      "step": 1400
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0006,
      "loss": 0.0041,
      "step": 1410
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0005333333333333334,
      "loss": 0.0034,
      "step": 1420
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0004666666666666667,
      "loss": 0.0032,
      "step": 1430
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0004,
      "loss": 0.0035,
      "step": 1440
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0026,
      "step": 1450
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.0042,
      "step": 1460
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0002,
      "loss": 0.0034,
      "step": 1470
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.0035,
      "step": 1480
    },
    {
      "epoch": 1.67,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0035,
      "step": 1490
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0,
      "loss": 0.0031,
      "step": 1500
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.006644444444444444,
      "loss": 0.2021,
      "step": 1510
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.006622222222222223,
      "loss": 0.0312,
      "step": 1520
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.006600000000000001,
      "loss": 0.0156,
      "step": 1530
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.006577777777777778,
      "loss": 0.0108,
      "step": 1540
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.006555555555555556,
      "loss": 0.0093,
      "step": 1550
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.006533333333333334,
      "loss": 0.0064,
      "step": 1560
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.006511111111111111,
      "loss": 0.0057,
      "step": 1570
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.006488888888888889,
      "loss": 0.0055,
      "step": 1580
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.006466666666666667,
      "loss": 0.0052,
      "step": 1590
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.006444444444444445,
      "loss": 0.0051,
      "step": 1600
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.006422222222222222,
      "loss": 0.0055,
      "step": 1610
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0064,
      "loss": 0.0044,
      "step": 1620
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.006377777777777778,
      "loss": 0.005,
      "step": 1630
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.006355555555555555,
      "loss": 0.0044,
      "step": 1640
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.006333333333333333,
      "loss": 0.0041,
      "step": 1650
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.006311111111111111,
      "loss": 0.0054,
      "step": 1660
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00628888888888889,
      "loss": 0.0041,
      "step": 1670
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.006266666666666667,
      "loss": 0.0035,
      "step": 1680
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.006244444444444445,
      "loss": 0.0045,
      "step": 1690
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.006222222222222223,
      "loss": 0.004,
      "step": 1700
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0062,
      "loss": 0.0037,
      "step": 1710
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.006177777777777778,
      "loss": 0.0036,
      "step": 1720
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.006155555555555556,
      "loss": 0.0058,
      "step": 1730
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.006133333333333333,
      "loss": 0.0037,
      "step": 1740
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.006111111111111111,
      "loss": 0.004,
      "step": 1750
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.006088888888888889,
      "loss": 0.0036,
      "step": 1760
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.006066666666666667,
      "loss": 0.0039,
      "step": 1770
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.006044444444444444,
      "loss": 0.0031,
      "step": 1780
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.006022222222222222,
      "loss": 0.0034,
      "step": 1790
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.006,
      "loss": 0.0026,
      "step": 1800
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.005977777777777777,
      "loss": 0.0035,
      "step": 1810
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.005955555555555555,
      "loss": 0.004,
      "step": 1820
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.005933333333333334,
      "loss": 0.0034,
      "step": 1830
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.005911111111111112,
      "loss": 0.0041,
      "step": 1840
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.005888888888888889,
      "loss": 0.0029,
      "step": 1850
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.005866666666666667,
      "loss": 0.003,
      "step": 1860
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.005844444444444445,
      "loss": 0.0038,
      "step": 1870
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.005822222222222222,
      "loss": 0.0037,
      "step": 1880
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0058,
      "loss": 0.0028,
      "step": 1890
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0057777777777777775,
      "loss": 0.0037,
      "step": 1900
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.005755555555555556,
      "loss": 0.0036,
      "step": 1910
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.005733333333333333,
      "loss": 0.003,
      "step": 1920
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.005711111111111111,
      "loss": 0.0032,
      "step": 1930
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.005688888888888889,
      "loss": 0.0042,
      "step": 1940
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.005666666666666666,
      "loss": 0.0039,
      "step": 1950
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.005644444444444444,
      "loss": 0.0035,
      "step": 1960
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.005622222222222222,
      "loss": 0.0039,
      "step": 1970
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.005600000000000001,
      "loss": 0.003,
      "step": 1980
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.005577777777777778,
      "loss": 0.0035,
      "step": 1990
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.005555555555555556,
      "loss": 0.0033,
      "step": 2000
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.005533333333333334,
      "loss": 0.0038,
      "step": 2010
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.005511111111111112,
      "loss": 0.0031,
      "step": 2020
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.005488888888888889,
      "loss": 0.0037,
      "step": 2030
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0054666666666666665,
      "loss": 0.003,
      "step": 2040
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0054444444444444445,
      "loss": 0.0035,
      "step": 2050
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.005422222222222223,
      "loss": 0.0032,
      "step": 2060
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0054,
      "loss": 0.0038,
      "step": 2070
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.005377777777777778,
      "loss": 0.0036,
      "step": 2080
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.005355555555555556,
      "loss": 0.0036,
      "step": 2090
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.005333333333333333,
      "loss": 0.003,
      "step": 2100
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.005311111111111111,
      "loss": 0.0036,
      "step": 2110
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.005288888888888889,
      "loss": 0.003,
      "step": 2120
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.005266666666666666,
      "loss": 0.0023,
      "step": 2130
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.005244444444444445,
      "loss": 0.0023,
      "step": 2140
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.005222222222222223,
      "loss": 0.0034,
      "step": 2150
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.005200000000000001,
      "loss": 0.0035,
      "step": 2160
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.005177777777777778,
      "loss": 0.0034,
      "step": 2170
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.005155555555555556,
      "loss": 0.0027,
      "step": 2180
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0051333333333333335,
      "loss": 0.0036,
      "step": 2190
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0051111111111111105,
      "loss": 0.0033,
      "step": 2200
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0050888888888888885,
      "loss": 0.0028,
      "step": 2210
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.005066666666666667,
      "loss": 0.0026,
      "step": 2220
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.005044444444444445,
      "loss": 0.0026,
      "step": 2230
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.005022222222222222,
      "loss": 0.0033,
      "step": 2240
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.005,
      "loss": 0.0028,
      "step": 2250
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.004977777777777778,
      "loss": 0.0027,
      "step": 2260
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.004955555555555556,
      "loss": 0.0024,
      "step": 2270
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.004933333333333334,
      "loss": 0.0024,
      "step": 2280
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.004911111111111111,
      "loss": 0.0023,
      "step": 2290
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.004888888888888889,
      "loss": 0.0024,
      "step": 2300
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.004866666666666667,
      "loss": 0.0019,
      "step": 2310
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.004844444444444445,
      "loss": 0.0021,
      "step": 2320
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0048222222222222225,
      "loss": 0.0031,
      "step": 2330
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0048,
      "loss": 0.003,
      "step": 2340
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.004777777777777778,
      "loss": 0.0031,
      "step": 2350
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.004755555555555555,
      "loss": 0.003,
      "step": 2360
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.004733333333333333,
      "loss": 0.0022,
      "step": 2370
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.004711111111111111,
      "loss": 0.004,
      "step": 2380
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.004688888888888889,
      "loss": 0.0035,
      "step": 2390
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.004666666666666667,
      "loss": 0.0033,
      "step": 2400
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.004644444444444444,
      "loss": 0.0025,
      "step": 2410
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.004622222222222222,
      "loss": 0.0033,
      "step": 2420
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0046,
      "loss": 0.0027,
      "step": 2430
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.004577777777777778,
      "loss": 0.0027,
      "step": 2440
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.004555555555555556,
      "loss": 0.0028,
      "step": 2450
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.004533333333333333,
      "loss": 0.0024,
      "step": 2460
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.004511111111111112,
      "loss": 0.0031,
      "step": 2470
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.004488888888888889,
      "loss": 0.003,
      "step": 2480
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0044666666666666665,
      "loss": 0.0035,
      "step": 2490
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0044444444444444444,
      "loss": 0.0045,
      "step": 2500
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.004422222222222222,
      "loss": 0.0033,
      "step": 2510
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0044,
      "loss": 0.0033,
      "step": 2520
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.004377777777777778,
      "loss": 0.0028,
      "step": 2530
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.004355555555555555,
      "loss": 0.0028,
      "step": 2540
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.004333333333333334,
      "loss": 0.0034,
      "step": 2550
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.004311111111111111,
      "loss": 0.003,
      "step": 2560
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.004288888888888889,
      "loss": 0.0029,
      "step": 2570
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.004266666666666667,
      "loss": 0.0035,
      "step": 2580
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.004244444444444445,
      "loss": 0.0025,
      "step": 2590
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.004222222222222223,
      "loss": 0.003,
      "step": 2600
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0042,
      "loss": 0.0022,
      "step": 2610
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0041777777777777785,
      "loss": 0.0031,
      "step": 2620
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0041555555555555556,
      "loss": 0.0025,
      "step": 2630
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0041333333333333335,
      "loss": 0.0026,
      "step": 2640
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.004111111111111111,
      "loss": 0.0025,
      "step": 2650
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.004088888888888889,
      "loss": 0.0023,
      "step": 2660
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.004066666666666667,
      "loss": 0.0037,
      "step": 2670
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.004044444444444444,
      "loss": 0.0036,
      "step": 2680
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.004022222222222222,
      "loss": 0.0022,
      "step": 2690
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.004,
      "loss": 0.0019,
      "step": 2700
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.003977777777777778,
      "loss": 0.0025,
      "step": 2710
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.003955555555555556,
      "loss": 0.0031,
      "step": 2720
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.003933333333333333,
      "loss": 0.0028,
      "step": 2730
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.003911111111111112,
      "loss": 0.0018,
      "step": 2740
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.003888888888888889,
      "loss": 0.0032,
      "step": 2750
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0038666666666666667,
      "loss": 0.0017,
      "step": 2760
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.003844444444444444,
      "loss": 0.002,
      "step": 2770
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0038222222222222225,
      "loss": 0.0025,
      "step": 2780
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0038,
      "loss": 0.0022,
      "step": 2790
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.003777777777777778,
      "loss": 0.0034,
      "step": 2800
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0037555555555555554,
      "loss": 0.0017,
      "step": 2810
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0037333333333333337,
      "loss": 0.0028,
      "step": 2820
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.003711111111111111,
      "loss": 0.0021,
      "step": 2830
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0036888888888888887,
      "loss": 0.002,
      "step": 2840
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0036666666666666666,
      "loss": 0.002,
      "step": 2850
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0036444444444444445,
      "loss": 0.0027,
      "step": 2860
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0036222222222222224,
      "loss": 0.0025,
      "step": 2870
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0036,
      "loss": 0.0023,
      "step": 2880
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0035777777777777774,
      "loss": 0.0018,
      "step": 2890
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0035555555555555557,
      "loss": 0.0033,
      "step": 2900
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.003533333333333333,
      "loss": 0.0029,
      "step": 2910
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.003511111111111111,
      "loss": 0.0026,
      "step": 2920
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.003488888888888889,
      "loss": 0.0025,
      "step": 2930
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.003466666666666667,
      "loss": 0.0027,
      "step": 2940
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0034444444444444444,
      "loss": 0.0028,
      "step": 2950
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0034222222222222223,
      "loss": 0.0031,
      "step": 2960
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0034000000000000002,
      "loss": 0.0029,
      "step": 2970
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.003377777777777778,
      "loss": 0.0022,
      "step": 2980
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.0033555555555555556,
      "loss": 0.0025,
      "step": 2990
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.003333333333333333,
      "loss": 0.0024,
      "step": 3000
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0049833333333333335,
      "loss": 0.1304,
      "step": 3010
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.004966666666666667,
      "loss": 0.0486,
      "step": 3020
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00495,
      "loss": 0.0175,
      "step": 3030
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.004933333333333334,
      "loss": 0.0146,
      "step": 3040
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.004916666666666666,
      "loss": 0.0133,
      "step": 3050
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0049,
      "loss": 0.0086,
      "step": 3060
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.004883333333333333,
      "loss": 0.0109,
      "step": 3070
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.004866666666666667,
      "loss": 0.0089,
      "step": 3080
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00485,
      "loss": 0.0072,
      "step": 3090
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.004833333333333334,
      "loss": 0.0064,
      "step": 3100
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.004816666666666667,
      "loss": 0.0054,
      "step": 3110
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0048,
      "loss": 0.0068,
      "step": 3120
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.004783333333333333,
      "loss": 0.006,
      "step": 3130
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.004766666666666667,
      "loss": 0.0046,
      "step": 3140
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00475,
      "loss": 0.0041,
      "step": 3150
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.004733333333333333,
      "loss": 0.0055,
      "step": 3160
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.004716666666666667,
      "loss": 0.0071,
      "step": 3170
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0047,
      "loss": 0.0057,
      "step": 3180
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.004683333333333334,
      "loss": 0.0045,
      "step": 3190
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.004666666666666667,
      "loss": 0.0053,
      "step": 3200
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0046500000000000005,
      "loss": 0.0063,
      "step": 3210
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.004633333333333333,
      "loss": 0.0053,
      "step": 3220
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0046166666666666665,
      "loss": 0.0037,
      "step": 3230
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0046,
      "loss": 0.0049,
      "step": 3240
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.004583333333333333,
      "loss": 0.0044,
      "step": 3250
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.004566666666666667,
      "loss": 0.0054,
      "step": 3260
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00455,
      "loss": 0.0046,
      "step": 3270
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.004533333333333333,
      "loss": 0.0043,
      "step": 3280
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.004516666666666667,
      "loss": 0.0023,
      "step": 3290
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0045000000000000005,
      "loss": 0.0046,
      "step": 3300
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.004483333333333333,
      "loss": 0.0035,
      "step": 3310
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.0044666666666666665,
      "loss": 0.0047,
      "step": 3320
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00445,
      "loss": 0.0048,
      "step": 3330
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.004433333333333333,
      "loss": 0.0063,
      "step": 3340
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.004416666666666667,
      "loss": 0.0064,
      "step": 3350
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.0044,
      "loss": 0.0045,
      "step": 3360
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.004383333333333334,
      "loss": 0.0039,
      "step": 3370
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.004366666666666666,
      "loss": 0.0042,
      "step": 3380
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00435,
      "loss": 0.0041,
      "step": 3390
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.004333333333333334,
      "loss": 0.0049,
      "step": 3400
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.004316666666666667,
      "loss": 0.0033,
      "step": 3410
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0043,
      "loss": 0.0034,
      "step": 3420
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0042833333333333334,
      "loss": 0.004,
      "step": 3430
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.004266666666666667,
      "loss": 0.0047,
      "step": 3440
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00425,
      "loss": 0.0038,
      "step": 3450
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.004233333333333334,
      "loss": 0.0041,
      "step": 3460
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.004216666666666667,
      "loss": 0.0033,
      "step": 3470
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0042,
      "loss": 0.0049,
      "step": 3480
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.004183333333333333,
      "loss": 0.0032,
      "step": 3490
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.004166666666666667,
      "loss": 0.0043,
      "step": 3500
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00415,
      "loss": 0.0035,
      "step": 3510
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0041333333333333335,
      "loss": 0.0033,
      "step": 3520
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.004116666666666667,
      "loss": 0.0037,
      "step": 3530
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0040999999999999995,
      "loss": 0.0033,
      "step": 3540
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.004083333333333333,
      "loss": 0.0034,
      "step": 3550
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.004066666666666667,
      "loss": 0.0047,
      "step": 3560
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.004050000000000001,
      "loss": 0.0037,
      "step": 3570
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.004033333333333333,
      "loss": 0.0031,
      "step": 3580
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.004016666666666667,
      "loss": 0.0036,
      "step": 3590
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.004,
      "loss": 0.0037,
      "step": 3600
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0039833333333333335,
      "loss": 0.0045,
      "step": 3610
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.003966666666666667,
      "loss": 0.003,
      "step": 3620
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00395,
      "loss": 0.0036,
      "step": 3630
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.003933333333333333,
      "loss": 0.004,
      "step": 3640
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.003916666666666666,
      "loss": 0.0022,
      "step": 3650
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.0039000000000000003,
      "loss": 0.0027,
      "step": 3660
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.0038833333333333333,
      "loss": 0.0029,
      "step": 3670
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.0038666666666666667,
      "loss": 0.0041,
      "step": 3680
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00385,
      "loss": 0.003,
      "step": 3690
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.0038333333333333336,
      "loss": 0.0035,
      "step": 3700
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0038166666666666666,
      "loss": 0.003,
      "step": 3710
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.0038,
      "loss": 0.0026,
      "step": 3720
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.0037833333333333334,
      "loss": 0.0039,
      "step": 3730
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.0037666666666666664,
      "loss": 0.0025,
      "step": 3740
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00375,
      "loss": 0.0026,
      "step": 3750
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.0037333333333333337,
      "loss": 0.0038,
      "step": 3760
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.0037166666666666667,
      "loss": 0.0029,
      "step": 3770
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.0037,
      "loss": 0.0033,
      "step": 3780
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.0036833333333333336,
      "loss": 0.0028,
      "step": 3790
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.0036666666666666666,
      "loss": 0.0033,
      "step": 3800
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00365,
      "loss": 0.0024,
      "step": 3810
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.0036333333333333335,
      "loss": 0.0026,
      "step": 3820
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.003616666666666667,
      "loss": 0.0021,
      "step": 3830
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.0036,
      "loss": 0.0028,
      "step": 3840
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0035833333333333333,
      "loss": 0.0031,
      "step": 3850
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.0035666666666666668,
      "loss": 0.0037,
      "step": 3860
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.0035499999999999998,
      "loss": 0.0027,
      "step": 3870
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.003533333333333333,
      "loss": 0.003,
      "step": 3880
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.003516666666666667,
      "loss": 0.0026,
      "step": 3890
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.0034999999999999996,
      "loss": 0.0026,
      "step": 3900
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.0034833333333333335,
      "loss": 0.003,
      "step": 3910
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.003466666666666667,
      "loss": 0.0032,
      "step": 3920
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00345,
      "loss": 0.0025,
      "step": 3930
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.0034333333333333334,
      "loss": 0.0028,
      "step": 3940
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.003416666666666667,
      "loss": 0.0021,
      "step": 3950
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.0034000000000000002,
      "loss": 0.0023,
      "step": 3960
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.0033833333333333332,
      "loss": 0.0021,
      "step": 3970
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.0033666666666666667,
      "loss": 0.003,
      "step": 3980
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00335,
      "loss": 0.0024,
      "step": 3990
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.003333333333333333,
      "loss": 0.0027,
      "step": 4000
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0033166666666666665,
      "loss": 0.0028,
      "step": 4010
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.0033000000000000004,
      "loss": 0.0023,
      "step": 4020
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.003283333333333333,
      "loss": 0.0027,
      "step": 4030
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.003266666666666667,
      "loss": 0.0031,
      "step": 4040
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.0032500000000000003,
      "loss": 0.0037,
      "step": 4050
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.0032333333333333333,
      "loss": 0.0024,
      "step": 4060
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.0032166666666666667,
      "loss": 0.0024,
      "step": 4070
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.0032,
      "loss": 0.0021,
      "step": 4080
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0031833333333333336,
      "loss": 0.0024,
      "step": 4090
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0031666666666666666,
      "loss": 0.0028,
      "step": 4100
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00315,
      "loss": 0.003,
      "step": 4110
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.0031333333333333335,
      "loss": 0.0027,
      "step": 4120
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.0031166666666666665,
      "loss": 0.0034,
      "step": 4130
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0031,
      "loss": 0.0026,
      "step": 4140
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.0030833333333333338,
      "loss": 0.0029,
      "step": 4150
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.0030666666666666663,
      "loss": 0.0027,
      "step": 4160
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00305,
      "loss": 0.0027,
      "step": 4170
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0030333333333333336,
      "loss": 0.0034,
      "step": 4180
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.003016666666666667,
      "loss": 0.0027,
      "step": 4190
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.003,
      "loss": 0.0027,
      "step": 4200
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.0029833333333333335,
      "loss": 0.0022,
      "step": 4210
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.002966666666666667,
      "loss": 0.0026,
      "step": 4220
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00295,
      "loss": 0.0029,
      "step": 4230
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0029333333333333334,
      "loss": 0.0022,
      "step": 4240
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.002916666666666667,
      "loss": 0.0021,
      "step": 4250
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.0029,
      "loss": 0.0024,
      "step": 4260
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.0028833333333333332,
      "loss": 0.0025,
      "step": 4270
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.0028666666666666667,
      "loss": 0.0018,
      "step": 4280
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.0028499999999999997,
      "loss": 0.0023,
      "step": 4290
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.002833333333333333,
      "loss": 0.003,
      "step": 4300
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.002816666666666667,
      "loss": 0.0017,
      "step": 4310
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.0028000000000000004,
      "loss": 0.0025,
      "step": 4320
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.0027833333333333334,
      "loss": 0.0024,
      "step": 4330
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.002766666666666667,
      "loss": 0.0028,
      "step": 4340
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.0027500000000000003,
      "loss": 0.0035,
      "step": 4350
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0027333333333333333,
      "loss": 0.0023,
      "step": 4360
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.0027166666666666667,
      "loss": 0.0027,
      "step": 4370
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.0027,
      "loss": 0.0029,
      "step": 4380
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.002683333333333333,
      "loss": 0.0027,
      "step": 4390
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.0026666666666666666,
      "loss": 0.0031,
      "step": 4400
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00265,
      "loss": 0.003,
      "step": 4410
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.002633333333333333,
      "loss": 0.0024,
      "step": 4420
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.0026166666666666664,
      "loss": 0.003,
      "step": 4430
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.0026000000000000003,
      "loss": 0.0027,
      "step": 4440
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.0025833333333333337,
      "loss": 0.0031,
      "step": 4450
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.0025666666666666667,
      "loss": 0.002,
      "step": 4460
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00255,
      "loss": 0.0024,
      "step": 4470
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.0025333333333333336,
      "loss": 0.0028,
      "step": 4480
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.0025166666666666666,
      "loss": 0.0027,
      "step": 4490
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.0025,
      "loss": 0.0023,
      "step": 4500
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.0024833333333333335,
      "loss": 0.0129,
      "step": 4510
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.002466666666666667,
      "loss": 0.0053,
      "step": 4520
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00245,
      "loss": 0.0034,
      "step": 4530
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.0024333333333333334,
      "loss": 0.0032,
      "step": 4540
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.002416666666666667,
      "loss": 0.0039,
      "step": 4550
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.0024,
      "loss": 0.0046,
      "step": 4560
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.0023833333333333337,
      "loss": 0.0027,
      "step": 4570
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.0023666666666666667,
      "loss": 0.0035,
      "step": 4580
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00235,
      "loss": 0.0023,
      "step": 4590
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.0023333333333333335,
      "loss": 0.0045,
      "step": 4600
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.0023166666666666665,
      "loss": 0.0039,
      "step": 4610
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.0023,
      "loss": 0.0042,
      "step": 4620
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.0022833333333333334,
      "loss": 0.0037,
      "step": 4630
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.0022666666666666664,
      "loss": 0.003,
      "step": 4640
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.0022500000000000003,
      "loss": 0.0033,
      "step": 4650
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.0022333333333333333,
      "loss": 0.0029,
      "step": 4660
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.0022166666666666667,
      "loss": 0.0027,
      "step": 4670
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.0022,
      "loss": 0.0048,
      "step": 4680
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.002183333333333333,
      "loss": 0.0041,
      "step": 4690
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.002166666666666667,
      "loss": 0.0036,
      "step": 4700
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00215,
      "loss": 0.0031,
      "step": 4710
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.0021333333333333334,
      "loss": 0.0037,
      "step": 4720
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.002116666666666667,
      "loss": 0.0043,
      "step": 4730
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.0021,
      "loss": 0.0028,
      "step": 4740
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0020833333333333333,
      "loss": 0.0029,
      "step": 4750
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.0020666666666666667,
      "loss": 0.0036,
      "step": 4760
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.0020499999999999997,
      "loss": 0.004,
      "step": 4770
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.0020333333333333336,
      "loss": 0.0031,
      "step": 4780
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.0020166666666666666,
      "loss": 0.0034,
      "step": 4790
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.002,
      "loss": 0.0031,
      "step": 4800
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.0019833333333333335,
      "loss": 0.0039,
      "step": 4810
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.0019666666666666665,
      "loss": 0.0037,
      "step": 4820
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.0019500000000000001,
      "loss": 0.0035,
      "step": 4830
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.0019333333333333333,
      "loss": 0.0037,
      "step": 4840
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.0019166666666666668,
      "loss": 0.0028,
      "step": 4850
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.0019,
      "loss": 0.0029,
      "step": 4860
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.0018833333333333332,
      "loss": 0.0025,
      "step": 4870
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.0018666666666666669,
      "loss": 0.0026,
      "step": 4880
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00185,
      "loss": 0.0034,
      "step": 4890
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.0018333333333333333,
      "loss": 0.003,
      "step": 4900
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.0018166666666666667,
      "loss": 0.0036,
      "step": 4910
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.0018,
      "loss": 0.0033,
      "step": 4920
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.0017833333333333334,
      "loss": 0.0024,
      "step": 4930
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.0017666666666666666,
      "loss": 0.0029,
      "step": 4940
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.0017499999999999998,
      "loss": 0.0022,
      "step": 4950
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.0017333333333333335,
      "loss": 0.0032,
      "step": 4960
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.0017166666666666667,
      "loss": 0.0027,
      "step": 4970
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.0017000000000000001,
      "loss": 0.0039,
      "step": 4980
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.0016833333333333333,
      "loss": 0.0027,
      "step": 4990
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.0016666666666666666,
      "loss": 0.0035,
      "step": 5000
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.0016500000000000002,
      "loss": 0.0024,
      "step": 5010
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.0016333333333333334,
      "loss": 0.0031,
      "step": 5020
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.0016166666666666666,
      "loss": 0.0028,
      "step": 5030
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.0016,
      "loss": 0.0039,
      "step": 5040
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.0015833333333333333,
      "loss": 0.0032,
      "step": 5050
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.0015666666666666667,
      "loss": 0.0031,
      "step": 5060
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00155,
      "loss": 0.0021,
      "step": 5070
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.0015333333333333332,
      "loss": 0.0023,
      "step": 5080
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.0015166666666666668,
      "loss": 0.0028,
      "step": 5090
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.0015,
      "loss": 0.0029,
      "step": 5100
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.0014833333333333335,
      "loss": 0.0028,
      "step": 5110
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.0014666666666666667,
      "loss": 0.0022,
      "step": 5120
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00145,
      "loss": 0.0028,
      "step": 5130
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.0014333333333333333,
      "loss": 0.0025,
      "step": 5140
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.0014166666666666666,
      "loss": 0.0038,
      "step": 5150
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.0014000000000000002,
      "loss": 0.0031,
      "step": 5160
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.0013833333333333334,
      "loss": 0.0022,
      "step": 5170
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.0013666666666666666,
      "loss": 0.003,
      "step": 5180
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00135,
      "loss": 0.003,
      "step": 5190
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.0013333333333333333,
      "loss": 0.0026,
      "step": 5200
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.0013166666666666665,
      "loss": 0.0027,
      "step": 5210
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.0013000000000000002,
      "loss": 0.0027,
      "step": 5220
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.0012833333333333334,
      "loss": 0.0036,
      "step": 5230
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.0012666666666666668,
      "loss": 0.0024,
      "step": 5240
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.00125,
      "loss": 0.0031,
      "step": 5250
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.0012333333333333335,
      "loss": 0.0022,
      "step": 5260
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.0012166666666666667,
      "loss": 0.0019,
      "step": 5270
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.0012,
      "loss": 0.0025,
      "step": 5280
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.0011833333333333333,
      "loss": 0.0027,
      "step": 5290
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.0011666666666666668,
      "loss": 0.0031,
      "step": 5300
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00115,
      "loss": 0.0035,
      "step": 5310
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.0011333333333333332,
      "loss": 0.0027,
      "step": 5320
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.0011166666666666666,
      "loss": 0.0032,
      "step": 5330
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.0011,
      "loss": 0.003,
      "step": 5340
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.0010833333333333335,
      "loss": 0.0019,
      "step": 5350
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.0010666666666666667,
      "loss": 0.0033,
      "step": 5360
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00105,
      "loss": 0.0018,
      "step": 5370
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.0010333333333333334,
      "loss": 0.003,
      "step": 5380
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.0010166666666666668,
      "loss": 0.0021,
      "step": 5390
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.001,
      "loss": 0.0031,
      "step": 5400
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.0009833333333333332,
      "loss": 0.0032,
      "step": 5410
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.0009666666666666667,
      "loss": 0.0025,
      "step": 5420
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00095,
      "loss": 0.0024,
      "step": 5430
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.0009333333333333334,
      "loss": 0.0021,
      "step": 5440
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.0009166666666666666,
      "loss": 0.0022,
      "step": 5450
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.0009,
      "loss": 0.002,
      "step": 5460
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.0008833333333333333,
      "loss": 0.0025,
      "step": 5470
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.0008666666666666667,
      "loss": 0.0028,
      "step": 5480
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.0008500000000000001,
      "loss": 0.0025,
      "step": 5490
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.0008333333333333333,
      "loss": 0.0024,
      "step": 5500
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.0008166666666666667,
      "loss": 0.0025,
      "step": 5510
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.0008,
      "loss": 0.0029,
      "step": 5520
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.0007833333333333334,
      "loss": 0.0024,
      "step": 5530
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.0007666666666666666,
      "loss": 0.0034,
      "step": 5540
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00075,
      "loss": 0.0042,
      "step": 5550
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.0007333333333333333,
      "loss": 0.0022,
      "step": 5560
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.0007166666666666667,
      "loss": 0.0022,
      "step": 5570
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.0007000000000000001,
      "loss": 0.0021,
      "step": 5580
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.0006833333333333333,
      "loss": 0.0027,
      "step": 5590
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.0006666666666666666,
      "loss": 0.0022,
      "step": 5600
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.0033,
      "step": 5610
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.0006333333333333334,
      "loss": 0.0032,
      "step": 5620
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.0006166666666666667,
      "loss": 0.0034,
      "step": 5630
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.0006,
      "loss": 0.0022,
      "step": 5640
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.0005833333333333334,
      "loss": 0.0024,
      "step": 5650
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.0005666666666666666,
      "loss": 0.0024,
      "step": 5660
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00055,
      "loss": 0.0031,
      "step": 5670
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.0005333333333333334,
      "loss": 0.0025,
      "step": 5680
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.0005166666666666667,
      "loss": 0.0026,
      "step": 5690
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.0005,
      "loss": 0.0031,
      "step": 5700
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00048333333333333334,
      "loss": 0.0022,
      "step": 5710
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.0004666666666666667,
      "loss": 0.003,
      "step": 5720
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00045,
      "loss": 0.0023,
      "step": 5730
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00043333333333333337,
      "loss": 0.0031,
      "step": 5740
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00041666666666666664,
      "loss": 0.0023,
      "step": 5750
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.0004,
      "loss": 0.0025,
      "step": 5760
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.0003833333333333333,
      "loss": 0.0024,
      "step": 5770
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.00036666666666666667,
      "loss": 0.003,
      "step": 5780
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00035000000000000005,
      "loss": 0.0021,
      "step": 5790
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0025,
      "step": 5800
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0003166666666666667,
      "loss": 0.0028,
      "step": 5810
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.0003,
      "loss": 0.0025,
      "step": 5820
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.0002833333333333333,
      "loss": 0.0025,
      "step": 5830
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.0028,
      "step": 5840
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00025,
      "loss": 0.0037,
      "step": 5850
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00023333333333333336,
      "loss": 0.0027,
      "step": 5860
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00021666666666666668,
      "loss": 0.0024,
      "step": 5870
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.0002,
      "loss": 0.0023,
      "step": 5880
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.0037,
      "step": 5890
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00016666666666666666,
      "loss": 0.0021,
      "step": 5900
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00015,
      "loss": 0.002,
      "step": 5910
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.0021,
      "step": 5920
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00011666666666666668,
      "loss": 0.0031,
      "step": 5930
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.0001,
      "loss": 0.0024,
      "step": 5940
    },
    {
      "epoch": 6.68,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.0024,
      "step": 5950
    },
    {
      "epoch": 6.69,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0031,
      "step": 5960
    },
    {
      "epoch": 6.7,
      "learning_rate": 5e-05,
      "loss": 0.0031,
      "step": 5970
    },
    {
      "epoch": 6.71,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0031,
      "step": 5980
    },
    {
      "epoch": 6.72,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0027,
      "step": 5990
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.0,
      "loss": 0.0024,
      "step": 6000
    }
  ],
  "max_steps": 6000,
  "num_train_epochs": 7,
  "total_flos": 3.529759430943965e+18,
  "trial_name": null,
  "trial_params": null
}
