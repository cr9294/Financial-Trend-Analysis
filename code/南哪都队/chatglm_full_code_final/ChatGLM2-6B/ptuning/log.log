master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-08-27 03:47:01.269250: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-08-27 03:47:01.291582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-27 03:47:01.652768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
08/27/2023 03:47:02 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2023 03:47:02 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.01,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../../model/classifier/runs/Aug27_03-47-02_RedDragon,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=1500,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_hf,
optim_args=None,
output_dir=../../model/classifier,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=8,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=../../model/classifier,
save_on_each_node=False,
save_safetensors=False,
save_steps=150,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/home/red/miniconda3/envs/torch/lib/python3.10/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
[INFO|configuration_utils.py:667] 2023-08-27 03:47:02,839 >> loading configuration file ../../model/chatglm2-6b/config.json
[INFO|configuration_utils.py:667] 2023-08-27 03:47:02,841 >> loading configuration file ../../model/chatglm2-6b/config.json
[INFO|configuration_utils.py:725] 2023-08-27 03:47:02,842 >> Model config ChatGLMConfig {
  "_name_or_path": "../../model/chatglm2-6b",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration"
  },
  "bias_dropout_fusion": true,
  "eos_token_id": 2,
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1e-05,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_layers": 28,
  "original_rope": true,
  "pad_token_id": 0,
  "padded_vocab_size": 65024,
  "post_layer_norm": true,
  "pre_seq_len": null,
  "prefix_projection": false,
  "quantization_bit": 0,
  "rmsnorm": true,
  "seq_length": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.30.2",
  "use_cache": true,
  "vocab_size": 65024
}

[INFO|tokenization_utils_base.py:1821] 2023-08-27 03:47:02,844 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:1821] 2023-08-27 03:47:02,844 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1821] 2023-08-27 03:47:02,844 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1821] 2023-08-27 03:47:02,844 >> loading file tokenizer_config.json
[INFO|modeling_utils.py:2575] 2023-08-27 03:47:02,884 >> loading weights file ../../model/chatglm2-6b/pytorch_model.bin.index.json
[INFO|configuration_utils.py:577] 2023-08-27 03:47:02,884 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "eos_token_id": 2,
  "pad_token_id": 0,
  "transformers_version": "4.30.2"
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:05,  1.13it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:01<00:04,  1.11it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:02<00:03,  1.12it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:03<00:02,  1.15it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:04<00:01,  1.15it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.21it/s]
[INFO|modeling_utils.py:3295] 2023-08-27 03:47:08,730 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.

[WARNING|modeling_utils.py:3297] 2023-08-27 03:47:08,731 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at ../../model/chatglm2-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:2927] 2023-08-27 03:47:08,731 >> Generation config file not found, using a generation config created from the model config.
Running tokenizer on train dataset (num_proc=10):   0%|          | 0/13486 [00:00<?, ? examples/s]Running tokenizer on train dataset (num_proc=10):   7%|▋         | 1000/13486 [00:00<00:04, 2637.63 examples/s]Running tokenizer on train dataset (num_proc=10):  64%|██████▍   | 8698/13486 [00:00<00:00, 22327.21 examples/s]Running tokenizer on train dataset (num_proc=10):  97%|█████████▋| 13138/13486 [00:00<00:00, 24456.70 examples/s]Running tokenizer on train dataset (num_proc=10): 100%|██████████| 13486/13486 [00:01<00:00, 11443.12 examples/s]
input_ids [64790, 64792, 790, 30951, 517, 30910, 30939, 30996, 13, 13, 54761, 31211, 36995, 32040, 39099, 32184, 33467, 43489, 31201, 31629, 33624, 31201, 36211, 33425, 54931, 31639, 31123, 36995, 54557, 44910, 33425, 33508, 31123, 36211, 32245, 31639, 31123, 36995, 54557, 44910, 45028, 43530, 31123, 54548, 8266, 32129, 33287, 30954, 31793, 56001, 56533, 32465, 30943, 30940, 30943, 30940, 31766, 52798, 31123, 35276, 48159, 32025, 31629, 31950, 40455, 31703, 32172, 42817, 32201, 32356, 54648, 31693, 54619, 54604, 31825, 41441, 48159, 31895, 31514, 13, 13, 55437, 31211, 15821, 33467, 2932, 449, 32245, 31639, 1252, 449, 31629, 33624, 2932, 449, 56001, 56533, 32465, 1252, 449, 43489, 2932, 15404, 30943, 30940, 30943, 30940, 15332, 449, 35075, 2932, 15404, 31703, 32172, 32201, 5515, 30983, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
inputs [Round 1]

问：提取以下句子的问题类型年份、公司名称、如果是财务类问题，提取出对应的财务指标，如果是开放问题，提取出对应的财报章节，以json形式回答:根据欣贺股份2020年的年报，能否简要介绍公司报告期内主要销售客户的客户集中度以及与同行业情况的简要分析？

答： {"类型": "开放问题", "公司名称": "欣贺股份", "年份": ["2020"], "关键词": ["主要销售客户"]}
label_ids [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 15821, 33467, 2932, 449, 32245, 31639, 1252, 449, 31629, 33624, 2932, 449, 56001, 56533, 32465, 1252, 449, 43489, 2932, 15404, 30943, 30940, 30943, 30940, 15332, 449, 35075, 2932, 15404, 31703, 32172, 32201, 5515, 30983, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
labels {"类型": "开放问题", "公司名称": "欣贺股份", "年份": ["2020"], "关键词": ["主要销售客户"]}
[INFO|trainer.py:577] 2023-08-27 03:47:12,741 >> max_steps is given, it will override any value given in num_train_epochs
/home/red/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[INFO|trainer.py:1786] 2023-08-27 03:47:12,958 >> ***** Running training *****
[INFO|trainer.py:1787] 2023-08-27 03:47:12,958 >>   Num examples = 13,486
[INFO|trainer.py:1788] 2023-08-27 03:47:12,959 >>   Num Epochs = 4
[INFO|trainer.py:1789] 2023-08-27 03:47:12,959 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:1790] 2023-08-27 03:47:12,959 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1791] 2023-08-27 03:47:12,959 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:1792] 2023-08-27 03:47:12,959 >>   Total optimization steps = 1,500
[INFO|trainer.py:1793] 2023-08-27 03:47:12,959 >>   Number of trainable parameters = 1,835,008
  0%|          | 0/1500 [00:00<?, ?it/s]08/27/2023 03:47:13 - WARNING - transformers_modules.chatglm2-6b.modeling_chatglm - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/1500 [00:14<5:57:58, 14.33s/it]  0%|          | 2/1500 [00:28<5:49:20, 13.99s/it]  0%|          | 3/1500 [00:41<5:46:54, 13.90s/it]  0%|          | 4/1500 [00:55<5:46:14, 13.89s/it]  0%|          | 5/1500 [01:09<5:46:04, 13.89s/it]  0%|          | 6/1500 [01:23<5:45:59, 13.90s/it]  0%|          | 7/1500 [01:37<5:46:03, 13.91s/it]  1%|          | 8/1500 [01:51<5:46:07, 13.92s/it]  1%|          | 9/1500 [02:05<5:45:56, 13.92s/it]  1%|          | 10/1500 [02:19<5:45:52, 13.93s/it]                                                   {'loss': 0.9593, 'learning_rate': 0.009933333333333334, 'epoch': 0.02}
  1%|          | 10/1500 [02:19<5:45:52, 13.93s/it]  1%|          | 11/1500 [02:33<5:45:42, 13.93s/it]  1%|          | 12/1500 [02:47<5:45:36, 13.94s/it]  1%|          | 13/1500 [03:01<5:45:23, 13.94s/it]  1%|          | 14/1500 [03:15<5:45:13, 13.94s/it]  1%|          | 15/1500 [03:29<5:45:01, 13.94s/it]  1%|          | 16/1500 [03:42<5:44:48, 13.94s/it]  1%|          | 17/1500 [03:56<5:44:34, 13.94s/it]  1%|          | 18/1500 [04:10<5:44:20, 13.94s/it]  1%|▏         | 19/1500 [04:24<5:44:06, 13.94s/it]  1%|▏         | 20/1500 [04:38<5:43:54, 13.94s/it]                                                   {'loss': 0.2161, 'learning_rate': 0.009866666666666668, 'epoch': 0.05}
  1%|▏         | 20/1500 [04:38<5:43:54, 13.94s/it]  1%|▏         | 21/1500 [04:52<5:43:39, 13.94s/it]  1%|▏         | 22/1500 [05:06<5:43:24, 13.94s/it]  2%|▏         | 23/1500 [05:20<5:43:07, 13.94s/it]  2%|▏         | 24/1500 [05:34<5:42:54, 13.94s/it]  2%|▏         | 25/1500 [05:48<5:42:45, 13.94s/it]  2%|▏         | 26/1500 [06:02<5:42:41, 13.95s/it]  2%|▏         | 27/1500 [06:16<5:42:29, 13.95s/it]  2%|▏         | 28/1500 [06:30<5:42:08, 13.95s/it]  2%|▏         | 29/1500 [06:44<5:41:50, 13.94s/it]  2%|▏         | 30/1500 [06:58<5:41:31, 13.94s/it]                                                   {'loss': 0.1232, 'learning_rate': 0.0098, 'epoch': 0.07}
  2%|▏         | 30/1500 [06:58<5:41:31, 13.94s/it]  2%|▏         | 31/1500 [07:12<5:41:15, 13.94s/it]  2%|▏         | 32/1500 [07:26<5:40:59, 13.94s/it]  2%|▏         | 33/1500 [07:39<5:40:47, 13.94s/it]  2%|▏         | 34/1500 [07:53<5:40:32, 13.94s/it]  2%|▏         | 35/1500 [08:07<5:40:18, 13.94s/it]  2%|▏         | 36/1500 [08:21<5:40:03, 13.94s/it]  2%|▏         | 37/1500 [08:35<5:39:48, 13.94s/it]  3%|▎         | 38/1500 [08:49<5:39:32, 13.93s/it]  3%|▎         | 39/1500 [09:03<5:39:15, 13.93s/it]  3%|▎         | 40/1500 [09:17<5:39:02, 13.93s/it]                                                   {'loss': 0.1031, 'learning_rate': 0.009733333333333333, 'epoch': 0.09}
  3%|▎         | 40/1500 [09:17<5:39:02, 13.93s/it]  3%|▎         | 41/1500 [09:31<5:38:53, 13.94s/it]  3%|▎         | 42/1500 [09:45<5:38:44, 13.94s/it]  3%|▎         | 43/1500 [09:59<5:38:29, 13.94s/it]  3%|▎         | 44/1500 [10:13<5:38:12, 13.94s/it]  3%|▎         | 45/1500 [10:27<5:38:04, 13.94s/it]  3%|▎         | 46/1500 [10:41<5:37:51, 13.94s/it]  3%|▎         | 47/1500 [10:55<5:37:34, 13.94s/it]  3%|▎         | 48/1500 [11:09<5:37:20, 13.94s/it]  3%|▎         | 49/1500 [11:22<5:37:02, 13.94s/it]  3%|▎         | 50/1500 [11:36<5:36:44, 13.93s/it]                                                   {'loss': 0.0879, 'learning_rate': 0.009666666666666667, 'epoch': 0.12}
  3%|▎         | 50/1500 [11:36<5:36:44, 13.93s/it]  3%|▎         | 51/1500 [11:50<5:36:34, 13.94s/it]  3%|▎         | 52/1500 [12:04<5:36:27, 13.94s/it]  4%|▎         | 53/1500 [12:18<5:36:14, 13.94s/it]  4%|▎         | 54/1500 [12:32<5:35:59, 13.94s/it]  4%|▎         | 55/1500 [12:46<5:35:44, 13.94s/it]  4%|▎         | 56/1500 [13:00<5:35:25, 13.94s/it]  4%|▍         | 57/1500 [13:14<5:35:10, 13.94s/it]  4%|▍         | 58/1500 [13:28<5:34:54, 13.93s/it]  4%|▍         | 59/1500 [13:42<5:34:39, 13.93s/it]  4%|▍         | 60/1500 [13:56<5:34:25, 13.93s/it]                                                   {'loss': 0.0659, 'learning_rate': 0.0096, 'epoch': 0.14}
  4%|▍         | 60/1500 [13:56<5:34:25, 13.93s/it]  4%|▍         | 61/1500 [14:10<5:34:11, 13.93s/it]  4%|▍         | 62/1500 [14:24<5:33:56, 13.93s/it]  4%|▍         | 63/1500 [14:38<5:33:43, 13.93s/it]  4%|▍         | 64/1500 [14:51<5:33:26, 13.93s/it]  4%|▍         | 65/1500 [15:05<5:33:16, 13.94s/it]  4%|▍         | 66/1500 [15:19<5:33:12, 13.94s/it]  4%|▍         | 67/1500 [15:33<5:32:53, 13.94s/it]  5%|▍         | 68/1500 [15:47<5:32:34, 13.93s/it]  5%|▍         | 69/1500 [16:01<5:32:15, 13.93s/it]  5%|▍         | 70/1500 [16:15<5:32:05, 13.93s/it]                                                   {'loss': 0.0695, 'learning_rate': 0.009533333333333335, 'epoch': 0.17}
  5%|▍         | 70/1500 [16:15<5:32:05, 13.93s/it]  5%|▍         | 71/1500 [16:29<5:31:51, 13.93s/it]  5%|▍         | 72/1500 [16:43<5:31:33, 13.93s/it]  5%|▍         | 73/1500 [16:57<5:31:21, 13.93s/it]  5%|▍         | 74/1500 [17:11<5:31:16, 13.94s/it]  5%|▌         | 75/1500 [17:25<5:31:00, 13.94s/it]  5%|▌         | 76/1500 [17:39<5:30:45, 13.94s/it]  5%|▌         | 77/1500 [17:53<5:30:29, 13.93s/it]  5%|▌         | 78/1500 [18:07<5:30:12, 13.93s/it]  5%|▌         | 79/1500 [18:21<5:29:57, 13.93s/it]  5%|▌         | 80/1500 [18:34<5:29:37, 13.93s/it]                                                   {'loss': 0.0496, 'learning_rate': 0.009466666666666667, 'epoch': 0.19}
  5%|▌         | 80/1500 [18:34<5:29:37, 13.93s/it]  5%|▌         | 81/1500 [18:48<5:29:23, 13.93s/it]  5%|▌         | 82/1500 [19:02<5:29:08, 13.93s/it]  6%|▌         | 83/1500 [19:16<5:28:50, 13.92s/it]  6%|▌         | 84/1500 [19:30<5:28:37, 13.92s/it]  6%|▌         | 85/1500 [19:44<5:28:21, 13.92s/it]  6%|▌         | 86/1500 [19:58<5:28:09, 13.92s/it]  6%|▌         | 87/1500 [20:12<5:27:59, 13.93s/it]  6%|▌         | 88/1500 [20:26<5:27:46, 13.93s/it]  6%|▌         | 89/1500 [20:40<5:27:31, 13.93s/it]  6%|▌         | 90/1500 [20:54<5:27:24, 13.93s/it]                                                   {'loss': 0.0523, 'learning_rate': 0.0094, 'epoch': 0.21}
  6%|▌         | 90/1500 [20:54<5:27:24, 13.93s/it]  6%|▌         | 91/1500 [21:08<5:27:14, 13.94s/it]  6%|▌         | 92/1500 [21:22<5:26:57, 13.93s/it]  6%|▌         | 93/1500 [21:36<5:26:42, 13.93s/it]  6%|▋         | 94/1500 [21:49<5:26:30, 13.93s/it]  6%|▋         | 95/1500 [22:03<5:26:14, 13.93s/it]  6%|▋         | 96/1500 [22:17<5:25:56, 13.93s/it]  6%|▋         | 97/1500 [22:31<5:25:40, 13.93s/it]  7%|▋         | 98/1500 [22:45<5:25:26, 13.93s/it]  7%|▋         | 99/1500 [22:59<5:25:12, 13.93s/it]  7%|▋         | 100/1500 [23:13<5:25:00, 13.93s/it]                                                    {'loss': 0.046, 'learning_rate': 0.009333333333333334, 'epoch': 0.24}
  7%|▋         | 100/1500 [23:13<5:25:00, 13.93s/it]  7%|▋         | 101/1500 [23:27<5:24:48, 13.93s/it]  7%|▋         | 102/1500 [23:41<5:24:35, 13.93s/it]  7%|▋         | 103/1500 [23:55<5:24:20, 13.93s/it]  7%|▋         | 104/1500 [24:09<5:24:05, 13.93s/it]  7%|▋         | 105/1500 [24:23<5:23:53, 13.93s/it]  7%|▋         | 106/1500 [24:37<5:23:38, 13.93s/it]  7%|▋         | 107/1500 [24:51<5:23:32, 13.94s/it]  7%|▋         | 108/1500 [25:04<5:23:28, 13.94s/it]  7%|▋         | 109/1500 [25:18<5:23:13, 13.94s/it]  7%|▋         | 110/1500 [25:32<5:23:01, 13.94s/it]                                                    {'loss': 0.0438, 'learning_rate': 0.009266666666666666, 'epoch': 0.26}
  7%|▋         | 110/1500 [25:32<5:23:01, 13.94s/it]  7%|▋         | 111/1500 [25:46<5:22:41, 13.94s/it]  7%|▋         | 112/1500 [26:00<5:22:25, 13.94s/it]  8%|▊         | 113/1500 [26:14<5:22:09, 13.94s/it]  8%|▊         | 114/1500 [26:28<5:21:53, 13.93s/it]  8%|▊         | 115/1500 [26:42<5:21:42, 13.94s/it]  8%|▊         | 116/1500 [26:56<5:21:24, 13.93s/it]  8%|▊         | 117/1500 [27:10<5:21:11, 13.93s/it]  8%|▊         | 118/1500 [27:24<5:20:54, 13.93s/it]  8%|▊         | 119/1500 [27:38<5:20:39, 13.93s/it]  8%|▊         | 120/1500 [27:52<5:20:21, 13.93s/it]                                                    {'loss': 0.0395, 'learning_rate': 0.0092, 'epoch': 0.28}
  8%|▊         | 120/1500 [27:52<5:20:21, 13.93s/it]  8%|▊         | 121/1500 [28:06<5:20:05, 13.93s/it]  8%|▊         | 122/1500 [28:20<5:19:49, 13.93s/it]  8%|▊         | 123/1500 [28:33<5:19:35, 13.93s/it]  8%|▊         | 124/1500 [28:47<5:19:20, 13.92s/it]  8%|▊         | 125/1500 [29:01<5:19:07, 13.93s/it]  8%|▊         | 126/1500 [29:15<5:19:00, 13.93s/it]  8%|▊         | 127/1500 [29:29<5:18:51, 13.93s/it]  9%|▊         | 128/1500 [29:43<5:18:34, 13.93s/it]  9%|▊         | 129/1500 [29:57<5:18:17, 13.93s/it]  9%|▊         | 130/1500 [30:11<5:18:03, 13.93s/it]                                                    {'loss': 0.0409, 'learning_rate': 0.009133333333333334, 'epoch': 0.31}
  9%|▊         | 130/1500 [30:11<5:18:03, 13.93s/it]  9%|▊         | 131/1500 [30:25<5:17:48, 13.93s/it]  9%|▉         | 132/1500 [30:39<5:17:31, 13.93s/it]  9%|▉         | 133/1500 [30:53<5:17:17, 13.93s/it]  9%|▉         | 134/1500 [31:07<5:17:02, 13.93s/it]  9%|▉         | 135/1500 [31:21<5:16:49, 13.93s/it]  9%|▉         | 136/1500 [31:35<5:16:34, 13.93s/it]  9%|▉         | 137/1500 [31:48<5:16:18, 13.92s/it]  9%|▉         | 138/1500 [32:02<5:16:06, 13.93s/it]  9%|▉         | 139/1500 [32:16<5:15:56, 13.93s/it]  9%|▉         | 140/1500 [32:30<5:15:39, 13.93s/it]                                                    {'loss': 0.0323, 'learning_rate': 0.009066666666666666, 'epoch': 0.33}
  9%|▉         | 140/1500 [32:30<5:15:39, 13.93s/it]  9%|▉         | 141/1500 [32:44<5:15:25, 13.93s/it]  9%|▉         | 142/1500 [32:58<5:15:12, 13.93s/it] 10%|▉         | 143/1500 [33:12<5:14:57, 13.93s/it] 10%|▉         | 144/1500 [33:26<5:14:43, 13.93s/it] 10%|▉         | 145/1500 [33:40<5:14:29, 13.93s/it] 10%|▉         | 146/1500 [33:54<5:14:16, 13.93s/it] 10%|▉         | 147/1500 [34:08<5:14:04, 13.93s/it] 10%|▉         | 148/1500 [34:22<5:13:51, 13.93s/it] 10%|▉         | 149/1500 [34:36<5:13:33, 13.93s/it] 10%|█         | 150/1500 [34:49<5:13:16, 13.92s/it]                                                    {'loss': 0.031, 'learning_rate': 0.009000000000000001, 'epoch': 0.36}
 10%|█         | 150/1500 [34:49<5:13:16, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 04:22:03,013 >> Configuration saved in ../../model/classifier/checkpoint-150/config.json
[INFO|configuration_utils.py:364] 2023-08-27 04:22:03,014 >> Configuration saved in ../../model/classifier/checkpoint-150/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 04:22:03,021 >> Model weights saved in ../../model/classifier/checkpoint-150/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 04:22:03,021 >> tokenizer config file saved in ../../model/classifier/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 04:22:03,022 >> Special tokens file saved in ../../model/classifier/checkpoint-150/special_tokens_map.json
 10%|█         | 151/1500 [35:03<5:13:12, 13.93s/it] 10%|█         | 152/1500 [35:17<5:12:56, 13.93s/it] 10%|█         | 153/1500 [35:31<5:12:47, 13.93s/it] 10%|█         | 154/1500 [35:45<5:12:34, 13.93s/it] 10%|█         | 155/1500 [35:59<5:12:15, 13.93s/it] 10%|█         | 156/1500 [36:13<5:11:58, 13.93s/it] 10%|█         | 157/1500 [36:27<5:11:49, 13.93s/it] 11%|█         | 158/1500 [36:41<5:11:42, 13.94s/it] 11%|█         | 159/1500 [36:55<5:11:24, 13.93s/it] 11%|█         | 160/1500 [37:09<5:11:09, 13.93s/it]                                                    {'loss': 0.0332, 'learning_rate': 0.008933333333333333, 'epoch': 0.38}
 11%|█         | 160/1500 [37:09<5:11:09, 13.93s/it] 11%|█         | 161/1500 [37:23<5:10:56, 13.93s/it] 11%|█         | 162/1500 [37:37<5:10:38, 13.93s/it] 11%|█         | 163/1500 [37:51<5:10:22, 13.93s/it] 11%|█         | 164/1500 [38:05<5:10:11, 13.93s/it] 11%|█         | 165/1500 [38:18<5:09:53, 13.93s/it] 11%|█         | 166/1500 [38:32<5:09:38, 13.93s/it] 11%|█         | 167/1500 [38:46<5:09:34, 13.93s/it] 11%|█         | 168/1500 [39:00<5:09:20, 13.93s/it] 11%|█▏        | 169/1500 [39:14<5:09:00, 13.93s/it] 11%|█▏        | 170/1500 [39:28<5:08:45, 13.93s/it]                                                    {'loss': 0.031, 'learning_rate': 0.008866666666666667, 'epoch': 0.4}
 11%|█▏        | 170/1500 [39:28<5:08:45, 13.93s/it] 11%|█▏        | 171/1500 [39:42<5:08:29, 13.93s/it] 11%|█▏        | 172/1500 [39:56<5:08:14, 13.93s/it] 12%|█▏        | 173/1500 [40:10<5:07:56, 13.92s/it] 12%|█▏        | 174/1500 [40:24<5:07:39, 13.92s/it] 12%|█▏        | 175/1500 [40:38<5:07:27, 13.92s/it] 12%|█▏        | 176/1500 [40:52<5:07:18, 13.93s/it] 12%|█▏        | 177/1500 [41:06<5:07:09, 13.93s/it] 12%|█▏        | 178/1500 [41:20<5:06:58, 13.93s/it] 12%|█▏        | 179/1500 [41:33<5:06:42, 13.93s/it] 12%|█▏        | 180/1500 [41:47<5:06:31, 13.93s/it]                                                    {'loss': 0.0278, 'learning_rate': 0.0088, 'epoch': 0.43}
 12%|█▏        | 180/1500 [41:47<5:06:31, 13.93s/it] 12%|█▏        | 181/1500 [42:01<5:06:23, 13.94s/it] 12%|█▏        | 182/1500 [42:15<5:06:02, 13.93s/it] 12%|█▏        | 183/1500 [42:29<5:05:45, 13.93s/it] 12%|█▏        | 184/1500 [42:43<5:05:30, 13.93s/it] 12%|█▏        | 185/1500 [42:57<5:05:13, 13.93s/it] 12%|█▏        | 186/1500 [43:11<5:04:56, 13.92s/it] 12%|█▏        | 187/1500 [43:25<5:04:40, 13.92s/it] 13%|█▎        | 188/1500 [43:39<5:04:26, 13.92s/it] 13%|█▎        | 189/1500 [43:53<5:04:10, 13.92s/it] 13%|█▎        | 190/1500 [44:07<5:03:56, 13.92s/it]                                                    {'loss': 0.0247, 'learning_rate': 0.008733333333333333, 'epoch': 0.45}
 13%|█▎        | 190/1500 [44:07<5:03:56, 13.92s/it] 13%|█▎        | 191/1500 [44:21<5:03:44, 13.92s/it] 13%|█▎        | 192/1500 [44:34<5:03:28, 13.92s/it] 13%|█▎        | 193/1500 [44:48<5:03:13, 13.92s/it] 13%|█▎        | 194/1500 [45:02<5:03:00, 13.92s/it] 13%|█▎        | 195/1500 [45:16<5:02:47, 13.92s/it] 13%|█▎        | 196/1500 [45:30<5:02:34, 13.92s/it] 13%|█▎        | 197/1500 [45:44<5:02:20, 13.92s/it] 13%|█▎        | 198/1500 [45:58<5:02:07, 13.92s/it] 13%|█▎        | 199/1500 [46:12<5:01:56, 13.92s/it] 13%|█▎        | 200/1500 [46:26<5:01:42, 13.93s/it]                                                    {'loss': 0.0235, 'learning_rate': 0.008666666666666668, 'epoch': 0.47}
 13%|█▎        | 200/1500 [46:26<5:01:42, 13.93s/it] 13%|█▎        | 201/1500 [46:40<5:01:28, 13.92s/it] 13%|█▎        | 202/1500 [46:54<5:01:13, 13.92s/it] 14%|█▎        | 203/1500 [47:08<5:00:55, 13.92s/it] 14%|█▎        | 204/1500 [47:22<5:00:41, 13.92s/it] 14%|█▎        | 205/1500 [47:35<5:00:30, 13.92s/it] 14%|█▎        | 206/1500 [47:49<5:00:18, 13.92s/it] 14%|█▍        | 207/1500 [48:03<5:00:01, 13.92s/it] 14%|█▍        | 208/1500 [48:17<4:59:48, 13.92s/it] 14%|█▍        | 209/1500 [48:31<4:59:33, 13.92s/it] 14%|█▍        | 210/1500 [48:45<4:59:17, 13.92s/it]                                                    {'loss': 0.021, 'learning_rate': 0.0086, 'epoch': 0.5}
 14%|█▍        | 210/1500 [48:45<4:59:17, 13.92s/it] 14%|█▍        | 211/1500 [48:59<4:59:06, 13.92s/it] 14%|█▍        | 212/1500 [49:13<4:58:52, 13.92s/it] 14%|█▍        | 213/1500 [49:27<4:58:40, 13.92s/it] 14%|█▍        | 214/1500 [49:41<4:58:32, 13.93s/it] 14%|█▍        | 215/1500 [49:55<4:58:23, 13.93s/it] 14%|█▍        | 216/1500 [50:09<4:58:03, 13.93s/it] 14%|█▍        | 217/1500 [50:23<4:57:50, 13.93s/it] 15%|█▍        | 218/1500 [50:37<4:57:37, 13.93s/it] 15%|█▍        | 219/1500 [50:50<4:57:22, 13.93s/it] 15%|█▍        | 220/1500 [51:04<4:57:06, 13.93s/it]                                                    {'loss': 0.0215, 'learning_rate': 0.008533333333333334, 'epoch': 0.52}
 15%|█▍        | 220/1500 [51:04<4:57:06, 13.93s/it] 15%|█▍        | 221/1500 [51:18<4:56:52, 13.93s/it] 15%|█▍        | 222/1500 [51:32<4:56:36, 13.93s/it] 15%|█▍        | 223/1500 [51:46<4:56:21, 13.92s/it] 15%|█▍        | 224/1500 [52:00<4:56:07, 13.92s/it] 15%|█▌        | 225/1500 [52:14<4:55:53, 13.92s/it] 15%|█▌        | 226/1500 [52:28<4:55:34, 13.92s/it] 15%|█▌        | 227/1500 [52:42<4:55:23, 13.92s/it] 15%|█▌        | 228/1500 [52:56<4:55:11, 13.92s/it] 15%|█▌        | 229/1500 [53:10<4:54:53, 13.92s/it] 15%|█▌        | 230/1500 [53:24<4:54:37, 13.92s/it]                                                    {'loss': 0.0187, 'learning_rate': 0.008466666666666667, 'epoch': 0.55}
 15%|█▌        | 230/1500 [53:24<4:54:37, 13.92s/it] 15%|█▌        | 231/1500 [53:38<4:54:23, 13.92s/it] 15%|█▌        | 232/1500 [53:51<4:54:08, 13.92s/it] 16%|█▌        | 233/1500 [54:05<4:53:55, 13.92s/it] 16%|█▌        | 234/1500 [54:19<4:53:45, 13.92s/it] 16%|█▌        | 235/1500 [54:33<4:53:33, 13.92s/it] 16%|█▌        | 236/1500 [54:47<4:53:20, 13.92s/it] 16%|█▌        | 237/1500 [55:01<4:53:05, 13.92s/it] 16%|█▌        | 238/1500 [55:15<4:52:50, 13.92s/it] 16%|█▌        | 239/1500 [55:29<4:52:36, 13.92s/it] 16%|█▌        | 240/1500 [55:43<4:52:21, 13.92s/it]                                                    {'loss': 0.0196, 'learning_rate': 0.0084, 'epoch': 0.57}
 16%|█▌        | 240/1500 [55:43<4:52:21, 13.92s/it] 16%|█▌        | 241/1500 [55:57<4:52:08, 13.92s/it] 16%|█▌        | 242/1500 [56:11<4:51:53, 13.92s/it] 16%|█▌        | 243/1500 [56:25<4:51:38, 13.92s/it] 16%|█▋        | 244/1500 [56:39<4:51:24, 13.92s/it] 16%|█▋        | 245/1500 [56:52<4:51:09, 13.92s/it] 16%|█▋        | 246/1500 [57:06<4:50:57, 13.92s/it] 16%|█▋        | 247/1500 [57:20<4:50:43, 13.92s/it] 17%|█▋        | 248/1500 [57:34<4:50:29, 13.92s/it] 17%|█▋        | 249/1500 [57:48<4:50:13, 13.92s/it] 17%|█▋        | 250/1500 [58:02<4:50:05, 13.92s/it]                                                    {'loss': 0.021, 'learning_rate': 0.008333333333333333, 'epoch': 0.59}
 17%|█▋        | 250/1500 [58:02<4:50:05, 13.92s/it] 17%|█▋        | 251/1500 [58:16<4:49:55, 13.93s/it] 17%|█▋        | 252/1500 [58:30<4:49:37, 13.92s/it] 17%|█▋        | 253/1500 [58:44<4:49:20, 13.92s/it] 17%|█▋        | 254/1500 [58:58<4:49:08, 13.92s/it] 17%|█▋        | 255/1500 [59:12<4:48:59, 13.93s/it] 17%|█▋        | 256/1500 [59:26<4:48:45, 13.93s/it] 17%|█▋        | 257/1500 [59:40<4:48:33, 13.93s/it] 17%|█▋        | 258/1500 [59:53<4:48:21, 13.93s/it] 17%|█▋        | 259/1500 [1:00:07<4:48:09, 13.93s/it] 17%|█▋        | 260/1500 [1:00:21<4:47:58, 13.93s/it]                                                      {'loss': 0.0158, 'learning_rate': 0.008266666666666667, 'epoch': 0.62}
 17%|█▋        | 260/1500 [1:00:21<4:47:58, 13.93s/it] 17%|█▋        | 261/1500 [1:00:35<4:47:39, 13.93s/it] 17%|█▋        | 262/1500 [1:00:49<4:47:20, 13.93s/it] 18%|█▊        | 263/1500 [1:01:03<4:47:04, 13.92s/it] 18%|█▊        | 264/1500 [1:01:17<4:46:49, 13.92s/it] 18%|█▊        | 265/1500 [1:01:31<4:46:36, 13.92s/it] 18%|█▊        | 266/1500 [1:01:45<4:46:22, 13.92s/it] 18%|█▊        | 267/1500 [1:01:59<4:46:08, 13.92s/it] 18%|█▊        | 268/1500 [1:02:13<4:45:52, 13.92s/it] 18%|█▊        | 269/1500 [1:02:27<4:45:40, 13.92s/it] 18%|█▊        | 270/1500 [1:02:41<4:45:31, 13.93s/it]                                                      {'loss': 0.0195, 'learning_rate': 0.008199999999999999, 'epoch': 0.64}
 18%|█▊        | 270/1500 [1:02:41<4:45:31, 13.93s/it] 18%|█▊        | 271/1500 [1:02:55<4:45:21, 13.93s/it] 18%|█▊        | 272/1500 [1:03:08<4:45:08, 13.93s/it] 18%|█▊        | 273/1500 [1:03:22<4:44:59, 13.94s/it] 18%|█▊        | 274/1500 [1:03:36<4:44:43, 13.93s/it] 18%|█▊        | 275/1500 [1:03:50<4:44:27, 13.93s/it] 18%|█▊        | 276/1500 [1:04:04<4:44:07, 13.93s/it] 18%|█▊        | 277/1500 [1:04:18<4:43:50, 13.93s/it] 19%|█▊        | 278/1500 [1:04:32<4:43:37, 13.93s/it] 19%|█▊        | 279/1500 [1:04:46<4:43:24, 13.93s/it] 19%|█▊        | 280/1500 [1:05:00<4:43:06, 13.92s/it]                                                      {'loss': 0.0136, 'learning_rate': 0.008133333333333334, 'epoch': 0.66}
 19%|█▊        | 280/1500 [1:05:00<4:43:06, 13.92s/it] 19%|█▊        | 281/1500 [1:05:14<4:42:50, 13.92s/it] 19%|█▉        | 282/1500 [1:05:28<4:42:36, 13.92s/it] 19%|█▉        | 283/1500 [1:05:42<4:42:21, 13.92s/it] 19%|█▉        | 284/1500 [1:05:56<4:42:06, 13.92s/it] 19%|█▉        | 285/1500 [1:06:09<4:41:53, 13.92s/it] 19%|█▉        | 286/1500 [1:06:23<4:41:41, 13.92s/it] 19%|█▉        | 287/1500 [1:06:37<4:41:26, 13.92s/it] 19%|█▉        | 288/1500 [1:06:51<4:41:09, 13.92s/it] 19%|█▉        | 289/1500 [1:07:05<4:40:54, 13.92s/it] 19%|█▉        | 290/1500 [1:07:19<4:40:39, 13.92s/it]                                                      {'loss': 0.0184, 'learning_rate': 0.008066666666666666, 'epoch': 0.69}
 19%|█▉        | 290/1500 [1:07:19<4:40:39, 13.92s/it] 19%|█▉        | 291/1500 [1:07:33<4:40:25, 13.92s/it] 19%|█▉        | 292/1500 [1:07:47<4:40:14, 13.92s/it] 20%|█▉        | 293/1500 [1:08:01<4:40:02, 13.92s/it] 20%|█▉        | 294/1500 [1:08:15<4:39:49, 13.92s/it] 20%|█▉        | 295/1500 [1:08:29<4:39:35, 13.92s/it] 20%|█▉        | 296/1500 [1:08:43<4:39:21, 13.92s/it] 20%|█▉        | 297/1500 [1:08:57<4:39:06, 13.92s/it] 20%|█▉        | 298/1500 [1:09:10<4:38:56, 13.92s/it] 20%|█▉        | 299/1500 [1:09:24<4:38:38, 13.92s/it] 20%|██        | 300/1500 [1:09:38<4:38:23, 13.92s/it]                                                      {'loss': 0.0133, 'learning_rate': 0.008, 'epoch': 0.71}
 20%|██        | 300/1500 [1:09:38<4:38:23, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 04:56:51,783 >> Configuration saved in ../../model/classifier/checkpoint-300/config.json
[INFO|configuration_utils.py:364] 2023-08-27 04:56:51,783 >> Configuration saved in ../../model/classifier/checkpoint-300/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 04:56:51,790 >> Model weights saved in ../../model/classifier/checkpoint-300/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 04:56:51,790 >> tokenizer config file saved in ../../model/classifier/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 04:56:51,791 >> Special tokens file saved in ../../model/classifier/checkpoint-300/special_tokens_map.json
 20%|██        | 301/1500 [1:09:52<4:38:15, 13.92s/it] 20%|██        | 302/1500 [1:10:06<4:37:57, 13.92s/it] 20%|██        | 303/1500 [1:10:20<4:37:42, 13.92s/it] 20%|██        | 304/1500 [1:10:34<4:37:31, 13.92s/it] 20%|██        | 305/1500 [1:10:48<4:37:18, 13.92s/it] 20%|██        | 306/1500 [1:11:02<4:37:03, 13.92s/it] 20%|██        | 307/1500 [1:11:16<4:36:49, 13.92s/it] 21%|██        | 308/1500 [1:11:30<4:36:32, 13.92s/it] 21%|██        | 309/1500 [1:11:44<4:36:20, 13.92s/it] 21%|██        | 310/1500 [1:11:58<4:36:10, 13.93s/it]                                                      {'loss': 0.0187, 'learning_rate': 0.007933333333333334, 'epoch': 0.74}
 21%|██        | 310/1500 [1:11:58<4:36:10, 13.93s/it] 21%|██        | 311/1500 [1:12:11<4:35:58, 13.93s/it] 21%|██        | 312/1500 [1:12:25<4:35:43, 13.93s/it] 21%|██        | 313/1500 [1:12:39<4:35:28, 13.92s/it] 21%|██        | 314/1500 [1:12:53<4:35:13, 13.92s/it] 21%|██        | 315/1500 [1:13:07<4:35:00, 13.92s/it] 21%|██        | 316/1500 [1:13:21<4:34:47, 13.93s/it] 21%|██        | 317/1500 [1:13:35<4:34:32, 13.92s/it] 21%|██        | 318/1500 [1:13:49<4:34:21, 13.93s/it] 21%|██▏       | 319/1500 [1:14:03<4:34:08, 13.93s/it] 21%|██▏       | 320/1500 [1:14:17<4:33:49, 13.92s/it]                                                      {'loss': 0.0124, 'learning_rate': 0.007866666666666666, 'epoch': 0.76}
 21%|██▏       | 320/1500 [1:14:17<4:33:49, 13.92s/it] 21%|██▏       | 321/1500 [1:14:31<4:33:36, 13.92s/it] 21%|██▏       | 322/1500 [1:14:45<4:33:20, 13.92s/it] 22%|██▏       | 323/1500 [1:14:59<4:33:05, 13.92s/it] 22%|██▏       | 324/1500 [1:15:12<4:32:50, 13.92s/it] 22%|██▏       | 325/1500 [1:15:26<4:32:34, 13.92s/it] 22%|██▏       | 326/1500 [1:15:40<4:32:21, 13.92s/it] 22%|██▏       | 327/1500 [1:15:54<4:32:09, 13.92s/it] 22%|██▏       | 328/1500 [1:16:08<4:31:55, 13.92s/it] 22%|██▏       | 329/1500 [1:16:22<4:31:43, 13.92s/it] 22%|██▏       | 330/1500 [1:16:36<4:31:30, 13.92s/it]                                                      {'loss': 0.0153, 'learning_rate': 0.0078000000000000005, 'epoch': 0.78}
 22%|██▏       | 330/1500 [1:16:36<4:31:30, 13.92s/it] 22%|██▏       | 331/1500 [1:16:50<4:31:18, 13.92s/it] 22%|██▏       | 332/1500 [1:17:04<4:31:02, 13.92s/it] 22%|██▏       | 333/1500 [1:17:18<4:30:50, 13.92s/it] 22%|██▏       | 334/1500 [1:17:32<4:30:35, 13.92s/it] 22%|██▏       | 335/1500 [1:17:46<4:30:19, 13.92s/it] 22%|██▏       | 336/1500 [1:17:59<4:30:02, 13.92s/it] 22%|██▏       | 337/1500 [1:18:13<4:29:49, 13.92s/it] 23%|██▎       | 338/1500 [1:18:27<4:29:34, 13.92s/it] 23%|██▎       | 339/1500 [1:18:41<4:29:22, 13.92s/it] 23%|██▎       | 340/1500 [1:18:55<4:29:09, 13.92s/it]                                                      {'loss': 0.0153, 'learning_rate': 0.007733333333333333, 'epoch': 0.81}
 23%|██▎       | 340/1500 [1:18:55<4:29:09, 13.92s/it] 23%|██▎       | 341/1500 [1:19:09<4:28:54, 13.92s/it] 23%|██▎       | 342/1500 [1:19:23<4:28:44, 13.92s/it] 23%|██▎       | 343/1500 [1:19:37<4:28:37, 13.93s/it] 23%|██▎       | 344/1500 [1:19:51<4:28:20, 13.93s/it] 23%|██▎       | 345/1500 [1:20:05<4:28:05, 13.93s/it] 23%|██▎       | 346/1500 [1:20:19<4:27:49, 13.93s/it] 23%|██▎       | 347/1500 [1:20:33<4:27:32, 13.92s/it] 23%|██▎       | 348/1500 [1:20:47<4:27:22, 13.93s/it] 23%|██▎       | 349/1500 [1:21:01<4:27:07, 13.92s/it] 23%|██▎       | 350/1500 [1:21:14<4:26:51, 13.92s/it]                                                      {'loss': 0.0145, 'learning_rate': 0.007666666666666667, 'epoch': 0.83}
 23%|██▎       | 350/1500 [1:21:14<4:26:51, 13.92s/it] 23%|██▎       | 351/1500 [1:21:28<4:26:40, 13.93s/it] 23%|██▎       | 352/1500 [1:21:42<4:26:26, 13.93s/it] 24%|██▎       | 353/1500 [1:21:56<4:26:09, 13.92s/it] 24%|██▎       | 354/1500 [1:22:10<4:25:54, 13.92s/it] 24%|██▎       | 355/1500 [1:22:24<4:25:41, 13.92s/it] 24%|██▎       | 356/1500 [1:22:38<4:25:27, 13.92s/it] 24%|██▍       | 357/1500 [1:22:52<4:25:13, 13.92s/it] 24%|██▍       | 358/1500 [1:23:06<4:24:59, 13.92s/it] 24%|██▍       | 359/1500 [1:23:20<4:24:47, 13.92s/it] 24%|██▍       | 360/1500 [1:23:34<4:24:32, 13.92s/it]                                                      {'loss': 0.0148, 'learning_rate': 0.0076, 'epoch': 0.85}
 24%|██▍       | 360/1500 [1:23:34<4:24:32, 13.92s/it] 24%|██▍       | 361/1500 [1:23:48<4:24:21, 13.93s/it] 24%|██▍       | 362/1500 [1:24:02<4:24:08, 13.93s/it] 24%|██▍       | 363/1500 [1:24:15<4:23:54, 13.93s/it] 24%|██▍       | 364/1500 [1:24:29<4:23:37, 13.92s/it] 24%|██▍       | 365/1500 [1:24:43<4:23:23, 13.92s/it] 24%|██▍       | 366/1500 [1:24:57<4:23:07, 13.92s/it] 24%|██▍       | 367/1500 [1:25:11<4:22:55, 13.92s/it] 25%|██▍       | 368/1500 [1:25:25<4:22:45, 13.93s/it] 25%|██▍       | 369/1500 [1:25:39<4:22:30, 13.93s/it] 25%|██▍       | 370/1500 [1:25:53<4:22:14, 13.92s/it]                                                      {'loss': 0.0146, 'learning_rate': 0.007533333333333333, 'epoch': 0.88}
 25%|██▍       | 370/1500 [1:25:53<4:22:14, 13.92s/it] 25%|██▍       | 371/1500 [1:26:07<4:21:58, 13.92s/it] 25%|██▍       | 372/1500 [1:26:21<4:21:42, 13.92s/it] 25%|██▍       | 373/1500 [1:26:35<4:21:26, 13.92s/it] 25%|██▍       | 374/1500 [1:26:49<4:21:12, 13.92s/it] 25%|██▌       | 375/1500 [1:27:03<4:20:57, 13.92s/it] 25%|██▌       | 376/1500 [1:27:16<4:20:42, 13.92s/it] 25%|██▌       | 377/1500 [1:27:30<4:20:29, 13.92s/it] 25%|██▌       | 378/1500 [1:27:44<4:20:17, 13.92s/it] 25%|██▌       | 379/1500 [1:27:58<4:20:06, 13.92s/it] 25%|██▌       | 380/1500 [1:28:12<4:19:52, 13.92s/it]                                                      {'loss': 0.0126, 'learning_rate': 0.0074666666666666675, 'epoch': 0.9}
 25%|██▌       | 380/1500 [1:28:12<4:19:52, 13.92s/it] 25%|██▌       | 381/1500 [1:28:26<4:19:37, 13.92s/it] 25%|██▌       | 382/1500 [1:28:40<4:19:31, 13.93s/it] 26%|██▌       | 383/1500 [1:28:54<4:19:19, 13.93s/it] 26%|██▌       | 384/1500 [1:29:08<4:19:00, 13.92s/it] 26%|██▌       | 385/1500 [1:29:22<4:18:46, 13.92s/it] 26%|██▌       | 386/1500 [1:29:36<4:18:32, 13.92s/it] 26%|██▌       | 387/1500 [1:29:50<4:18:15, 13.92s/it] 26%|██▌       | 388/1500 [1:30:04<4:17:58, 13.92s/it] 26%|██▌       | 389/1500 [1:30:17<4:17:46, 13.92s/it] 26%|██▌       | 390/1500 [1:30:31<4:17:32, 13.92s/it]                                                      {'loss': 0.0199, 'learning_rate': 0.0074, 'epoch': 0.93}
 26%|██▌       | 390/1500 [1:30:31<4:17:32, 13.92s/it] 26%|██▌       | 391/1500 [1:30:45<4:17:17, 13.92s/it] 26%|██▌       | 392/1500 [1:30:59<4:17:03, 13.92s/it] 26%|██▌       | 393/1500 [1:31:13<4:16:47, 13.92s/it] 26%|██▋       | 394/1500 [1:31:27<4:16:31, 13.92s/it] 26%|██▋       | 395/1500 [1:31:41<4:16:17, 13.92s/it] 26%|██▋       | 396/1500 [1:31:55<4:16:03, 13.92s/it] 26%|██▋       | 397/1500 [1:32:09<4:15:49, 13.92s/it] 27%|██▋       | 398/1500 [1:32:23<4:15:36, 13.92s/it] 27%|██▋       | 399/1500 [1:32:37<4:15:23, 13.92s/it] 27%|██▋       | 400/1500 [1:32:51<4:15:08, 13.92s/it]                                                      {'loss': 0.0155, 'learning_rate': 0.007333333333333333, 'epoch': 0.95}
 27%|██▋       | 400/1500 [1:32:51<4:15:08, 13.92s/it] 27%|██▋       | 401/1500 [1:33:04<4:14:55, 13.92s/it] 27%|██▋       | 402/1500 [1:33:18<4:14:41, 13.92s/it] 27%|██▋       | 403/1500 [1:33:32<4:14:27, 13.92s/it] 27%|██▋       | 404/1500 [1:33:46<4:14:11, 13.92s/it] 27%|██▋       | 405/1500 [1:34:00<4:13:59, 13.92s/it] 27%|██▋       | 406/1500 [1:34:14<4:13:43, 13.92s/it] 27%|██▋       | 407/1500 [1:34:28<4:13:31, 13.92s/it] 27%|██▋       | 408/1500 [1:34:42<4:13:22, 13.92s/it] 27%|██▋       | 409/1500 [1:34:56<4:13:10, 13.92s/it] 27%|██▋       | 410/1500 [1:35:10<4:12:56, 13.92s/it]                                                      {'loss': 0.0145, 'learning_rate': 0.007266666666666667, 'epoch': 0.97}
 27%|██▋       | 410/1500 [1:35:10<4:12:56, 13.92s/it] 27%|██▋       | 411/1500 [1:35:24<4:12:41, 13.92s/it] 27%|██▋       | 412/1500 [1:35:38<4:12:26, 13.92s/it] 28%|██▊       | 413/1500 [1:35:51<4:12:15, 13.92s/it] 28%|██▊       | 414/1500 [1:36:05<4:11:58, 13.92s/it] 28%|██▊       | 415/1500 [1:36:19<4:11:42, 13.92s/it] 28%|██▊       | 416/1500 [1:36:33<4:11:30, 13.92s/it] 28%|██▊       | 417/1500 [1:36:47<4:11:17, 13.92s/it] 28%|██▊       | 418/1500 [1:37:01<4:11:02, 13.92s/it] 28%|██▊       | 419/1500 [1:37:15<4:10:44, 13.92s/it] 28%|██▊       | 420/1500 [1:37:29<4:10:30, 13.92s/it]                                                      {'loss': 0.0137, 'learning_rate': 0.0072, 'epoch': 1.0}
 28%|██▊       | 420/1500 [1:37:29<4:10:30, 13.92s/it] 28%|██▊       | 421/1500 [1:37:43<4:10:15, 13.92s/it] 28%|██▊       | 422/1500 [1:37:56<4:05:48, 13.68s/it] 28%|██▊       | 423/1500 [1:38:10<4:06:45, 13.75s/it] 28%|██▊       | 424/1500 [1:38:24<4:07:24, 13.80s/it] 28%|██▊       | 425/1500 [1:38:38<4:07:48, 13.83s/it] 28%|██▊       | 426/1500 [1:38:52<4:08:00, 13.86s/it] 28%|██▊       | 427/1500 [1:39:06<4:08:05, 13.87s/it] 29%|██▊       | 428/1500 [1:39:19<4:08:07, 13.89s/it] 29%|██▊       | 429/1500 [1:39:33<4:08:09, 13.90s/it] 29%|██▊       | 430/1500 [1:39:47<4:08:02, 13.91s/it]                                                      {'loss': 0.0127, 'learning_rate': 0.0071333333333333335, 'epoch': 1.02}
 29%|██▊       | 430/1500 [1:39:47<4:08:02, 13.91s/it] 29%|██▊       | 431/1500 [1:40:01<4:07:53, 13.91s/it] 29%|██▉       | 432/1500 [1:40:15<4:07:43, 13.92s/it] 29%|██▉       | 433/1500 [1:40:29<4:07:31, 13.92s/it] 29%|██▉       | 434/1500 [1:40:43<4:07:15, 13.92s/it] 29%|██▉       | 435/1500 [1:40:57<4:07:05, 13.92s/it] 29%|██▉       | 436/1500 [1:41:11<4:06:52, 13.92s/it] 29%|██▉       | 437/1500 [1:41:25<4:06:37, 13.92s/it] 29%|██▉       | 438/1500 [1:41:39<4:06:25, 13.92s/it] 29%|██▉       | 439/1500 [1:41:53<4:06:13, 13.92s/it] 29%|██▉       | 440/1500 [1:42:07<4:05:57, 13.92s/it]                                                      {'loss': 0.0103, 'learning_rate': 0.007066666666666666, 'epoch': 1.04}
 29%|██▉       | 440/1500 [1:42:07<4:05:57, 13.92s/it] 29%|██▉       | 441/1500 [1:42:20<4:05:41, 13.92s/it] 29%|██▉       | 442/1500 [1:42:34<4:05:26, 13.92s/it] 30%|██▉       | 443/1500 [1:42:48<4:05:10, 13.92s/it] 30%|██▉       | 444/1500 [1:43:02<4:04:56, 13.92s/it] 30%|██▉       | 445/1500 [1:43:16<4:04:41, 13.92s/it] 30%|██▉       | 446/1500 [1:43:30<4:04:26, 13.92s/it] 30%|██▉       | 447/1500 [1:43:44<4:04:13, 13.92s/it] 30%|██▉       | 448/1500 [1:43:58<4:03:59, 13.92s/it] 30%|██▉       | 449/1500 [1:44:12<4:03:45, 13.92s/it] 30%|███       | 450/1500 [1:44:26<4:03:32, 13.92s/it]                                                      {'loss': 0.0116, 'learning_rate': 0.006999999999999999, 'epoch': 1.07}
 30%|███       | 450/1500 [1:44:26<4:03:32, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 05:31:39,188 >> Configuration saved in ../../model/classifier/checkpoint-450/config.json
[INFO|configuration_utils.py:364] 2023-08-27 05:31:39,188 >> Configuration saved in ../../model/classifier/checkpoint-450/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 05:31:39,195 >> Model weights saved in ../../model/classifier/checkpoint-450/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 05:31:39,195 >> tokenizer config file saved in ../../model/classifier/checkpoint-450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 05:31:39,195 >> Special tokens file saved in ../../model/classifier/checkpoint-450/special_tokens_map.json
 30%|███       | 451/1500 [1:44:40<4:03:26, 13.92s/it] 30%|███       | 452/1500 [1:44:54<4:03:13, 13.92s/it] 30%|███       | 453/1500 [1:45:07<4:02:56, 13.92s/it] 30%|███       | 454/1500 [1:45:21<4:02:38, 13.92s/it] 30%|███       | 455/1500 [1:45:35<4:02:22, 13.92s/it] 30%|███       | 456/1500 [1:45:49<4:02:07, 13.92s/it] 30%|███       | 457/1500 [1:46:03<4:01:52, 13.91s/it] 31%|███       | 458/1500 [1:46:17<4:01:37, 13.91s/it] 31%|███       | 459/1500 [1:46:31<4:01:24, 13.91s/it] 31%|███       | 460/1500 [1:46:45<4:01:10, 13.91s/it]                                                      {'loss': 0.012, 'learning_rate': 0.006933333333333334, 'epoch': 1.09}
 31%|███       | 460/1500 [1:46:45<4:01:10, 13.91s/it] 31%|███       | 461/1500 [1:46:59<4:00:57, 13.92s/it] 31%|███       | 462/1500 [1:47:13<4:00:43, 13.92s/it] 31%|███       | 463/1500 [1:47:27<4:00:30, 13.92s/it] 31%|███       | 464/1500 [1:47:41<4:00:17, 13.92s/it] 31%|███       | 465/1500 [1:47:54<4:00:02, 13.92s/it] 31%|███       | 466/1500 [1:48:08<3:59:49, 13.92s/it] 31%|███       | 467/1500 [1:48:22<3:59:34, 13.92s/it] 31%|███       | 468/1500 [1:48:36<3:59:20, 13.91s/it] 31%|███▏      | 469/1500 [1:48:50<3:59:06, 13.91s/it] 31%|███▏      | 470/1500 [1:49:04<3:58:53, 13.92s/it]                                                      {'loss': 0.0099, 'learning_rate': 0.006866666666666667, 'epoch': 1.12}
 31%|███▏      | 470/1500 [1:49:04<3:58:53, 13.92s/it] 31%|███▏      | 471/1500 [1:49:18<3:58:40, 13.92s/it] 31%|███▏      | 472/1500 [1:49:32<3:58:30, 13.92s/it] 32%|███▏      | 473/1500 [1:49:46<3:58:16, 13.92s/it] 32%|███▏      | 474/1500 [1:50:00<3:58:02, 13.92s/it] 32%|███▏      | 475/1500 [1:50:14<3:57:51, 13.92s/it] 32%|███▏      | 476/1500 [1:50:28<3:57:40, 13.93s/it] 32%|███▏      | 477/1500 [1:50:41<3:57:22, 13.92s/it] 32%|███▏      | 478/1500 [1:50:55<3:57:06, 13.92s/it] 32%|███▏      | 479/1500 [1:51:09<3:56:53, 13.92s/it] 32%|███▏      | 480/1500 [1:51:23<3:56:42, 13.92s/it]                                                      {'loss': 0.0098, 'learning_rate': 0.0068000000000000005, 'epoch': 1.14}
 32%|███▏      | 480/1500 [1:51:23<3:56:42, 13.92s/it] 32%|███▏      | 481/1500 [1:51:37<3:56:27, 13.92s/it] 32%|███▏      | 482/1500 [1:51:51<3:56:09, 13.92s/it] 32%|███▏      | 483/1500 [1:52:05<3:55:53, 13.92s/it] 32%|███▏      | 484/1500 [1:52:19<3:55:40, 13.92s/it] 32%|███▏      | 485/1500 [1:52:33<3:55:30, 13.92s/it] 32%|███▏      | 486/1500 [1:52:47<3:55:19, 13.92s/it] 32%|███▏      | 487/1500 [1:53:01<3:55:03, 13.92s/it] 33%|███▎      | 488/1500 [1:53:15<3:54:48, 13.92s/it] 33%|███▎      | 489/1500 [1:53:29<3:54:36, 13.92s/it] 33%|███▎      | 490/1500 [1:53:42<3:54:22, 13.92s/it]                                                      {'loss': 0.0103, 'learning_rate': 0.006733333333333333, 'epoch': 1.16}
 33%|███▎      | 490/1500 [1:53:42<3:54:22, 13.92s/it] 33%|███▎      | 491/1500 [1:53:56<3:54:07, 13.92s/it] 33%|███▎      | 492/1500 [1:54:10<3:53:58, 13.93s/it] 33%|███▎      | 493/1500 [1:54:24<3:53:47, 13.93s/it] 33%|███▎      | 494/1500 [1:54:38<3:53:33, 13.93s/it] 33%|███▎      | 495/1500 [1:54:52<3:53:17, 13.93s/it] 33%|███▎      | 496/1500 [1:55:06<3:53:03, 13.93s/it] 33%|███▎      | 497/1500 [1:55:20<3:52:46, 13.92s/it] 33%|███▎      | 498/1500 [1:55:34<3:52:29, 13.92s/it] 33%|███▎      | 499/1500 [1:55:48<3:52:16, 13.92s/it] 33%|███▎      | 500/1500 [1:56:02<3:52:03, 13.92s/it]                                                      {'loss': 0.0113, 'learning_rate': 0.006666666666666666, 'epoch': 1.19}
 33%|███▎      | 500/1500 [1:56:02<3:52:03, 13.92s/it] 33%|███▎      | 501/1500 [1:56:16<3:51:49, 13.92s/it] 33%|███▎      | 502/1500 [1:56:30<3:51:34, 13.92s/it] 34%|███▎      | 503/1500 [1:56:43<3:51:21, 13.92s/it] 34%|███▎      | 504/1500 [1:56:57<3:51:11, 13.93s/it] 34%|███▎      | 505/1500 [1:57:11<3:50:54, 13.92s/it] 34%|███▎      | 506/1500 [1:57:25<3:50:40, 13.92s/it] 34%|███▍      | 507/1500 [1:57:39<3:50:25, 13.92s/it] 34%|███▍      | 508/1500 [1:57:53<3:50:07, 13.92s/it] 34%|███▍      | 509/1500 [1:58:07<3:49:52, 13.92s/it] 34%|███▍      | 510/1500 [1:58:21<3:49:38, 13.92s/it]                                                      {'loss': 0.0091, 'learning_rate': 0.006600000000000001, 'epoch': 1.21}
 34%|███▍      | 510/1500 [1:58:21<3:49:38, 13.92s/it] 34%|███▍      | 511/1500 [1:58:35<3:49:25, 13.92s/it] 34%|███▍      | 512/1500 [1:58:49<3:49:11, 13.92s/it] 34%|███▍      | 513/1500 [1:59:03<3:48:56, 13.92s/it] 34%|███▍      | 514/1500 [1:59:17<3:48:41, 13.92s/it] 34%|███▍      | 515/1500 [1:59:30<3:48:27, 13.92s/it] 34%|███▍      | 516/1500 [1:59:44<3:48:15, 13.92s/it] 34%|███▍      | 517/1500 [1:59:58<3:48:05, 13.92s/it] 35%|███▍      | 518/1500 [2:00:12<3:47:48, 13.92s/it] 35%|███▍      | 519/1500 [2:00:26<3:47:38, 13.92s/it] 35%|███▍      | 520/1500 [2:00:40<3:47:25, 13.92s/it]                                                      {'loss': 0.0103, 'learning_rate': 0.006533333333333334, 'epoch': 1.23}
 35%|███▍      | 520/1500 [2:00:40<3:47:25, 13.92s/it] 35%|███▍      | 521/1500 [2:00:54<3:47:09, 13.92s/it] 35%|███▍      | 522/1500 [2:01:08<3:46:53, 13.92s/it] 35%|███▍      | 523/1500 [2:01:22<3:46:42, 13.92s/it] 35%|███▍      | 524/1500 [2:01:36<3:46:31, 13.93s/it] 35%|███▌      | 525/1500 [2:01:50<3:46:15, 13.92s/it] 35%|███▌      | 526/1500 [2:02:04<3:45:59, 13.92s/it] 35%|███▌      | 527/1500 [2:02:18<3:45:47, 13.92s/it] 35%|███▌      | 528/1500 [2:02:31<3:45:30, 13.92s/it] 35%|███▌      | 529/1500 [2:02:45<3:45:14, 13.92s/it] 35%|███▌      | 530/1500 [2:02:59<3:45:02, 13.92s/it]                                                      {'loss': 0.0109, 'learning_rate': 0.006466666666666667, 'epoch': 1.26}
 35%|███▌      | 530/1500 [2:02:59<3:45:02, 13.92s/it] 35%|███▌      | 531/1500 [2:03:13<3:44:49, 13.92s/it] 35%|███▌      | 532/1500 [2:03:27<3:44:33, 13.92s/it] 36%|███▌      | 533/1500 [2:03:41<3:44:17, 13.92s/it] 36%|███▌      | 534/1500 [2:03:55<3:44:05, 13.92s/it] 36%|███▌      | 535/1500 [2:04:09<3:43:50, 13.92s/it] 36%|███▌      | 536/1500 [2:04:23<3:43:37, 13.92s/it] 36%|███▌      | 537/1500 [2:04:37<3:43:20, 13.92s/it] 36%|███▌      | 538/1500 [2:04:51<3:43:07, 13.92s/it] 36%|███▌      | 539/1500 [2:05:05<3:42:53, 13.92s/it] 36%|███▌      | 540/1500 [2:05:18<3:42:40, 13.92s/it]                                                      {'loss': 0.0094, 'learning_rate': 0.0064, 'epoch': 1.28}
 36%|███▌      | 540/1500 [2:05:18<3:42:40, 13.92s/it] 36%|███▌      | 541/1500 [2:05:32<3:42:25, 13.92s/it] 36%|███▌      | 542/1500 [2:05:46<3:42:10, 13.92s/it] 36%|███▌      | 543/1500 [2:06:00<3:41:55, 13.91s/it] 36%|███▋      | 544/1500 [2:06:14<3:41:44, 13.92s/it] 36%|███▋      | 545/1500 [2:06:28<3:41:31, 13.92s/it] 36%|███▋      | 546/1500 [2:06:42<3:41:18, 13.92s/it] 36%|███▋      | 547/1500 [2:06:56<3:41:03, 13.92s/it] 37%|███▋      | 548/1500 [2:07:10<3:40:53, 13.92s/it] 37%|███▋      | 549/1500 [2:07:24<3:40:41, 13.92s/it] 37%|███▋      | 550/1500 [2:07:38<3:40:23, 13.92s/it]                                                      {'loss': 0.0137, 'learning_rate': 0.006333333333333333, 'epoch': 1.3}
 37%|███▋      | 550/1500 [2:07:38<3:40:23, 13.92s/it] 37%|███▋      | 551/1500 [2:07:52<3:40:09, 13.92s/it] 37%|███▋      | 552/1500 [2:08:06<3:39:57, 13.92s/it] 37%|███▋      | 553/1500 [2:08:19<3:39:46, 13.92s/it] 37%|███▋      | 554/1500 [2:08:33<3:39:36, 13.93s/it] 37%|███▋      | 555/1500 [2:08:47<3:39:19, 13.93s/it] 37%|███▋      | 556/1500 [2:09:01<3:39:03, 13.92s/it] 37%|███▋      | 557/1500 [2:09:15<3:38:48, 13.92s/it] 37%|███▋      | 558/1500 [2:09:29<3:38:36, 13.92s/it] 37%|███▋      | 559/1500 [2:09:43<3:38:24, 13.93s/it] 37%|███▋      | 560/1500 [2:09:57<3:38:15, 13.93s/it]                                                      {'loss': 0.0095, 'learning_rate': 0.006266666666666667, 'epoch': 1.33}
 37%|███▋      | 560/1500 [2:09:57<3:38:15, 13.93s/it] 37%|███▋      | 561/1500 [2:10:11<3:37:57, 13.93s/it] 37%|███▋      | 562/1500 [2:10:25<3:37:40, 13.92s/it] 38%|███▊      | 563/1500 [2:10:39<3:37:26, 13.92s/it] 38%|███▊      | 564/1500 [2:10:53<3:37:12, 13.92s/it] 38%|███▊      | 565/1500 [2:11:07<3:36:57, 13.92s/it] 38%|███▊      | 566/1500 [2:11:20<3:36:43, 13.92s/it] 38%|███▊      | 567/1500 [2:11:34<3:36:30, 13.92s/it] 38%|███▊      | 568/1500 [2:11:48<3:36:15, 13.92s/it] 38%|███▊      | 569/1500 [2:12:02<3:35:59, 13.92s/it] 38%|███▊      | 570/1500 [2:12:16<3:35:45, 13.92s/it]                                                      {'loss': 0.0085, 'learning_rate': 0.0062, 'epoch': 1.35}
 38%|███▊      | 570/1500 [2:12:16<3:35:45, 13.92s/it] 38%|███▊      | 571/1500 [2:12:30<3:35:32, 13.92s/it] 38%|███▊      | 572/1500 [2:12:44<3:35:18, 13.92s/it] 38%|███▊      | 573/1500 [2:12:58<3:35:04, 13.92s/it] 38%|███▊      | 574/1500 [2:13:12<3:34:49, 13.92s/it] 38%|███▊      | 575/1500 [2:13:26<3:34:34, 13.92s/it] 38%|███▊      | 576/1500 [2:13:40<3:34:21, 13.92s/it] 38%|███▊      | 577/1500 [2:13:54<3:34:05, 13.92s/it] 39%|███▊      | 578/1500 [2:14:07<3:33:50, 13.92s/it] 39%|███▊      | 579/1500 [2:14:21<3:33:38, 13.92s/it] 39%|███▊      | 580/1500 [2:14:35<3:33:24, 13.92s/it]                                                      {'loss': 0.0092, 'learning_rate': 0.006133333333333333, 'epoch': 1.38}
 39%|███▊      | 580/1500 [2:14:35<3:33:24, 13.92s/it] 39%|███▊      | 581/1500 [2:14:49<3:33:11, 13.92s/it] 39%|███▉      | 582/1500 [2:15:03<3:32:57, 13.92s/it] 39%|███▉      | 583/1500 [2:15:17<3:32:42, 13.92s/it] 39%|███▉      | 584/1500 [2:15:31<3:32:31, 13.92s/it] 39%|███▉      | 585/1500 [2:15:45<3:32:22, 13.93s/it] 39%|███▉      | 586/1500 [2:15:59<3:32:07, 13.93s/it] 39%|███▉      | 587/1500 [2:16:13<3:31:53, 13.93s/it] 39%|███▉      | 588/1500 [2:16:27<3:31:45, 13.93s/it] 39%|███▉      | 589/1500 [2:16:41<3:31:30, 13.93s/it] 39%|███▉      | 590/1500 [2:16:55<3:31:13, 13.93s/it]                                                      {'loss': 0.0106, 'learning_rate': 0.006066666666666667, 'epoch': 1.4}
 39%|███▉      | 590/1500 [2:16:55<3:31:13, 13.93s/it] 39%|███▉      | 591/1500 [2:17:09<3:30:58, 13.93s/it] 39%|███▉      | 592/1500 [2:17:22<3:30:46, 13.93s/it] 40%|███▉      | 593/1500 [2:17:36<3:30:32, 13.93s/it] 40%|███▉      | 594/1500 [2:17:50<3:30:15, 13.92s/it] 40%|███▉      | 595/1500 [2:18:04<3:29:59, 13.92s/it] 40%|███▉      | 596/1500 [2:18:18<3:29:42, 13.92s/it] 40%|███▉      | 597/1500 [2:18:32<3:29:30, 13.92s/it] 40%|███▉      | 598/1500 [2:18:46<3:29:15, 13.92s/it] 40%|███▉      | 599/1500 [2:19:00<3:28:59, 13.92s/it] 40%|████      | 600/1500 [2:19:14<3:28:43, 13.92s/it]                                                      {'loss': 0.0089, 'learning_rate': 0.006, 'epoch': 1.42}
 40%|████      | 600/1500 [2:19:14<3:28:43, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 06:06:27,316 >> Configuration saved in ../../model/classifier/checkpoint-600/config.json
[INFO|configuration_utils.py:364] 2023-08-27 06:06:27,316 >> Configuration saved in ../../model/classifier/checkpoint-600/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 06:06:27,322 >> Model weights saved in ../../model/classifier/checkpoint-600/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 06:06:27,323 >> tokenizer config file saved in ../../model/classifier/checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 06:06:27,323 >> Special tokens file saved in ../../model/classifier/checkpoint-600/special_tokens_map.json
 40%|████      | 601/1500 [2:19:28<3:28:36, 13.92s/it] 40%|████      | 602/1500 [2:19:42<3:28:26, 13.93s/it] 40%|████      | 603/1500 [2:19:56<3:28:11, 13.93s/it] 40%|████      | 604/1500 [2:20:10<3:27:58, 13.93s/it] 40%|████      | 605/1500 [2:20:23<3:27:47, 13.93s/it] 40%|████      | 606/1500 [2:20:37<3:27:31, 13.93s/it] 40%|████      | 607/1500 [2:20:51<3:27:15, 13.93s/it] 41%|████      | 608/1500 [2:21:05<3:26:58, 13.92s/it] 41%|████      | 609/1500 [2:21:19<3:26:42, 13.92s/it] 41%|████      | 610/1500 [2:21:33<3:26:29, 13.92s/it]                                                      {'loss': 0.0101, 'learning_rate': 0.005933333333333334, 'epoch': 1.45}
 41%|████      | 610/1500 [2:21:33<3:26:29, 13.92s/it] 41%|████      | 611/1500 [2:21:47<3:26:14, 13.92s/it] 41%|████      | 612/1500 [2:22:01<3:26:03, 13.92s/it] 41%|████      | 613/1500 [2:22:15<3:25:46, 13.92s/it] 41%|████      | 614/1500 [2:22:29<3:25:31, 13.92s/it] 41%|████      | 615/1500 [2:22:43<3:25:18, 13.92s/it] 41%|████      | 616/1500 [2:22:57<3:25:08, 13.92s/it] 41%|████      | 617/1500 [2:23:11<3:24:52, 13.92s/it] 41%|████      | 618/1500 [2:23:24<3:24:37, 13.92s/it] 41%|████▏     | 619/1500 [2:23:38<3:24:23, 13.92s/it] 41%|████▏     | 620/1500 [2:23:52<3:24:09, 13.92s/it]                                                      {'loss': 0.0135, 'learning_rate': 0.005866666666666667, 'epoch': 1.47}
 41%|████▏     | 620/1500 [2:23:52<3:24:09, 13.92s/it] 41%|████▏     | 621/1500 [2:24:06<3:23:56, 13.92s/it] 41%|████▏     | 622/1500 [2:24:20<3:23:44, 13.92s/it] 42%|████▏     | 623/1500 [2:24:34<3:23:30, 13.92s/it] 42%|████▏     | 624/1500 [2:24:48<3:23:15, 13.92s/it] 42%|████▏     | 625/1500 [2:25:02<3:23:02, 13.92s/it] 42%|████▏     | 626/1500 [2:25:16<3:22:48, 13.92s/it] 42%|████▏     | 627/1500 [2:25:30<3:22:33, 13.92s/it] 42%|████▏     | 628/1500 [2:25:44<3:22:18, 13.92s/it] 42%|████▏     | 629/1500 [2:25:58<3:22:06, 13.92s/it] 42%|████▏     | 630/1500 [2:26:11<3:21:53, 13.92s/it]                                                      {'loss': 0.0111, 'learning_rate': 0.0058, 'epoch': 1.49}
 42%|████▏     | 630/1500 [2:26:11<3:21:53, 13.92s/it] 42%|████▏     | 631/1500 [2:26:25<3:21:39, 13.92s/it] 42%|████▏     | 632/1500 [2:26:39<3:21:24, 13.92s/it] 42%|████▏     | 633/1500 [2:26:53<3:21:12, 13.92s/it] 42%|████▏     | 634/1500 [2:27:07<3:21:01, 13.93s/it] 42%|████▏     | 635/1500 [2:27:21<3:20:46, 13.93s/it] 42%|████▏     | 636/1500 [2:27:35<3:20:31, 13.93s/it] 42%|████▏     | 637/1500 [2:27:49<3:20:18, 13.93s/it] 43%|████▎     | 638/1500 [2:28:03<3:20:04, 13.93s/it] 43%|████▎     | 639/1500 [2:28:17<3:19:50, 13.93s/it] 43%|████▎     | 640/1500 [2:28:31<3:19:36, 13.93s/it]                                                      {'loss': 0.0096, 'learning_rate': 0.005733333333333333, 'epoch': 1.52}
 43%|████▎     | 640/1500 [2:28:31<3:19:36, 13.93s/it] 43%|████▎     | 641/1500 [2:28:45<3:19:25, 13.93s/it] 43%|████▎     | 642/1500 [2:28:59<3:19:08, 13.93s/it] 43%|████▎     | 643/1500 [2:29:13<3:18:52, 13.92s/it] 43%|████▎     | 644/1500 [2:29:26<3:18:37, 13.92s/it] 43%|████▎     | 645/1500 [2:29:40<3:18:21, 13.92s/it] 43%|████▎     | 646/1500 [2:29:54<3:18:10, 13.92s/it] 43%|████▎     | 647/1500 [2:30:08<3:17:55, 13.92s/it] 43%|████▎     | 648/1500 [2:30:22<3:17:41, 13.92s/it] 43%|████▎     | 649/1500 [2:30:36<3:17:25, 13.92s/it] 43%|████▎     | 650/1500 [2:30:50<3:17:11, 13.92s/it]                                                      {'loss': 0.0106, 'learning_rate': 0.005666666666666666, 'epoch': 1.54}
 43%|████▎     | 650/1500 [2:30:50<3:17:11, 13.92s/it] 43%|████▎     | 651/1500 [2:31:04<3:16:56, 13.92s/it] 43%|████▎     | 652/1500 [2:31:18<3:16:41, 13.92s/it] 44%|████▎     | 653/1500 [2:31:32<3:16:28, 13.92s/it] 44%|████▎     | 654/1500 [2:31:46<3:16:13, 13.92s/it] 44%|████▎     | 655/1500 [2:32:00<3:16:00, 13.92s/it] 44%|████▎     | 656/1500 [2:32:13<3:15:48, 13.92s/it] 44%|████▍     | 657/1500 [2:32:27<3:15:34, 13.92s/it] 44%|████▍     | 658/1500 [2:32:41<3:15:21, 13.92s/it] 44%|████▍     | 659/1500 [2:32:55<3:15:07, 13.92s/it] 44%|████▍     | 660/1500 [2:33:09<3:14:52, 13.92s/it]                                                      {'loss': 0.0075, 'learning_rate': 0.005600000000000001, 'epoch': 1.57}
 44%|████▍     | 660/1500 [2:33:09<3:14:52, 13.92s/it] 44%|████▍     | 661/1500 [2:33:23<3:14:37, 13.92s/it] 44%|████▍     | 662/1500 [2:33:37<3:14:27, 13.92s/it] 44%|████▍     | 663/1500 [2:33:51<3:14:11, 13.92s/it] 44%|████▍     | 664/1500 [2:34:05<3:13:56, 13.92s/it] 44%|████▍     | 665/1500 [2:34:19<3:13:42, 13.92s/it] 44%|████▍     | 666/1500 [2:34:33<3:13:29, 13.92s/it] 44%|████▍     | 667/1500 [2:34:47<3:13:16, 13.92s/it] 45%|████▍     | 668/1500 [2:35:01<3:13:00, 13.92s/it] 45%|████▍     | 669/1500 [2:35:14<3:12:48, 13.92s/it] 45%|████▍     | 670/1500 [2:35:28<3:12:33, 13.92s/it]                                                      {'loss': 0.0109, 'learning_rate': 0.005533333333333334, 'epoch': 1.59}
 45%|████▍     | 670/1500 [2:35:28<3:12:33, 13.92s/it] 45%|████▍     | 671/1500 [2:35:42<3:12:18, 13.92s/it] 45%|████▍     | 672/1500 [2:35:56<3:12:04, 13.92s/it] 45%|████▍     | 673/1500 [2:36:10<3:11:49, 13.92s/it] 45%|████▍     | 674/1500 [2:36:24<3:11:35, 13.92s/it] 45%|████▌     | 675/1500 [2:36:38<3:11:20, 13.92s/it] 45%|████▌     | 676/1500 [2:36:52<3:11:06, 13.92s/it] 45%|████▌     | 677/1500 [2:37:06<3:10:52, 13.92s/it] 45%|████▌     | 678/1500 [2:37:20<3:10:39, 13.92s/it] 45%|████▌     | 679/1500 [2:37:34<3:10:24, 13.92s/it] 45%|████▌     | 680/1500 [2:37:48<3:10:11, 13.92s/it]                                                      {'loss': 0.0069, 'learning_rate': 0.0054666666666666665, 'epoch': 1.61}
 45%|████▌     | 680/1500 [2:37:48<3:10:11, 13.92s/it] 45%|████▌     | 681/1500 [2:38:01<3:09:58, 13.92s/it] 45%|████▌     | 682/1500 [2:38:15<3:09:44, 13.92s/it] 46%|████▌     | 683/1500 [2:38:29<3:09:32, 13.92s/it] 46%|████▌     | 684/1500 [2:38:43<3:09:18, 13.92s/it] 46%|████▌     | 685/1500 [2:38:57<3:09:04, 13.92s/it] 46%|████▌     | 686/1500 [2:39:11<3:08:49, 13.92s/it] 46%|████▌     | 687/1500 [2:39:25<3:08:37, 13.92s/it] 46%|████▌     | 688/1500 [2:39:39<3:08:27, 13.93s/it] 46%|████▌     | 689/1500 [2:39:53<3:08:12, 13.92s/it] 46%|████▌     | 690/1500 [2:40:07<3:07:57, 13.92s/it]                                                      {'loss': 0.0091, 'learning_rate': 0.0054, 'epoch': 1.64}
 46%|████▌     | 690/1500 [2:40:07<3:07:57, 13.92s/it] 46%|████▌     | 691/1500 [2:40:21<3:07:42, 13.92s/it] 46%|████▌     | 692/1500 [2:40:35<3:07:31, 13.93s/it] 46%|████▌     | 693/1500 [2:40:49<3:07:21, 13.93s/it] 46%|████▋     | 694/1500 [2:41:02<3:07:03, 13.93s/it] 46%|████▋     | 695/1500 [2:41:16<3:06:47, 13.92s/it] 46%|████▋     | 696/1500 [2:41:30<3:06:32, 13.92s/it] 46%|████▋     | 697/1500 [2:41:44<3:06:18, 13.92s/it] 47%|████▋     | 698/1500 [2:41:58<3:06:05, 13.92s/it] 47%|████▋     | 699/1500 [2:42:12<3:05:53, 13.92s/it] 47%|████▋     | 700/1500 [2:42:26<3:05:43, 13.93s/it]                                                      {'loss': 0.0112, 'learning_rate': 0.005333333333333333, 'epoch': 1.66}
 47%|████▋     | 700/1500 [2:42:26<3:05:43, 13.93s/it] 47%|████▋     | 701/1500 [2:42:40<3:05:26, 13.93s/it] 47%|████▋     | 702/1500 [2:42:54<3:05:11, 13.92s/it] 47%|████▋     | 703/1500 [2:43:08<3:04:57, 13.92s/it] 47%|████▋     | 704/1500 [2:43:22<3:04:44, 13.92s/it] 47%|████▋     | 705/1500 [2:43:36<3:04:28, 13.92s/it] 47%|████▋     | 706/1500 [2:43:50<3:04:16, 13.93s/it] 47%|████▋     | 707/1500 [2:44:03<3:04:04, 13.93s/it] 47%|████▋     | 708/1500 [2:44:17<3:03:47, 13.92s/it] 47%|████▋     | 709/1500 [2:44:31<3:03:30, 13.92s/it] 47%|████▋     | 710/1500 [2:44:45<3:03:14, 13.92s/it]                                                      {'loss': 0.0076, 'learning_rate': 0.005266666666666666, 'epoch': 1.68}
 47%|████▋     | 710/1500 [2:44:45<3:03:14, 13.92s/it] 47%|████▋     | 711/1500 [2:44:59<3:02:58, 13.91s/it] 47%|████▋     | 712/1500 [2:45:13<3:02:45, 13.92s/it] 48%|████▊     | 713/1500 [2:45:27<3:02:31, 13.92s/it] 48%|████▊     | 714/1500 [2:45:41<3:02:17, 13.91s/it] 48%|████▊     | 715/1500 [2:45:55<3:02:01, 13.91s/it] 48%|████▊     | 716/1500 [2:46:09<3:01:48, 13.91s/it] 48%|████▊     | 717/1500 [2:46:23<3:01:33, 13.91s/it] 48%|████▊     | 718/1500 [2:46:37<3:01:18, 13.91s/it] 48%|████▊     | 719/1500 [2:46:50<3:01:05, 13.91s/it] 48%|████▊     | 720/1500 [2:47:04<3:00:52, 13.91s/it]                                                      {'loss': 0.0103, 'learning_rate': 0.005200000000000001, 'epoch': 1.71}
 48%|████▊     | 720/1500 [2:47:04<3:00:52, 13.91s/it] 48%|████▊     | 721/1500 [2:47:18<3:00:41, 13.92s/it] 48%|████▊     | 722/1500 [2:47:32<3:00:28, 13.92s/it] 48%|████▊     | 723/1500 [2:47:46<3:00:14, 13.92s/it] 48%|████▊     | 724/1500 [2:48:00<2:59:59, 13.92s/it] 48%|████▊     | 725/1500 [2:48:14<2:59:43, 13.91s/it] 48%|████▊     | 726/1500 [2:48:28<2:59:30, 13.91s/it] 48%|████▊     | 727/1500 [2:48:42<2:59:15, 13.91s/it] 49%|████▊     | 728/1500 [2:48:56<2:59:02, 13.91s/it] 49%|████▊     | 729/1500 [2:49:10<2:58:53, 13.92s/it] 49%|████▊     | 730/1500 [2:49:24<2:58:38, 13.92s/it]                                                      {'loss': 0.0098, 'learning_rate': 0.0051333333333333335, 'epoch': 1.73}
 49%|████▊     | 730/1500 [2:49:24<2:58:38, 13.92s/it] 49%|████▊     | 731/1500 [2:49:37<2:58:23, 13.92s/it] 49%|████▉     | 732/1500 [2:49:51<2:58:07, 13.92s/it] 49%|████▉     | 733/1500 [2:50:05<2:57:56, 13.92s/it] 49%|████▉     | 734/1500 [2:50:19<2:57:44, 13.92s/it] 49%|████▉     | 735/1500 [2:50:33<2:57:29, 13.92s/it] 49%|████▉     | 736/1500 [2:50:47<2:57:13, 13.92s/it] 49%|████▉     | 737/1500 [2:51:01<2:56:56, 13.91s/it] 49%|████▉     | 738/1500 [2:51:15<2:56:47, 13.92s/it] 49%|████▉     | 739/1500 [2:51:29<2:56:33, 13.92s/it] 49%|████▉     | 740/1500 [2:51:43<2:56:20, 13.92s/it]                                                      {'loss': 0.0106, 'learning_rate': 0.005066666666666667, 'epoch': 1.76}
 49%|████▉     | 740/1500 [2:51:43<2:56:20, 13.92s/it] 49%|████▉     | 741/1500 [2:51:57<2:56:05, 13.92s/it] 49%|████▉     | 742/1500 [2:52:11<2:55:50, 13.92s/it] 50%|████▉     | 743/1500 [2:52:24<2:55:37, 13.92s/it] 50%|████▉     | 744/1500 [2:52:38<2:55:21, 13.92s/it] 50%|████▉     | 745/1500 [2:52:52<2:55:07, 13.92s/it] 50%|████▉     | 746/1500 [2:53:06<2:54:53, 13.92s/it] 50%|████▉     | 747/1500 [2:53:20<2:54:38, 13.92s/it] 50%|████▉     | 748/1500 [2:53:34<2:54:27, 13.92s/it] 50%|████▉     | 749/1500 [2:53:48<2:54:13, 13.92s/it] 50%|█████     | 750/1500 [2:54:02<2:53:58, 13.92s/it]                                                      {'loss': 0.0081, 'learning_rate': 0.005, 'epoch': 1.78}
 50%|█████     | 750/1500 [2:54:02<2:53:58, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 06:41:15,408 >> Configuration saved in ../../model/classifier/checkpoint-750/config.json
[INFO|configuration_utils.py:364] 2023-08-27 06:41:15,408 >> Configuration saved in ../../model/classifier/checkpoint-750/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 06:41:15,415 >> Model weights saved in ../../model/classifier/checkpoint-750/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 06:41:15,415 >> tokenizer config file saved in ../../model/classifier/checkpoint-750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 06:41:15,416 >> Special tokens file saved in ../../model/classifier/checkpoint-750/special_tokens_map.json
 50%|█████     | 751/1500 [2:54:16<2:53:48, 13.92s/it] 50%|█████     | 752/1500 [2:54:30<2:53:31, 13.92s/it] 50%|█████     | 753/1500 [2:54:44<2:53:18, 13.92s/it] 50%|█████     | 754/1500 [2:54:58<2:53:04, 13.92s/it] 50%|█████     | 755/1500 [2:55:11<2:52:49, 13.92s/it] 50%|█████     | 756/1500 [2:55:25<2:52:36, 13.92s/it] 50%|█████     | 757/1500 [2:55:39<2:52:21, 13.92s/it] 51%|█████     | 758/1500 [2:55:53<2:52:07, 13.92s/it] 51%|█████     | 759/1500 [2:56:07<2:51:54, 13.92s/it] 51%|█████     | 760/1500 [2:56:21<2:51:39, 13.92s/it]                                                      {'loss': 0.0074, 'learning_rate': 0.004933333333333334, 'epoch': 1.8}
 51%|█████     | 760/1500 [2:56:21<2:51:39, 13.92s/it] 51%|█████     | 761/1500 [2:56:35<2:51:27, 13.92s/it] 51%|█████     | 762/1500 [2:56:49<2:51:14, 13.92s/it] 51%|█████     | 763/1500 [2:57:03<2:50:59, 13.92s/it] 51%|█████     | 764/1500 [2:57:17<2:50:46, 13.92s/it] 51%|█████     | 765/1500 [2:57:31<2:50:30, 13.92s/it] 51%|█████     | 766/1500 [2:57:45<2:50:16, 13.92s/it] 51%|█████     | 767/1500 [2:57:59<2:50:01, 13.92s/it] 51%|█████     | 768/1500 [2:58:12<2:49:46, 13.92s/it] 51%|█████▏    | 769/1500 [2:58:26<2:49:33, 13.92s/it] 51%|█████▏    | 770/1500 [2:58:40<2:49:20, 13.92s/it]                                                      {'loss': 0.011, 'learning_rate': 0.004866666666666667, 'epoch': 1.83}
 51%|█████▏    | 770/1500 [2:58:40<2:49:20, 13.92s/it] 51%|█████▏    | 771/1500 [2:58:54<2:49:09, 13.92s/it] 51%|█████▏    | 772/1500 [2:59:08<2:48:56, 13.92s/it] 52%|█████▏    | 773/1500 [2:59:22<2:48:40, 13.92s/it] 52%|█████▏    | 774/1500 [2:59:36<2:48:26, 13.92s/it] 52%|█████▏    | 775/1500 [2:59:50<2:48:15, 13.92s/it] 52%|█████▏    | 776/1500 [3:00:04<2:48:03, 13.93s/it] 52%|█████▏    | 777/1500 [3:00:18<2:47:47, 13.92s/it] 52%|█████▏    | 778/1500 [3:00:32<2:47:32, 13.92s/it] 52%|█████▏    | 779/1500 [3:00:46<2:47:18, 13.92s/it] 52%|█████▏    | 780/1500 [3:01:00<2:47:03, 13.92s/it]                                                      {'loss': 0.0095, 'learning_rate': 0.0048, 'epoch': 1.85}
 52%|█████▏    | 780/1500 [3:01:00<2:47:03, 13.92s/it] 52%|█████▏    | 781/1500 [3:01:13<2:46:49, 13.92s/it] 52%|█████▏    | 782/1500 [3:01:27<2:46:35, 13.92s/it] 52%|█████▏    | 783/1500 [3:01:41<2:46:22, 13.92s/it] 52%|█████▏    | 784/1500 [3:01:55<2:46:08, 13.92s/it] 52%|█████▏    | 785/1500 [3:02:09<2:45:56, 13.93s/it] 52%|█████▏    | 786/1500 [3:02:23<2:45:42, 13.92s/it] 52%|█████▏    | 787/1500 [3:02:37<2:45:28, 13.93s/it] 53%|█████▎    | 788/1500 [3:02:51<2:45:14, 13.93s/it] 53%|█████▎    | 789/1500 [3:03:05<2:45:00, 13.92s/it] 53%|█████▎    | 790/1500 [3:03:19<2:44:45, 13.92s/it]                                                      {'loss': 0.009, 'learning_rate': 0.004733333333333333, 'epoch': 1.87}
 53%|█████▎    | 790/1500 [3:03:19<2:44:45, 13.92s/it] 53%|█████▎    | 791/1500 [3:03:33<2:44:30, 13.92s/it] 53%|█████▎    | 792/1500 [3:03:47<2:44:16, 13.92s/it] 53%|█████▎    | 793/1500 [3:04:01<2:44:04, 13.92s/it] 53%|█████▎    | 794/1500 [3:04:14<2:43:50, 13.92s/it] 53%|█████▎    | 795/1500 [3:04:28<2:43:36, 13.92s/it] 53%|█████▎    | 796/1500 [3:04:42<2:43:22, 13.92s/it] 53%|█████▎    | 797/1500 [3:04:56<2:43:06, 13.92s/it] 53%|█████▎    | 798/1500 [3:05:10<2:42:52, 13.92s/it] 53%|█████▎    | 799/1500 [3:05:24<2:42:41, 13.93s/it] 53%|█████▎    | 800/1500 [3:05:38<2:42:28, 13.93s/it]                                                      {'loss': 0.0061, 'learning_rate': 0.004666666666666667, 'epoch': 1.9}
 53%|█████▎    | 800/1500 [3:05:38<2:42:28, 13.93s/it] 53%|█████▎    | 801/1500 [3:05:52<2:42:16, 13.93s/it] 53%|█████▎    | 802/1500 [3:06:06<2:42:00, 13.93s/it] 54%|█████▎    | 803/1500 [3:06:20<2:41:45, 13.92s/it] 54%|█████▎    | 804/1500 [3:06:34<2:41:32, 13.93s/it] 54%|█████▎    | 805/1500 [3:06:48<2:41:17, 13.92s/it] 54%|█████▎    | 806/1500 [3:07:02<2:41:01, 13.92s/it] 54%|█████▍    | 807/1500 [3:07:15<2:40:50, 13.93s/it] 54%|█████▍    | 808/1500 [3:07:29<2:40:36, 13.93s/it] 54%|█████▍    | 809/1500 [3:07:43<2:40:22, 13.93s/it] 54%|█████▍    | 810/1500 [3:07:57<2:40:07, 13.92s/it]                                                      {'loss': 0.0084, 'learning_rate': 0.0046, 'epoch': 1.92}
 54%|█████▍    | 810/1500 [3:07:57<2:40:07, 13.92s/it] 54%|█████▍    | 811/1500 [3:08:11<2:39:51, 13.92s/it] 54%|█████▍    | 812/1500 [3:08:25<2:39:36, 13.92s/it] 54%|█████▍    | 813/1500 [3:08:39<2:39:22, 13.92s/it] 54%|█████▍    | 814/1500 [3:08:53<2:39:09, 13.92s/it] 54%|█████▍    | 815/1500 [3:09:07<2:38:56, 13.92s/it] 54%|█████▍    | 816/1500 [3:09:21<2:38:41, 13.92s/it] 54%|█████▍    | 817/1500 [3:09:35<2:38:27, 13.92s/it] 55%|█████▍    | 818/1500 [3:09:49<2:38:14, 13.92s/it] 55%|█████▍    | 819/1500 [3:10:03<2:38:00, 13.92s/it] 55%|█████▍    | 820/1500 [3:10:16<2:37:45, 13.92s/it]                                                      {'loss': 0.007, 'learning_rate': 0.004533333333333333, 'epoch': 1.95}
 55%|█████▍    | 820/1500 [3:10:16<2:37:45, 13.92s/it] 55%|█████▍    | 821/1500 [3:10:30<2:37:30, 13.92s/it] 55%|█████▍    | 822/1500 [3:10:44<2:37:15, 13.92s/it] 55%|█████▍    | 823/1500 [3:10:58<2:37:01, 13.92s/it] 55%|█████▍    | 824/1500 [3:11:12<2:36:48, 13.92s/it] 55%|█████▌    | 825/1500 [3:11:26<2:36:36, 13.92s/it] 55%|█████▌    | 826/1500 [3:11:40<2:36:22, 13.92s/it] 55%|█████▌    | 827/1500 [3:11:54<2:36:08, 13.92s/it] 55%|█████▌    | 828/1500 [3:12:08<2:35:55, 13.92s/it] 55%|█████▌    | 829/1500 [3:12:22<2:35:44, 13.93s/it] 55%|█████▌    | 830/1500 [3:12:36<2:35:32, 13.93s/it]                                                      {'loss': 0.0066, 'learning_rate': 0.0044666666666666665, 'epoch': 1.97}
 55%|█████▌    | 830/1500 [3:12:36<2:35:32, 13.93s/it] 55%|█████▌    | 831/1500 [3:12:50<2:35:20, 13.93s/it] 55%|█████▌    | 832/1500 [3:13:04<2:35:10, 13.94s/it] 56%|█████▌    | 833/1500 [3:13:17<2:34:54, 13.94s/it] 56%|█████▌    | 834/1500 [3:13:31<2:34:38, 13.93s/it] 56%|█████▌    | 835/1500 [3:13:45<2:34:24, 13.93s/it] 56%|█████▌    | 836/1500 [3:13:59<2:34:09, 13.93s/it] 56%|█████▌    | 837/1500 [3:14:13<2:33:56, 13.93s/it] 56%|█████▌    | 838/1500 [3:14:27<2:33:40, 13.93s/it] 56%|█████▌    | 839/1500 [3:14:41<2:33:25, 13.93s/it] 56%|█████▌    | 840/1500 [3:14:55<2:33:12, 13.93s/it]                                                      {'loss': 0.0105, 'learning_rate': 0.0044, 'epoch': 1.99}
 56%|█████▌    | 840/1500 [3:14:55<2:33:12, 13.93s/it] 56%|█████▌    | 841/1500 [3:15:09<2:32:57, 13.93s/it] 56%|█████▌    | 842/1500 [3:15:23<2:32:42, 13.92s/it] 56%|█████▌    | 843/1500 [3:15:36<2:29:53, 13.69s/it] 56%|█████▋    | 844/1500 [3:15:50<2:30:25, 13.76s/it] 56%|█████▋    | 845/1500 [3:16:04<2:30:43, 13.81s/it] 56%|█████▋    | 846/1500 [3:16:18<2:30:53, 13.84s/it] 56%|█████▋    | 847/1500 [3:16:32<2:30:54, 13.87s/it] 57%|█████▋    | 848/1500 [3:16:46<2:30:54, 13.89s/it] 57%|█████▋    | 849/1500 [3:17:00<2:30:50, 13.90s/it] 57%|█████▋    | 850/1500 [3:17:13<2:30:45, 13.92s/it]                                                      {'loss': 0.007, 'learning_rate': 0.004333333333333334, 'epoch': 2.02}
 57%|█████▋    | 850/1500 [3:17:13<2:30:45, 13.92s/it] 57%|█████▋    | 851/1500 [3:17:27<2:30:35, 13.92s/it] 57%|█████▋    | 852/1500 [3:17:41<2:30:20, 13.92s/it] 57%|█████▋    | 853/1500 [3:17:55<2:30:07, 13.92s/it] 57%|█████▋    | 854/1500 [3:18:09<2:29:55, 13.93s/it] 57%|█████▋    | 855/1500 [3:18:23<2:29:45, 13.93s/it] 57%|█████▋    | 856/1500 [3:18:37<2:29:30, 13.93s/it] 57%|█████▋    | 857/1500 [3:18:51<2:29:15, 13.93s/it] 57%|█████▋    | 858/1500 [3:19:05<2:29:03, 13.93s/it] 57%|█████▋    | 859/1500 [3:19:19<2:28:48, 13.93s/it] 57%|█████▋    | 860/1500 [3:19:33<2:28:33, 13.93s/it]                                                      {'loss': 0.0064, 'learning_rate': 0.004266666666666667, 'epoch': 2.04}
 57%|█████▋    | 860/1500 [3:19:33<2:28:33, 13.93s/it] 57%|█████▋    | 861/1500 [3:19:47<2:28:22, 13.93s/it] 57%|█████▋    | 862/1500 [3:20:01<2:28:07, 13.93s/it] 58%|█████▊    | 863/1500 [3:20:15<2:27:52, 13.93s/it] 58%|█████▊    | 864/1500 [3:20:28<2:27:38, 13.93s/it] 58%|█████▊    | 865/1500 [3:20:42<2:27:24, 13.93s/it] 58%|█████▊    | 866/1500 [3:20:56<2:27:09, 13.93s/it] 58%|█████▊    | 867/1500 [3:21:10<2:26:54, 13.93s/it] 58%|█████▊    | 868/1500 [3:21:24<2:26:40, 13.93s/it] 58%|█████▊    | 869/1500 [3:21:38<2:26:29, 13.93s/it] 58%|█████▊    | 870/1500 [3:21:52<2:26:17, 13.93s/it]                                                      {'loss': 0.0074, 'learning_rate': 0.0042, 'epoch': 2.06}
 58%|█████▊    | 870/1500 [3:21:52<2:26:17, 13.93s/it] 58%|█████▊    | 871/1500 [3:22:06<2:26:04, 13.93s/it] 58%|█████▊    | 872/1500 [3:22:20<2:25:51, 13.94s/it] 58%|█████▊    | 873/1500 [3:22:34<2:25:38, 13.94s/it] 58%|█████▊    | 874/1500 [3:22:48<2:25:24, 13.94s/it] 58%|█████▊    | 875/1500 [3:23:02<2:25:07, 13.93s/it] 58%|█████▊    | 876/1500 [3:23:16<2:24:52, 13.93s/it] 58%|█████▊    | 877/1500 [3:23:30<2:24:38, 13.93s/it] 59%|█████▊    | 878/1500 [3:23:44<2:24:26, 13.93s/it] 59%|█████▊    | 879/1500 [3:23:57<2:24:12, 13.93s/it] 59%|█████▊    | 880/1500 [3:24:11<2:23:58, 13.93s/it]                                                      {'loss': 0.0082, 'learning_rate': 0.0041333333333333335, 'epoch': 2.09}
 59%|█████▊    | 880/1500 [3:24:11<2:23:58, 13.93s/it] 59%|█████▊    | 881/1500 [3:24:25<2:23:41, 13.93s/it] 59%|█████▉    | 882/1500 [3:24:39<2:23:26, 13.93s/it] 59%|█████▉    | 883/1500 [3:24:53<2:23:12, 13.93s/it] 59%|█████▉    | 884/1500 [3:25:07<2:22:59, 13.93s/it] 59%|█████▉    | 885/1500 [3:25:21<2:22:44, 13.93s/it] 59%|█████▉    | 886/1500 [3:25:35<2:22:28, 13.92s/it] 59%|█████▉    | 887/1500 [3:25:49<2:22:14, 13.92s/it] 59%|█████▉    | 888/1500 [3:26:03<2:21:59, 13.92s/it] 59%|█████▉    | 889/1500 [3:26:17<2:21:46, 13.92s/it] 59%|█████▉    | 890/1500 [3:26:31<2:21:31, 13.92s/it]                                                      {'loss': 0.0073, 'learning_rate': 0.004066666666666667, 'epoch': 2.11}
 59%|█████▉    | 890/1500 [3:26:31<2:21:31, 13.92s/it] 59%|█████▉    | 891/1500 [3:26:45<2:21:16, 13.92s/it] 59%|█████▉    | 892/1500 [3:26:58<2:21:01, 13.92s/it] 60%|█████▉    | 893/1500 [3:27:12<2:20:47, 13.92s/it] 60%|█████▉    | 894/1500 [3:27:26<2:20:33, 13.92s/it] 60%|█████▉    | 895/1500 [3:27:40<2:20:20, 13.92s/it] 60%|█████▉    | 896/1500 [3:27:54<2:20:06, 13.92s/it] 60%|█████▉    | 897/1500 [3:28:08<2:19:53, 13.92s/it] 60%|█████▉    | 898/1500 [3:28:22<2:19:39, 13.92s/it] 60%|█████▉    | 899/1500 [3:28:36<2:19:25, 13.92s/it] 60%|██████    | 900/1500 [3:28:50<2:19:10, 13.92s/it]                                                      {'loss': 0.0083, 'learning_rate': 0.004, 'epoch': 2.14}
 60%|██████    | 900/1500 [3:28:50<2:19:10, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 07:16:03,308 >> Configuration saved in ../../model/classifier/checkpoint-900/config.json
[INFO|configuration_utils.py:364] 2023-08-27 07:16:03,308 >> Configuration saved in ../../model/classifier/checkpoint-900/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 07:16:03,313 >> Model weights saved in ../../model/classifier/checkpoint-900/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 07:16:03,314 >> tokenizer config file saved in ../../model/classifier/checkpoint-900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 07:16:03,314 >> Special tokens file saved in ../../model/classifier/checkpoint-900/special_tokens_map.json
 60%|██████    | 901/1500 [3:29:04<2:18:59, 13.92s/it] 60%|██████    | 902/1500 [3:29:18<2:18:47, 13.93s/it] 60%|██████    | 903/1500 [3:29:32<2:18:35, 13.93s/it] 60%|██████    | 904/1500 [3:29:46<2:18:22, 13.93s/it] 60%|██████    | 905/1500 [3:29:59<2:18:06, 13.93s/it] 60%|██████    | 906/1500 [3:30:13<2:17:51, 13.93s/it] 60%|██████    | 907/1500 [3:30:27<2:17:35, 13.92s/it] 61%|██████    | 908/1500 [3:30:41<2:17:19, 13.92s/it] 61%|██████    | 909/1500 [3:30:55<2:17:04, 13.92s/it] 61%|██████    | 910/1500 [3:31:09<2:16:51, 13.92s/it]                                                      {'loss': 0.0067, 'learning_rate': 0.003933333333333333, 'epoch': 2.16}
 61%|██████    | 910/1500 [3:31:09<2:16:51, 13.92s/it] 61%|██████    | 911/1500 [3:31:23<2:16:36, 13.92s/it] 61%|██████    | 912/1500 [3:31:37<2:16:23, 13.92s/it] 61%|██████    | 913/1500 [3:31:51<2:16:09, 13.92s/it] 61%|██████    | 914/1500 [3:32:05<2:15:57, 13.92s/it] 61%|██████    | 915/1500 [3:32:19<2:15:44, 13.92s/it] 61%|██████    | 916/1500 [3:32:33<2:15:30, 13.92s/it] 61%|██████    | 917/1500 [3:32:46<2:15:16, 13.92s/it] 61%|██████    | 918/1500 [3:33:00<2:15:02, 13.92s/it] 61%|██████▏   | 919/1500 [3:33:14<2:14:50, 13.92s/it] 61%|██████▏   | 920/1500 [3:33:28<2:14:36, 13.93s/it]                                                      {'loss': 0.0061, 'learning_rate': 0.0038666666666666667, 'epoch': 2.18}
 61%|██████▏   | 920/1500 [3:33:28<2:14:36, 13.93s/it] 61%|██████▏   | 921/1500 [3:33:42<2:14:22, 13.92s/it] 61%|██████▏   | 922/1500 [3:33:56<2:14:07, 13.92s/it] 62%|██████▏   | 923/1500 [3:34:10<2:13:52, 13.92s/it] 62%|██████▏   | 924/1500 [3:34:24<2:13:40, 13.92s/it] 62%|██████▏   | 925/1500 [3:34:38<2:13:28, 13.93s/it] 62%|██████▏   | 926/1500 [3:34:52<2:13:12, 13.92s/it] 62%|██████▏   | 927/1500 [3:35:06<2:12:58, 13.92s/it] 62%|██████▏   | 928/1500 [3:35:20<2:12:44, 13.92s/it] 62%|██████▏   | 929/1500 [3:35:34<2:12:29, 13.92s/it] 62%|██████▏   | 930/1500 [3:35:47<2:12:15, 13.92s/it]                                                      {'loss': 0.0066, 'learning_rate': 0.0038, 'epoch': 2.21}
 62%|██████▏   | 930/1500 [3:35:47<2:12:15, 13.92s/it] 62%|██████▏   | 931/1500 [3:36:01<2:12:00, 13.92s/it] 62%|██████▏   | 932/1500 [3:36:15<2:11:46, 13.92s/it] 62%|██████▏   | 933/1500 [3:36:29<2:11:31, 13.92s/it] 62%|██████▏   | 934/1500 [3:36:43<2:11:16, 13.92s/it] 62%|██████▏   | 935/1500 [3:36:57<2:11:03, 13.92s/it] 62%|██████▏   | 936/1500 [3:37:11<2:10:48, 13.92s/it] 62%|██████▏   | 937/1500 [3:37:25<2:10:36, 13.92s/it] 63%|██████▎   | 938/1500 [3:37:39<2:10:24, 13.92s/it] 63%|██████▎   | 939/1500 [3:37:53<2:10:10, 13.92s/it] 63%|██████▎   | 940/1500 [3:38:07<2:09:55, 13.92s/it]                                                      {'loss': 0.0057, 'learning_rate': 0.0037333333333333337, 'epoch': 2.23}
 63%|██████▎   | 940/1500 [3:38:07<2:09:55, 13.92s/it] 63%|██████▎   | 941/1500 [3:38:21<2:09:39, 13.92s/it] 63%|██████▎   | 942/1500 [3:38:34<2:09:26, 13.92s/it] 63%|██████▎   | 943/1500 [3:38:48<2:09:11, 13.92s/it] 63%|██████▎   | 944/1500 [3:39:02<2:08:58, 13.92s/it] 63%|██████▎   | 945/1500 [3:39:16<2:08:43, 13.92s/it] 63%|██████▎   | 946/1500 [3:39:30<2:08:30, 13.92s/it] 63%|██████▎   | 947/1500 [3:39:44<2:08:14, 13.91s/it] 63%|██████▎   | 948/1500 [3:39:58<2:08:01, 13.92s/it] 63%|██████▎   | 949/1500 [3:40:12<2:07:47, 13.91s/it] 63%|██████▎   | 950/1500 [3:40:26<2:07:32, 13.91s/it]                                                      {'loss': 0.0076, 'learning_rate': 0.0036666666666666666, 'epoch': 2.25}
 63%|██████▎   | 950/1500 [3:40:26<2:07:32, 13.91s/it] 63%|██████▎   | 951/1500 [3:40:40<2:07:19, 13.91s/it] 63%|██████▎   | 952/1500 [3:40:54<2:07:05, 13.91s/it] 64%|██████▎   | 953/1500 [3:41:08<2:06:51, 13.91s/it] 64%|██████▎   | 954/1500 [3:41:21<2:06:37, 13.91s/it] 64%|██████▎   | 955/1500 [3:41:35<2:06:23, 13.91s/it] 64%|██████▎   | 956/1500 [3:41:49<2:06:10, 13.92s/it] 64%|██████▍   | 957/1500 [3:42:03<2:05:57, 13.92s/it] 64%|██████▍   | 958/1500 [3:42:17<2:05:44, 13.92s/it] 64%|██████▍   | 959/1500 [3:42:31<2:05:29, 13.92s/it] 64%|██████▍   | 960/1500 [3:42:45<2:05:16, 13.92s/it]                                                      {'loss': 0.0079, 'learning_rate': 0.0036, 'epoch': 2.28}
 64%|██████▍   | 960/1500 [3:42:45<2:05:16, 13.92s/it] 64%|██████▍   | 961/1500 [3:42:59<2:05:04, 13.92s/it] 64%|██████▍   | 962/1500 [3:43:13<2:04:49, 13.92s/it] 64%|██████▍   | 963/1500 [3:43:27<2:04:34, 13.92s/it] 64%|██████▍   | 964/1500 [3:43:41<2:04:21, 13.92s/it] 64%|██████▍   | 965/1500 [3:43:55<2:04:07, 13.92s/it] 64%|██████▍   | 966/1500 [3:44:09<2:03:56, 13.93s/it] 64%|██████▍   | 967/1500 [3:44:22<2:03:42, 13.93s/it] 65%|██████▍   | 968/1500 [3:44:36<2:03:28, 13.93s/it] 65%|██████▍   | 969/1500 [3:44:50<2:03:14, 13.93s/it] 65%|██████▍   | 970/1500 [3:45:04<2:02:59, 13.92s/it]                                                      {'loss': 0.0094, 'learning_rate': 0.003533333333333333, 'epoch': 2.3}
 65%|██████▍   | 970/1500 [3:45:04<2:02:59, 13.92s/it] 65%|██████▍   | 971/1500 [3:45:18<2:02:44, 13.92s/it] 65%|██████▍   | 972/1500 [3:45:32<2:02:28, 13.92s/it] 65%|██████▍   | 973/1500 [3:45:46<2:02:14, 13.92s/it] 65%|██████▍   | 974/1500 [3:46:00<2:02:01, 13.92s/it] 65%|██████▌   | 975/1500 [3:46:14<2:01:48, 13.92s/it] 65%|██████▌   | 976/1500 [3:46:28<2:01:34, 13.92s/it] 65%|██████▌   | 977/1500 [3:46:42<2:01:21, 13.92s/it] 65%|██████▌   | 978/1500 [3:46:56<2:01:07, 13.92s/it] 65%|██████▌   | 979/1500 [3:47:10<2:00:53, 13.92s/it] 65%|██████▌   | 980/1500 [3:47:23<2:00:37, 13.92s/it]                                                      {'loss': 0.0085, 'learning_rate': 0.003466666666666667, 'epoch': 2.33}
 65%|██████▌   | 980/1500 [3:47:23<2:00:37, 13.92s/it] 65%|██████▌   | 981/1500 [3:47:37<2:00:22, 13.92s/it] 65%|██████▌   | 982/1500 [3:47:51<2:00:09, 13.92s/it] 66%|██████▌   | 983/1500 [3:48:05<1:59:56, 13.92s/it] 66%|██████▌   | 984/1500 [3:48:19<1:59:42, 13.92s/it] 66%|██████▌   | 985/1500 [3:48:33<1:59:30, 13.92s/it] 66%|██████▌   | 986/1500 [3:48:47<1:59:17, 13.92s/it] 66%|██████▌   | 987/1500 [3:49:01<1:59:02, 13.92s/it] 66%|██████▌   | 988/1500 [3:49:15<1:58:47, 13.92s/it] 66%|██████▌   | 989/1500 [3:49:29<1:58:32, 13.92s/it] 66%|██████▌   | 990/1500 [3:49:43<1:58:19, 13.92s/it]                                                      {'loss': 0.0065, 'learning_rate': 0.0034000000000000002, 'epoch': 2.35}
 66%|██████▌   | 990/1500 [3:49:43<1:58:19, 13.92s/it] 66%|██████▌   | 991/1500 [3:49:57<1:58:04, 13.92s/it] 66%|██████▌   | 992/1500 [3:50:10<1:57:50, 13.92s/it] 66%|██████▌   | 993/1500 [3:50:24<1:57:36, 13.92s/it] 66%|██████▋   | 994/1500 [3:50:38<1:57:22, 13.92s/it] 66%|██████▋   | 995/1500 [3:50:52<1:57:09, 13.92s/it] 66%|██████▋   | 996/1500 [3:51:06<1:56:54, 13.92s/it] 66%|██████▋   | 997/1500 [3:51:20<1:56:40, 13.92s/it] 67%|██████▋   | 998/1500 [3:51:34<1:56:27, 13.92s/it] 67%|██████▋   | 999/1500 [3:51:48<1:56:15, 13.92s/it] 67%|██████▋   | 1000/1500 [3:52:02<1:56:01, 13.92s/it]                                                       {'loss': 0.0066, 'learning_rate': 0.003333333333333333, 'epoch': 2.37}
 67%|██████▋   | 1000/1500 [3:52:02<1:56:01, 13.92s/it] 67%|██████▋   | 1001/1500 [3:52:16<1:55:48, 13.92s/it] 67%|██████▋   | 1002/1500 [3:52:30<1:55:33, 13.92s/it] 67%|██████▋   | 1003/1500 [3:52:44<1:55:19, 13.92s/it] 67%|██████▋   | 1004/1500 [3:52:58<1:55:06, 13.92s/it] 67%|██████▋   | 1005/1500 [3:53:11<1:54:52, 13.92s/it] 67%|██████▋   | 1006/1500 [3:53:25<1:54:38, 13.92s/it] 67%|██████▋   | 1007/1500 [3:53:39<1:54:24, 13.92s/it] 67%|██████▋   | 1008/1500 [3:53:53<1:54:11, 13.93s/it] 67%|██████▋   | 1009/1500 [3:54:07<1:53:58, 13.93s/it] 67%|██████▋   | 1010/1500 [3:54:21<1:53:42, 13.92s/it]                                                       {'loss': 0.007, 'learning_rate': 0.003266666666666667, 'epoch': 2.4}
 67%|██████▋   | 1010/1500 [3:54:21<1:53:42, 13.92s/it] 67%|██████▋   | 1011/1500 [3:54:35<1:53:27, 13.92s/it] 67%|██████▋   | 1012/1500 [3:54:49<1:53:14, 13.92s/it] 68%|██████▊   | 1013/1500 [3:55:03<1:52:59, 13.92s/it] 68%|██████▊   | 1014/1500 [3:55:17<1:52:45, 13.92s/it] 68%|██████▊   | 1015/1500 [3:55:31<1:52:32, 13.92s/it] 68%|██████▊   | 1016/1500 [3:55:45<1:52:18, 13.92s/it] 68%|██████▊   | 1017/1500 [3:55:59<1:52:03, 13.92s/it] 68%|██████▊   | 1018/1500 [3:56:12<1:51:48, 13.92s/it] 68%|██████▊   | 1019/1500 [3:56:26<1:51:34, 13.92s/it] 68%|██████▊   | 1020/1500 [3:56:40<1:51:20, 13.92s/it]                                                       {'loss': 0.0091, 'learning_rate': 0.0032, 'epoch': 2.42}
 68%|██████▊   | 1020/1500 [3:56:40<1:51:20, 13.92s/it] 68%|██████▊   | 1021/1500 [3:56:54<1:51:06, 13.92s/it] 68%|██████▊   | 1022/1500 [3:57:08<1:50:53, 13.92s/it] 68%|██████▊   | 1023/1500 [3:57:22<1:50:39, 13.92s/it] 68%|██████▊   | 1024/1500 [3:57:36<1:50:25, 13.92s/it] 68%|██████▊   | 1025/1500 [3:57:50<1:50:11, 13.92s/it] 68%|██████▊   | 1026/1500 [3:58:04<1:49:58, 13.92s/it] 68%|██████▊   | 1027/1500 [3:58:18<1:49:44, 13.92s/it] 69%|██████▊   | 1028/1500 [3:58:32<1:49:31, 13.92s/it] 69%|██████▊   | 1029/1500 [3:58:46<1:49:18, 13.92s/it] 69%|██████▊   | 1030/1500 [3:59:00<1:49:07, 13.93s/it]                                                       {'loss': 0.0063, 'learning_rate': 0.0031333333333333335, 'epoch': 2.44}
 69%|██████▊   | 1030/1500 [3:59:00<1:49:07, 13.93s/it] 69%|██████▊   | 1031/1500 [3:59:13<1:48:52, 13.93s/it] 69%|██████▉   | 1032/1500 [3:59:27<1:48:38, 13.93s/it] 69%|██████▉   | 1033/1500 [3:59:41<1:48:23, 13.93s/it] 69%|██████▉   | 1034/1500 [3:59:55<1:48:09, 13.93s/it] 69%|██████▉   | 1035/1500 [4:00:09<1:47:55, 13.93s/it] 69%|██████▉   | 1036/1500 [4:00:23<1:47:41, 13.93s/it] 69%|██████▉   | 1037/1500 [4:00:37<1:47:28, 13.93s/it] 69%|██████▉   | 1038/1500 [4:00:51<1:47:15, 13.93s/it] 69%|██████▉   | 1039/1500 [4:01:05<1:47:03, 13.93s/it] 69%|██████▉   | 1040/1500 [4:01:19<1:46:47, 13.93s/it]                                                       {'loss': 0.0075, 'learning_rate': 0.0030666666666666663, 'epoch': 2.47}
 69%|██████▉   | 1040/1500 [4:01:19<1:46:47, 13.93s/it] 69%|██████▉   | 1041/1500 [4:01:33<1:46:33, 13.93s/it] 69%|██████▉   | 1042/1500 [4:01:47<1:46:18, 13.93s/it] 70%|██████▉   | 1043/1500 [4:02:01<1:46:04, 13.93s/it] 70%|██████▉   | 1044/1500 [4:02:14<1:45:49, 13.92s/it] 70%|██████▉   | 1045/1500 [4:02:28<1:45:35, 13.92s/it] 70%|██████▉   | 1046/1500 [4:02:42<1:45:20, 13.92s/it] 70%|██████▉   | 1047/1500 [4:02:56<1:45:05, 13.92s/it] 70%|██████▉   | 1048/1500 [4:03:10<1:44:51, 13.92s/it] 70%|██████▉   | 1049/1500 [4:03:24<1:44:37, 13.92s/it] 70%|███████   | 1050/1500 [4:03:38<1:44:24, 13.92s/it]                                                       {'loss': 0.0075, 'learning_rate': 0.003, 'epoch': 2.49}
 70%|███████   | 1050/1500 [4:03:38<1:44:24, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 07:50:51,513 >> Configuration saved in ../../model/classifier/checkpoint-1050/config.json
[INFO|configuration_utils.py:364] 2023-08-27 07:50:51,513 >> Configuration saved in ../../model/classifier/checkpoint-1050/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 07:50:51,518 >> Model weights saved in ../../model/classifier/checkpoint-1050/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 07:50:51,519 >> tokenizer config file saved in ../../model/classifier/checkpoint-1050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 07:50:51,519 >> Special tokens file saved in ../../model/classifier/checkpoint-1050/special_tokens_map.json
 70%|███████   | 1051/1500 [4:03:52<1:44:13, 13.93s/it] 70%|███████   | 1052/1500 [4:04:06<1:43:59, 13.93s/it] 70%|███████   | 1053/1500 [4:04:20<1:43:44, 13.92s/it] 70%|███████   | 1054/1500 [4:04:34<1:43:30, 13.92s/it] 70%|███████   | 1055/1500 [4:04:48<1:43:15, 13.92s/it] 70%|███████   | 1056/1500 [4:05:02<1:42:59, 13.92s/it] 70%|███████   | 1057/1500 [4:05:15<1:42:45, 13.92s/it] 71%|███████   | 1058/1500 [4:05:29<1:42:30, 13.92s/it] 71%|███████   | 1059/1500 [4:05:43<1:42:17, 13.92s/it] 71%|███████   | 1060/1500 [4:05:57<1:42:03, 13.92s/it]                                                       {'loss': 0.0075, 'learning_rate': 0.0029333333333333334, 'epoch': 2.51}
 71%|███████   | 1060/1500 [4:05:57<1:42:03, 13.92s/it] 71%|███████   | 1061/1500 [4:06:11<1:41:48, 13.92s/it] 71%|███████   | 1062/1500 [4:06:25<1:41:34, 13.91s/it] 71%|███████   | 1063/1500 [4:06:39<1:41:20, 13.91s/it] 71%|███████   | 1064/1500 [4:06:53<1:41:06, 13.91s/it] 71%|███████   | 1065/1500 [4:07:07<1:40:53, 13.92s/it] 71%|███████   | 1066/1500 [4:07:21<1:40:39, 13.92s/it] 71%|███████   | 1067/1500 [4:07:35<1:40:27, 13.92s/it] 71%|███████   | 1068/1500 [4:07:49<1:40:12, 13.92s/it] 71%|███████▏  | 1069/1500 [4:08:02<1:39:58, 13.92s/it] 71%|███████▏  | 1070/1500 [4:08:16<1:39:44, 13.92s/it]                                                       {'loss': 0.0073, 'learning_rate': 0.0028666666666666667, 'epoch': 2.54}
 71%|███████▏  | 1070/1500 [4:08:16<1:39:44, 13.92s/it] 71%|███████▏  | 1071/1500 [4:08:30<1:39:31, 13.92s/it] 71%|███████▏  | 1072/1500 [4:08:44<1:39:16, 13.92s/it] 72%|███████▏  | 1073/1500 [4:08:58<1:39:03, 13.92s/it] 72%|███████▏  | 1074/1500 [4:09:12<1:38:50, 13.92s/it] 72%|███████▏  | 1075/1500 [4:09:26<1:38:38, 13.92s/it] 72%|███████▏  | 1076/1500 [4:09:40<1:38:22, 13.92s/it] 72%|███████▏  | 1077/1500 [4:09:54<1:38:08, 13.92s/it] 72%|███████▏  | 1078/1500 [4:10:08<1:37:53, 13.92s/it] 72%|███████▏  | 1079/1500 [4:10:22<1:37:39, 13.92s/it] 72%|███████▏  | 1080/1500 [4:10:36<1:37:24, 13.92s/it]                                                       {'loss': 0.0076, 'learning_rate': 0.0028000000000000004, 'epoch': 2.56}
 72%|███████▏  | 1080/1500 [4:10:36<1:37:24, 13.92s/it] 72%|███████▏  | 1081/1500 [4:10:49<1:37:10, 13.92s/it] 72%|███████▏  | 1082/1500 [4:11:03<1:36:57, 13.92s/it] 72%|███████▏  | 1083/1500 [4:11:17<1:36:43, 13.92s/it] 72%|███████▏  | 1084/1500 [4:11:31<1:36:29, 13.92s/it] 72%|███████▏  | 1085/1500 [4:11:45<1:36:15, 13.92s/it] 72%|███████▏  | 1086/1500 [4:11:59<1:36:03, 13.92s/it] 72%|███████▏  | 1087/1500 [4:12:13<1:35:49, 13.92s/it] 73%|███████▎  | 1088/1500 [4:12:27<1:35:35, 13.92s/it] 73%|███████▎  | 1089/1500 [4:12:41<1:35:21, 13.92s/it] 73%|███████▎  | 1090/1500 [4:12:55<1:35:08, 13.92s/it]                                                       {'loss': 0.007, 'learning_rate': 0.0027333333333333333, 'epoch': 2.59}
 73%|███████▎  | 1090/1500 [4:12:55<1:35:08, 13.92s/it] 73%|███████▎  | 1091/1500 [4:13:09<1:34:53, 13.92s/it] 73%|███████▎  | 1092/1500 [4:13:23<1:34:38, 13.92s/it] 73%|███████▎  | 1093/1500 [4:13:37<1:34:24, 13.92s/it] 73%|███████▎  | 1094/1500 [4:13:50<1:34:11, 13.92s/it] 73%|███████▎  | 1095/1500 [4:14:04<1:33:57, 13.92s/it] 73%|███████▎  | 1096/1500 [4:14:18<1:33:44, 13.92s/it] 73%|███████▎  | 1097/1500 [4:14:32<1:33:29, 13.92s/it] 73%|███████▎  | 1098/1500 [4:14:46<1:33:15, 13.92s/it] 73%|███████▎  | 1099/1500 [4:15:00<1:33:00, 13.92s/it] 73%|███████▎  | 1100/1500 [4:15:14<1:32:46, 13.92s/it]                                                       {'loss': 0.0079, 'learning_rate': 0.0026666666666666666, 'epoch': 2.61}
 73%|███████▎  | 1100/1500 [4:15:14<1:32:46, 13.92s/it] 73%|███████▎  | 1101/1500 [4:15:28<1:32:33, 13.92s/it] 73%|███████▎  | 1102/1500 [4:15:42<1:32:21, 13.92s/it] 74%|███████▎  | 1103/1500 [4:15:56<1:32:06, 13.92s/it] 74%|███████▎  | 1104/1500 [4:16:10<1:31:51, 13.92s/it] 74%|███████▎  | 1105/1500 [4:16:24<1:31:36, 13.92s/it] 74%|███████▎  | 1106/1500 [4:16:37<1:31:22, 13.92s/it] 74%|███████▍  | 1107/1500 [4:16:51<1:31:08, 13.92s/it] 74%|███████▍  | 1108/1500 [4:17:05<1:30:54, 13.91s/it] 74%|███████▍  | 1109/1500 [4:17:19<1:30:41, 13.92s/it] 74%|███████▍  | 1110/1500 [4:17:33<1:30:27, 13.92s/it]                                                       {'loss': 0.0084, 'learning_rate': 0.0026000000000000003, 'epoch': 2.63}
 74%|███████▍  | 1110/1500 [4:17:33<1:30:27, 13.92s/it] 74%|███████▍  | 1111/1500 [4:17:47<1:30:13, 13.92s/it] 74%|███████▍  | 1112/1500 [4:18:01<1:30:00, 13.92s/it] 74%|███████▍  | 1113/1500 [4:18:15<1:29:47, 13.92s/it] 74%|███████▍  | 1114/1500 [4:18:29<1:29:32, 13.92s/it] 74%|███████▍  | 1115/1500 [4:18:43<1:29:18, 13.92s/it] 74%|███████▍  | 1116/1500 [4:18:57<1:29:05, 13.92s/it] 74%|███████▍  | 1117/1500 [4:19:11<1:28:50, 13.92s/it] 75%|███████▍  | 1118/1500 [4:19:24<1:28:37, 13.92s/it] 75%|███████▍  | 1119/1500 [4:19:38<1:28:23, 13.92s/it] 75%|███████▍  | 1120/1500 [4:19:52<1:28:10, 13.92s/it]                                                       {'loss': 0.007, 'learning_rate': 0.0025333333333333336, 'epoch': 2.66}
 75%|███████▍  | 1120/1500 [4:19:52<1:28:10, 13.92s/it] 75%|███████▍  | 1121/1500 [4:20:06<1:27:56, 13.92s/it] 75%|███████▍  | 1122/1500 [4:20:20<1:27:41, 13.92s/it] 75%|███████▍  | 1123/1500 [4:20:34<1:27:26, 13.92s/it] 75%|███████▍  | 1124/1500 [4:20:48<1:27:12, 13.92s/it] 75%|███████▌  | 1125/1500 [4:21:02<1:26:58, 13.92s/it] 75%|███████▌  | 1126/1500 [4:21:16<1:26:45, 13.92s/it] 75%|███████▌  | 1127/1500 [4:21:30<1:26:33, 13.92s/it] 75%|███████▌  | 1128/1500 [4:21:44<1:26:18, 13.92s/it] 75%|███████▌  | 1129/1500 [4:21:58<1:26:05, 13.92s/it] 75%|███████▌  | 1130/1500 [4:22:12<1:25:51, 13.92s/it]                                                       {'loss': 0.0072, 'learning_rate': 0.002466666666666667, 'epoch': 2.68}
 75%|███████▌  | 1130/1500 [4:22:12<1:25:51, 13.92s/it] 75%|███████▌  | 1131/1500 [4:22:25<1:25:37, 13.92s/it] 75%|███████▌  | 1132/1500 [4:22:39<1:25:22, 13.92s/it] 76%|███████▌  | 1133/1500 [4:22:53<1:25:07, 13.92s/it] 76%|███████▌  | 1134/1500 [4:23:07<1:24:54, 13.92s/it] 76%|███████▌  | 1135/1500 [4:23:21<1:24:40, 13.92s/it] 76%|███████▌  | 1136/1500 [4:23:35<1:24:26, 13.92s/it] 76%|███████▌  | 1137/1500 [4:23:49<1:24:12, 13.92s/it] 76%|███████▌  | 1138/1500 [4:24:03<1:23:57, 13.92s/it] 76%|███████▌  | 1139/1500 [4:24:17<1:23:44, 13.92s/it] 76%|███████▌  | 1140/1500 [4:24:31<1:23:30, 13.92s/it]                                                       {'loss': 0.0068, 'learning_rate': 0.0024, 'epoch': 2.7}
 76%|███████▌  | 1140/1500 [4:24:31<1:23:30, 13.92s/it] 76%|███████▌  | 1141/1500 [4:24:45<1:23:16, 13.92s/it] 76%|███████▌  | 1142/1500 [4:24:59<1:23:03, 13.92s/it] 76%|███████▌  | 1143/1500 [4:25:12<1:22:49, 13.92s/it] 76%|███████▋  | 1144/1500 [4:25:26<1:22:35, 13.92s/it] 76%|███████▋  | 1145/1500 [4:25:40<1:22:22, 13.92s/it] 76%|███████▋  | 1146/1500 [4:25:54<1:22:10, 13.93s/it] 76%|███████▋  | 1147/1500 [4:26:08<1:21:55, 13.93s/it] 77%|███████▋  | 1148/1500 [4:26:22<1:21:41, 13.93s/it] 77%|███████▋  | 1149/1500 [4:26:36<1:21:27, 13.92s/it] 77%|███████▋  | 1150/1500 [4:26:50<1:21:13, 13.92s/it]                                                       {'loss': 0.0083, 'learning_rate': 0.0023333333333333335, 'epoch': 2.73}
 77%|███████▋  | 1150/1500 [4:26:50<1:21:13, 13.92s/it] 77%|███████▋  | 1151/1500 [4:27:04<1:20:59, 13.92s/it] 77%|███████▋  | 1152/1500 [4:27:18<1:20:44, 13.92s/it] 77%|███████▋  | 1153/1500 [4:27:32<1:20:30, 13.92s/it] 77%|███████▋  | 1154/1500 [4:27:46<1:20:16, 13.92s/it] 77%|███████▋  | 1155/1500 [4:28:00<1:20:02, 13.92s/it] 77%|███████▋  | 1156/1500 [4:28:13<1:19:48, 13.92s/it] 77%|███████▋  | 1157/1500 [4:28:27<1:19:34, 13.92s/it] 77%|███████▋  | 1158/1500 [4:28:41<1:19:20, 13.92s/it] 77%|███████▋  | 1159/1500 [4:28:55<1:19:06, 13.92s/it] 77%|███████▋  | 1160/1500 [4:29:09<1:18:53, 13.92s/it]                                                       {'loss': 0.0058, 'learning_rate': 0.0022666666666666664, 'epoch': 2.75}
 77%|███████▋  | 1160/1500 [4:29:09<1:18:53, 13.92s/it] 77%|███████▋  | 1161/1500 [4:29:23<1:18:40, 13.92s/it] 77%|███████▋  | 1162/1500 [4:29:37<1:18:27, 13.93s/it] 78%|███████▊  | 1163/1500 [4:29:51<1:18:13, 13.93s/it] 78%|███████▊  | 1164/1500 [4:30:05<1:18:01, 13.93s/it] 78%|███████▊  | 1165/1500 [4:30:19<1:17:46, 13.93s/it] 78%|███████▊  | 1166/1500 [4:30:33<1:17:32, 13.93s/it] 78%|███████▊  | 1167/1500 [4:30:47<1:17:18, 13.93s/it] 78%|███████▊  | 1168/1500 [4:31:01<1:17:03, 13.93s/it] 78%|███████▊  | 1169/1500 [4:31:15<1:16:50, 13.93s/it] 78%|███████▊  | 1170/1500 [4:31:28<1:16:36, 13.93s/it]                                                       {'loss': 0.009, 'learning_rate': 0.0022, 'epoch': 2.78}
 78%|███████▊  | 1170/1500 [4:31:28<1:16:36, 13.93s/it] 78%|███████▊  | 1171/1500 [4:31:42<1:16:21, 13.92s/it] 78%|███████▊  | 1172/1500 [4:31:56<1:16:06, 13.92s/it] 78%|███████▊  | 1173/1500 [4:32:10<1:15:53, 13.93s/it] 78%|███████▊  | 1174/1500 [4:32:24<1:15:40, 13.93s/it] 78%|███████▊  | 1175/1500 [4:32:38<1:15:25, 13.93s/it] 78%|███████▊  | 1176/1500 [4:32:52<1:15:11, 13.92s/it] 78%|███████▊  | 1177/1500 [4:33:06<1:14:57, 13.92s/it] 79%|███████▊  | 1178/1500 [4:33:20<1:14:43, 13.92s/it] 79%|███████▊  | 1179/1500 [4:33:34<1:14:28, 13.92s/it] 79%|███████▊  | 1180/1500 [4:33:48<1:14:15, 13.92s/it]                                                       {'loss': 0.0068, 'learning_rate': 0.0021333333333333334, 'epoch': 2.8}
 79%|███████▊  | 1180/1500 [4:33:48<1:14:15, 13.92s/it] 79%|███████▊  | 1181/1500 [4:34:02<1:14:01, 13.92s/it] 79%|███████▉  | 1182/1500 [4:34:16<1:13:47, 13.92s/it] 79%|███████▉  | 1183/1500 [4:34:29<1:13:32, 13.92s/it] 79%|███████▉  | 1184/1500 [4:34:43<1:13:19, 13.92s/it] 79%|███████▉  | 1185/1500 [4:34:57<1:13:05, 13.92s/it] 79%|███████▉  | 1186/1500 [4:35:11<1:12:51, 13.92s/it] 79%|███████▉  | 1187/1500 [4:35:25<1:12:38, 13.92s/it] 79%|███████▉  | 1188/1500 [4:35:39<1:12:25, 13.93s/it] 79%|███████▉  | 1189/1500 [4:35:53<1:12:10, 13.92s/it] 79%|███████▉  | 1190/1500 [4:36:07<1:11:55, 13.92s/it]                                                       {'loss': 0.0057, 'learning_rate': 0.0020666666666666667, 'epoch': 2.82}
 79%|███████▉  | 1190/1500 [4:36:07<1:11:55, 13.92s/it] 79%|███████▉  | 1191/1500 [4:36:21<1:11:41, 13.92s/it] 79%|███████▉  | 1192/1500 [4:36:35<1:11:27, 13.92s/it] 80%|███████▉  | 1193/1500 [4:36:49<1:11:13, 13.92s/it] 80%|███████▉  | 1194/1500 [4:37:03<1:10:58, 13.92s/it] 80%|███████▉  | 1195/1500 [4:37:16<1:10:44, 13.92s/it] 80%|███████▉  | 1196/1500 [4:37:30<1:10:31, 13.92s/it] 80%|███████▉  | 1197/1500 [4:37:44<1:10:20, 13.93s/it] 80%|███████▉  | 1198/1500 [4:37:58<1:10:05, 13.93s/it] 80%|███████▉  | 1199/1500 [4:38:12<1:09:52, 13.93s/it] 80%|████████  | 1200/1500 [4:38:26<1:09:37, 13.92s/it]                                                       {'loss': 0.0074, 'learning_rate': 0.002, 'epoch': 2.85}
 80%|████████  | 1200/1500 [4:38:26<1:09:37, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 08:25:39,641 >> Configuration saved in ../../model/classifier/checkpoint-1200/config.json
[INFO|configuration_utils.py:364] 2023-08-27 08:25:39,641 >> Configuration saved in ../../model/classifier/checkpoint-1200/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 08:25:39,646 >> Model weights saved in ../../model/classifier/checkpoint-1200/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 08:25:39,647 >> tokenizer config file saved in ../../model/classifier/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 08:25:39,647 >> Special tokens file saved in ../../model/classifier/checkpoint-1200/special_tokens_map.json
 80%|████████  | 1201/1500 [4:38:40<1:09:24, 13.93s/it] 80%|████████  | 1202/1500 [4:38:54<1:09:10, 13.93s/it] 80%|████████  | 1203/1500 [4:39:08<1:08:56, 13.93s/it] 80%|████████  | 1204/1500 [4:39:22<1:08:42, 13.93s/it] 80%|████████  | 1205/1500 [4:39:36<1:08:27, 13.93s/it] 80%|████████  | 1206/1500 [4:39:50<1:08:13, 13.92s/it] 80%|████████  | 1207/1500 [4:40:04<1:07:59, 13.92s/it] 81%|████████  | 1208/1500 [4:40:18<1:07:44, 13.92s/it] 81%|████████  | 1209/1500 [4:40:31<1:07:30, 13.92s/it] 81%|████████  | 1210/1500 [4:40:45<1:07:16, 13.92s/it]                                                       {'loss': 0.0081, 'learning_rate': 0.0019333333333333333, 'epoch': 2.87}
 81%|████████  | 1210/1500 [4:40:45<1:07:16, 13.92s/it] 81%|████████  | 1211/1500 [4:40:59<1:07:02, 13.92s/it] 81%|████████  | 1212/1500 [4:41:13<1:06:48, 13.92s/it] 81%|████████  | 1213/1500 [4:41:27<1:06:34, 13.92s/it] 81%|████████  | 1214/1500 [4:41:41<1:06:20, 13.92s/it] 81%|████████  | 1215/1500 [4:41:55<1:06:06, 13.92s/it] 81%|████████  | 1216/1500 [4:42:09<1:05:52, 13.92s/it] 81%|████████  | 1217/1500 [4:42:23<1:05:38, 13.92s/it] 81%|████████  | 1218/1500 [4:42:37<1:05:25, 13.92s/it] 81%|████████▏ | 1219/1500 [4:42:51<1:05:11, 13.92s/it] 81%|████████▏ | 1220/1500 [4:43:05<1:04:57, 13.92s/it]                                                       {'loss': 0.0073, 'learning_rate': 0.0018666666666666669, 'epoch': 2.89}
 81%|████████▏ | 1220/1500 [4:43:05<1:04:57, 13.92s/it] 81%|████████▏ | 1221/1500 [4:43:18<1:04:45, 13.93s/it] 81%|████████▏ | 1222/1500 [4:43:32<1:04:32, 13.93s/it] 82%|████████▏ | 1223/1500 [4:43:46<1:04:17, 13.93s/it] 82%|████████▏ | 1224/1500 [4:44:00<1:04:03, 13.92s/it] 82%|████████▏ | 1225/1500 [4:44:14<1:03:48, 13.92s/it] 82%|████████▏ | 1226/1500 [4:44:28<1:03:33, 13.92s/it] 82%|████████▏ | 1227/1500 [4:44:42<1:03:19, 13.92s/it] 82%|████████▏ | 1228/1500 [4:44:56<1:03:06, 13.92s/it] 82%|████████▏ | 1229/1500 [4:45:10<1:02:53, 13.92s/it] 82%|████████▏ | 1230/1500 [4:45:24<1:02:40, 13.93s/it]                                                       {'loss': 0.0073, 'learning_rate': 0.0018, 'epoch': 2.92}
 82%|████████▏ | 1230/1500 [4:45:24<1:02:40, 13.93s/it] 82%|████████▏ | 1231/1500 [4:45:38<1:02:25, 13.92s/it] 82%|████████▏ | 1232/1500 [4:45:52<1:02:10, 13.92s/it] 82%|████████▏ | 1233/1500 [4:46:06<1:01:57, 13.92s/it] 82%|████████▏ | 1234/1500 [4:46:19<1:01:43, 13.92s/it] 82%|████████▏ | 1235/1500 [4:46:33<1:01:28, 13.92s/it] 82%|████████▏ | 1236/1500 [4:46:47<1:01:14, 13.92s/it] 82%|████████▏ | 1237/1500 [4:47:01<1:01:00, 13.92s/it] 83%|████████▎ | 1238/1500 [4:47:15<1:00:47, 13.92s/it] 83%|████████▎ | 1239/1500 [4:47:29<1:00:32, 13.92s/it] 83%|████████▎ | 1240/1500 [4:47:43<1:00:18, 13.92s/it]                                                       {'loss': 0.0073, 'learning_rate': 0.0017333333333333335, 'epoch': 2.94}
 83%|████████▎ | 1240/1500 [4:47:43<1:00:18, 13.92s/it] 83%|████████▎ | 1241/1500 [4:47:57<1:00:04, 13.92s/it] 83%|████████▎ | 1242/1500 [4:48:11<59:51, 13.92s/it]   83%|████████▎ | 1243/1500 [4:48:25<59:37, 13.92s/it] 83%|████████▎ | 1244/1500 [4:48:39<59:23, 13.92s/it] 83%|████████▎ | 1245/1500 [4:48:53<59:09, 13.92s/it] 83%|████████▎ | 1246/1500 [4:49:06<58:55, 13.92s/it] 83%|████████▎ | 1247/1500 [4:49:20<58:41, 13.92s/it] 83%|████████▎ | 1248/1500 [4:49:34<58:27, 13.92s/it] 83%|████████▎ | 1249/1500 [4:49:48<58:13, 13.92s/it] 83%|████████▎ | 1250/1500 [4:50:02<57:59, 13.92s/it]                                                     {'loss': 0.0123, 'learning_rate': 0.0016666666666666666, 'epoch': 2.97}
 83%|████████▎ | 1250/1500 [4:50:02<57:59, 13.92s/it] 83%|████████▎ | 1251/1500 [4:50:16<57:45, 13.92s/it] 83%|████████▎ | 1252/1500 [4:50:30<57:31, 13.92s/it] 84%|████████▎ | 1253/1500 [4:50:44<57:18, 13.92s/it] 84%|████████▎ | 1254/1500 [4:50:58<57:05, 13.93s/it] 84%|████████▎ | 1255/1500 [4:51:12<56:52, 13.93s/it] 84%|████████▎ | 1256/1500 [4:51:26<56:38, 13.93s/it] 84%|████████▍ | 1257/1500 [4:51:40<56:23, 13.92s/it] 84%|████████▍ | 1258/1500 [4:51:54<56:08, 13.92s/it] 84%|████████▍ | 1259/1500 [4:52:07<55:56, 13.93s/it] 84%|████████▍ | 1260/1500 [4:52:21<55:42, 13.93s/it]                                                     {'loss': 0.0077, 'learning_rate': 0.0016, 'epoch': 2.99}
 84%|████████▍ | 1260/1500 [4:52:21<55:42, 13.93s/it] 84%|████████▍ | 1261/1500 [4:52:35<55:27, 13.92s/it] 84%|████████▍ | 1262/1500 [4:52:49<55:13, 13.92s/it] 84%|████████▍ | 1263/1500 [4:53:03<54:59, 13.92s/it] 84%|████████▍ | 1264/1500 [4:53:17<54:46, 13.92s/it] 84%|████████▍ | 1265/1500 [4:53:30<53:37, 13.69s/it] 84%|████████▍ | 1266/1500 [4:53:44<53:39, 13.76s/it] 84%|████████▍ | 1267/1500 [4:53:58<53:36, 13.81s/it] 85%|████████▍ | 1268/1500 [4:54:12<53:30, 13.84s/it] 85%|████████▍ | 1269/1500 [4:54:26<53:21, 13.86s/it] 85%|████████▍ | 1270/1500 [4:54:40<53:11, 13.88s/it]                                                     {'loss': 0.0066, 'learning_rate': 0.0015333333333333332, 'epoch': 3.01}
 85%|████████▍ | 1270/1500 [4:54:40<53:11, 13.88s/it] 85%|████████▍ | 1271/1500 [4:54:54<53:00, 13.89s/it] 85%|████████▍ | 1272/1500 [4:55:08<52:48, 13.90s/it] 85%|████████▍ | 1273/1500 [4:55:22<52:37, 13.91s/it] 85%|████████▍ | 1274/1500 [4:55:36<52:24, 13.91s/it] 85%|████████▌ | 1275/1500 [4:55:49<52:10, 13.91s/it] 85%|████████▌ | 1276/1500 [4:56:03<51:56, 13.91s/it] 85%|████████▌ | 1277/1500 [4:56:17<51:43, 13.91s/it] 85%|████████▌ | 1278/1500 [4:56:31<51:29, 13.92s/it] 85%|████████▌ | 1279/1500 [4:56:45<51:15, 13.92s/it] 85%|████████▌ | 1280/1500 [4:56:59<51:02, 13.92s/it]                                                     {'loss': 0.0067, 'learning_rate': 0.0014666666666666667, 'epoch': 3.04}
 85%|████████▌ | 1280/1500 [4:56:59<51:02, 13.92s/it] 85%|████████▌ | 1281/1500 [4:57:13<50:48, 13.92s/it] 85%|████████▌ | 1282/1500 [4:57:27<50:33, 13.92s/it] 86%|████████▌ | 1283/1500 [4:57:41<50:20, 13.92s/it] 86%|████████▌ | 1284/1500 [4:57:55<50:06, 13.92s/it] 86%|████████▌ | 1285/1500 [4:58:09<49:53, 13.92s/it] 86%|████████▌ | 1286/1500 [4:58:23<49:39, 13.92s/it] 86%|████████▌ | 1287/1500 [4:58:36<49:25, 13.92s/it] 86%|████████▌ | 1288/1500 [4:58:50<49:11, 13.92s/it] 86%|████████▌ | 1289/1500 [4:59:04<48:58, 13.93s/it] 86%|████████▌ | 1290/1500 [4:59:18<48:44, 13.93s/it]                                                     {'loss': 0.0062, 'learning_rate': 0.0014000000000000002, 'epoch': 3.06}
 86%|████████▌ | 1290/1500 [4:59:18<48:44, 13.93s/it] 86%|████████▌ | 1291/1500 [4:59:32<48:30, 13.92s/it] 86%|████████▌ | 1292/1500 [4:59:46<48:16, 13.93s/it] 86%|████████▌ | 1293/1500 [5:00:00<48:02, 13.93s/it] 86%|████████▋ | 1294/1500 [5:00:14<47:48, 13.93s/it] 86%|████████▋ | 1295/1500 [5:00:28<47:35, 13.93s/it] 86%|████████▋ | 1296/1500 [5:00:42<47:21, 13.93s/it] 86%|████████▋ | 1297/1500 [5:00:56<47:06, 13.93s/it] 87%|████████▋ | 1298/1500 [5:01:10<46:52, 13.92s/it] 87%|████████▋ | 1299/1500 [5:01:24<46:38, 13.92s/it] 87%|████████▋ | 1300/1500 [5:01:38<46:24, 13.92s/it]                                                     {'loss': 0.0069, 'learning_rate': 0.0013333333333333333, 'epoch': 3.08}
 87%|████████▋ | 1300/1500 [5:01:38<46:24, 13.92s/it] 87%|████████▋ | 1301/1500 [5:01:51<46:10, 13.92s/it] 87%|████████▋ | 1302/1500 [5:02:05<45:56, 13.92s/it] 87%|████████▋ | 1303/1500 [5:02:19<45:42, 13.92s/it] 87%|████████▋ | 1304/1500 [5:02:33<45:28, 13.92s/it] 87%|████████▋ | 1305/1500 [5:02:47<45:14, 13.92s/it] 87%|████████▋ | 1306/1500 [5:03:01<45:00, 13.92s/it] 87%|████████▋ | 1307/1500 [5:03:15<44:46, 13.92s/it] 87%|████████▋ | 1308/1500 [5:03:29<44:32, 13.92s/it] 87%|████████▋ | 1309/1500 [5:03:43<44:18, 13.92s/it] 87%|████████▋ | 1310/1500 [5:03:57<44:05, 13.92s/it]                                                     {'loss': 0.0073, 'learning_rate': 0.0012666666666666668, 'epoch': 3.11}
 87%|████████▋ | 1310/1500 [5:03:57<44:05, 13.92s/it] 87%|████████▋ | 1311/1500 [5:04:11<43:51, 13.92s/it] 87%|████████▋ | 1312/1500 [5:04:25<43:37, 13.92s/it] 88%|████████▊ | 1313/1500 [5:04:38<43:22, 13.92s/it] 88%|████████▊ | 1314/1500 [5:04:52<43:08, 13.92s/it] 88%|████████▊ | 1315/1500 [5:05:06<42:54, 13.92s/it] 88%|████████▊ | 1316/1500 [5:05:20<42:40, 13.92s/it] 88%|████████▊ | 1317/1500 [5:05:34<42:26, 13.91s/it] 88%|████████▊ | 1318/1500 [5:05:48<42:12, 13.91s/it] 88%|████████▊ | 1319/1500 [5:06:02<41:58, 13.91s/it] 88%|████████▊ | 1320/1500 [5:06:16<41:44, 13.92s/it]                                                     {'loss': 0.0079, 'learning_rate': 0.0012, 'epoch': 3.13}
 88%|████████▊ | 1320/1500 [5:06:16<41:44, 13.92s/it] 88%|████████▊ | 1321/1500 [5:06:30<41:31, 13.92s/it] 88%|████████▊ | 1322/1500 [5:06:44<41:17, 13.92s/it] 88%|████████▊ | 1323/1500 [5:06:58<41:03, 13.92s/it] 88%|████████▊ | 1324/1500 [5:07:12<40:50, 13.92s/it] 88%|████████▊ | 1325/1500 [5:07:26<40:36, 13.93s/it] 88%|████████▊ | 1326/1500 [5:07:39<40:23, 13.93s/it] 88%|████████▊ | 1327/1500 [5:07:53<40:09, 13.93s/it] 89%|████████▊ | 1328/1500 [5:08:07<39:55, 13.93s/it] 89%|████████▊ | 1329/1500 [5:08:21<39:41, 13.93s/it] 89%|████████▊ | 1330/1500 [5:08:35<39:26, 13.92s/it]                                                     {'loss': 0.0074, 'learning_rate': 0.0011333333333333332, 'epoch': 3.16}
 89%|████████▊ | 1330/1500 [5:08:35<39:26, 13.92s/it] 89%|████████▊ | 1331/1500 [5:08:49<39:13, 13.93s/it] 89%|████████▉ | 1332/1500 [5:09:03<38:59, 13.92s/it] 89%|████████▉ | 1333/1500 [5:09:17<38:45, 13.93s/it] 89%|████████▉ | 1334/1500 [5:09:31<38:32, 13.93s/it] 89%|████████▉ | 1335/1500 [5:09:45<38:17, 13.93s/it] 89%|████████▉ | 1336/1500 [5:09:59<38:03, 13.92s/it] 89%|████████▉ | 1337/1500 [5:10:13<37:49, 13.92s/it] 89%|████████▉ | 1338/1500 [5:10:27<37:35, 13.92s/it] 89%|████████▉ | 1339/1500 [5:10:40<37:20, 13.92s/it] 89%|████████▉ | 1340/1500 [5:10:54<37:06, 13.92s/it]                                                     {'loss': 0.0069, 'learning_rate': 0.0010666666666666667, 'epoch': 3.18}
 89%|████████▉ | 1340/1500 [5:10:54<37:06, 13.92s/it] 89%|████████▉ | 1341/1500 [5:11:08<36:52, 13.91s/it] 89%|████████▉ | 1342/1500 [5:11:22<36:38, 13.91s/it] 90%|████████▉ | 1343/1500 [5:11:36<36:24, 13.91s/it] 90%|████████▉ | 1344/1500 [5:11:50<36:10, 13.92s/it] 90%|████████▉ | 1345/1500 [5:12:04<35:57, 13.92s/it] 90%|████████▉ | 1346/1500 [5:12:18<35:43, 13.92s/it] 90%|████████▉ | 1347/1500 [5:12:32<35:29, 13.92s/it] 90%|████████▉ | 1348/1500 [5:12:46<35:16, 13.92s/it] 90%|████████▉ | 1349/1500 [5:13:00<35:01, 13.92s/it] 90%|█████████ | 1350/1500 [5:13:14<34:47, 13.92s/it]                                                     {'loss': 0.0059, 'learning_rate': 0.001, 'epoch': 3.2}
 90%|█████████ | 1350/1500 [5:13:14<34:47, 13.92s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 09:00:27,042 >> Configuration saved in ../../model/classifier/checkpoint-1350/config.json
[INFO|configuration_utils.py:364] 2023-08-27 09:00:27,042 >> Configuration saved in ../../model/classifier/checkpoint-1350/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 09:00:27,047 >> Model weights saved in ../../model/classifier/checkpoint-1350/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 09:00:27,047 >> tokenizer config file saved in ../../model/classifier/checkpoint-1350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 09:00:27,047 >> Special tokens file saved in ../../model/classifier/checkpoint-1350/special_tokens_map.json
 90%|█████████ | 1351/1500 [5:13:27<34:34, 13.92s/it] 90%|█████████ | 1352/1500 [5:13:41<34:20, 13.92s/it] 90%|█████████ | 1353/1500 [5:13:55<34:06, 13.92s/it] 90%|█████████ | 1354/1500 [5:14:09<33:52, 13.92s/it] 90%|█████████ | 1355/1500 [5:14:23<33:38, 13.92s/it] 90%|█████████ | 1356/1500 [5:14:37<33:25, 13.93s/it] 90%|█████████ | 1357/1500 [5:14:51<33:11, 13.93s/it] 91%|█████████ | 1358/1500 [5:15:05<32:56, 13.92s/it] 91%|█████████ | 1359/1500 [5:15:19<32:42, 13.92s/it] 91%|█████████ | 1360/1500 [5:15:33<32:28, 13.92s/it]                                                     {'loss': 0.0055, 'learning_rate': 0.0009333333333333334, 'epoch': 3.23}
 91%|█████████ | 1360/1500 [5:15:33<32:28, 13.92s/it] 91%|█████████ | 1361/1500 [5:15:47<32:14, 13.92s/it] 91%|█████████ | 1362/1500 [5:16:01<32:00, 13.92s/it] 91%|█████████ | 1363/1500 [5:16:14<31:46, 13.92s/it] 91%|█████████ | 1364/1500 [5:16:28<31:32, 13.92s/it] 91%|█████████ | 1365/1500 [5:16:42<31:18, 13.92s/it] 91%|█████████ | 1366/1500 [5:16:56<31:04, 13.92s/it] 91%|█████████ | 1367/1500 [5:17:10<30:50, 13.92s/it] 91%|█████████ | 1368/1500 [5:17:24<30:36, 13.92s/it] 91%|█████████▏| 1369/1500 [5:17:38<30:23, 13.92s/it] 91%|█████████▏| 1370/1500 [5:17:52<30:09, 13.92s/it]                                                     {'loss': 0.0062, 'learning_rate': 0.0008666666666666667, 'epoch': 3.25}
 91%|█████████▏| 1370/1500 [5:17:52<30:09, 13.92s/it] 91%|█████████▏| 1371/1500 [5:18:06<29:55, 13.92s/it] 91%|█████████▏| 1372/1500 [5:18:20<29:41, 13.92s/it] 92%|█████████▏| 1373/1500 [5:18:34<29:27, 13.92s/it] 92%|█████████▏| 1374/1500 [5:18:48<29:13, 13.92s/it] 92%|█████████▏| 1375/1500 [5:19:01<28:59, 13.92s/it] 92%|█████████▏| 1376/1500 [5:19:15<28:45, 13.92s/it] 92%|█████████▏| 1377/1500 [5:19:29<28:31, 13.92s/it] 92%|█████████▏| 1378/1500 [5:19:43<28:17, 13.91s/it] 92%|█████████▏| 1379/1500 [5:19:57<28:04, 13.92s/it] 92%|█████████▏| 1380/1500 [5:20:11<27:50, 13.92s/it]                                                     {'loss': 0.0057, 'learning_rate': 0.0008, 'epoch': 3.27}
 92%|█████████▏| 1380/1500 [5:20:11<27:50, 13.92s/it] 92%|█████████▏| 1381/1500 [5:20:25<27:36, 13.92s/it] 92%|█████████▏| 1382/1500 [5:20:39<27:22, 13.92s/it] 92%|█████████▏| 1383/1500 [5:20:53<27:07, 13.91s/it] 92%|█████████▏| 1384/1500 [5:21:07<26:54, 13.92s/it] 92%|█████████▏| 1385/1500 [5:21:21<26:40, 13.92s/it] 92%|█████████▏| 1386/1500 [5:21:35<26:26, 13.92s/it] 92%|█████████▏| 1387/1500 [5:21:49<26:12, 13.92s/it] 93%|█████████▎| 1388/1500 [5:22:02<25:58, 13.92s/it] 93%|█████████▎| 1389/1500 [5:22:16<25:44, 13.92s/it] 93%|█████████▎| 1390/1500 [5:22:30<25:30, 13.92s/it]                                                     {'loss': 0.0068, 'learning_rate': 0.0007333333333333333, 'epoch': 3.3}
 93%|█████████▎| 1390/1500 [5:22:30<25:30, 13.92s/it] 93%|█████████▎| 1391/1500 [5:22:44<25:16, 13.92s/it] 93%|█████████▎| 1392/1500 [5:22:58<25:03, 13.92s/it] 93%|█████████▎| 1393/1500 [5:23:12<24:49, 13.92s/it] 93%|█████████▎| 1394/1500 [5:23:26<24:35, 13.92s/it] 93%|█████████▎| 1395/1500 [5:23:40<24:21, 13.92s/it] 93%|█████████▎| 1396/1500 [5:23:54<24:07, 13.92s/it] 93%|█████████▎| 1397/1500 [5:24:08<23:53, 13.91s/it] 93%|█████████▎| 1398/1500 [5:24:22<23:39, 13.91s/it] 93%|█████████▎| 1399/1500 [5:24:36<23:25, 13.92s/it] 93%|█████████▎| 1400/1500 [5:24:49<23:11, 13.92s/it]                                                     {'loss': 0.0059, 'learning_rate': 0.0006666666666666666, 'epoch': 3.32}
 93%|█████████▎| 1400/1500 [5:24:49<23:11, 13.92s/it] 93%|█████████▎| 1401/1500 [5:25:03<22:57, 13.92s/it] 93%|█████████▎| 1402/1500 [5:25:17<22:44, 13.92s/it] 94%|█████████▎| 1403/1500 [5:25:31<22:29, 13.92s/it] 94%|█████████▎| 1404/1500 [5:25:45<22:16, 13.92s/it] 94%|█████████▎| 1405/1500 [5:25:59<22:02, 13.92s/it] 94%|█████████▎| 1406/1500 [5:26:13<21:48, 13.92s/it] 94%|█████████▍| 1407/1500 [5:26:27<21:34, 13.92s/it] 94%|█████████▍| 1408/1500 [5:26:41<21:21, 13.93s/it] 94%|█████████▍| 1409/1500 [5:26:55<21:06, 13.92s/it] 94%|█████████▍| 1410/1500 [5:27:09<20:53, 13.92s/it]                                                     {'loss': 0.008, 'learning_rate': 0.0006, 'epoch': 3.35}
 94%|█████████▍| 1410/1500 [5:27:09<20:53, 13.92s/it] 94%|█████████▍| 1411/1500 [5:27:23<20:38, 13.92s/it] 94%|█████████▍| 1412/1500 [5:27:36<20:24, 13.92s/it] 94%|█████████▍| 1413/1500 [5:27:50<20:10, 13.92s/it] 94%|█████████▍| 1414/1500 [5:28:04<19:57, 13.92s/it] 94%|█████████▍| 1415/1500 [5:28:18<19:43, 13.92s/it] 94%|█████████▍| 1416/1500 [5:28:32<19:29, 13.92s/it] 94%|█████████▍| 1417/1500 [5:28:46<19:15, 13.92s/it] 95%|█████████▍| 1418/1500 [5:29:00<19:01, 13.92s/it] 95%|█████████▍| 1419/1500 [5:29:14<18:47, 13.92s/it] 95%|█████████▍| 1420/1500 [5:29:28<18:33, 13.92s/it]                                                     {'loss': 0.0077, 'learning_rate': 0.0005333333333333334, 'epoch': 3.37}
 95%|█████████▍| 1420/1500 [5:29:28<18:33, 13.92s/it] 95%|█████████▍| 1421/1500 [5:29:42<18:19, 13.92s/it] 95%|█████████▍| 1422/1500 [5:29:56<18:05, 13.92s/it] 95%|█████████▍| 1423/1500 [5:30:10<17:51, 13.91s/it] 95%|█████████▍| 1424/1500 [5:30:23<17:37, 13.92s/it] 95%|█████████▌| 1425/1500 [5:30:37<17:23, 13.92s/it] 95%|█████████▌| 1426/1500 [5:30:51<17:09, 13.92s/it] 95%|█████████▌| 1427/1500 [5:31:05<16:55, 13.92s/it] 95%|█████████▌| 1428/1500 [5:31:19<16:41, 13.91s/it] 95%|█████████▌| 1429/1500 [5:31:33<16:28, 13.92s/it] 95%|█████████▌| 1430/1500 [5:31:47<16:14, 13.92s/it]                                                     {'loss': 0.0058, 'learning_rate': 0.0004666666666666667, 'epoch': 3.39}
 95%|█████████▌| 1430/1500 [5:31:47<16:14, 13.92s/it] 95%|█████████▌| 1431/1500 [5:32:01<16:00, 13.92s/it] 95%|█████████▌| 1432/1500 [5:32:15<15:46, 13.92s/it] 96%|█████████▌| 1433/1500 [5:32:29<15:32, 13.92s/it] 96%|█████████▌| 1434/1500 [5:32:43<15:18, 13.92s/it] 96%|█████████▌| 1435/1500 [5:32:57<15:04, 13.92s/it] 96%|█████████▌| 1436/1500 [5:33:11<14:50, 13.92s/it] 96%|█████████▌| 1437/1500 [5:33:24<14:36, 13.92s/it] 96%|█████████▌| 1438/1500 [5:33:38<14:22, 13.92s/it] 96%|█████████▌| 1439/1500 [5:33:52<14:09, 13.92s/it] 96%|█████████▌| 1440/1500 [5:34:06<13:55, 13.92s/it]                                                     {'loss': 0.0087, 'learning_rate': 0.0004, 'epoch': 3.42}
 96%|█████████▌| 1440/1500 [5:34:06<13:55, 13.92s/it] 96%|█████████▌| 1441/1500 [5:34:20<13:41, 13.92s/it] 96%|█████████▌| 1442/1500 [5:34:34<13:27, 13.92s/it] 96%|█████████▌| 1443/1500 [5:34:48<13:13, 13.92s/it] 96%|█████████▋| 1444/1500 [5:35:02<12:59, 13.92s/it] 96%|█████████▋| 1445/1500 [5:35:16<12:45, 13.93s/it] 96%|█████████▋| 1446/1500 [5:35:30<12:31, 13.93s/it] 96%|█████████▋| 1447/1500 [5:35:44<12:17, 13.92s/it] 97%|█████████▋| 1448/1500 [5:35:58<12:04, 13.92s/it] 97%|█████████▋| 1449/1500 [5:36:12<11:50, 13.92s/it] 97%|█████████▋| 1450/1500 [5:36:25<11:35, 13.92s/it]                                                     {'loss': 0.0074, 'learning_rate': 0.0003333333333333333, 'epoch': 3.44}
 97%|█████████▋| 1450/1500 [5:36:25<11:35, 13.92s/it] 97%|█████████▋| 1451/1500 [5:36:39<11:22, 13.92s/it] 97%|█████████▋| 1452/1500 [5:36:53<11:07, 13.92s/it] 97%|█████████▋| 1453/1500 [5:37:07<10:54, 13.92s/it] 97%|█████████▋| 1454/1500 [5:37:21<10:40, 13.92s/it] 97%|█████████▋| 1455/1500 [5:37:35<10:26, 13.92s/it] 97%|█████████▋| 1456/1500 [5:37:49<10:12, 13.92s/it] 97%|█████████▋| 1457/1500 [5:38:03<09:58, 13.92s/it] 97%|█████████▋| 1458/1500 [5:38:17<09:44, 13.92s/it] 97%|█████████▋| 1459/1500 [5:38:31<09:30, 13.92s/it] 97%|█████████▋| 1460/1500 [5:38:45<09:16, 13.92s/it]                                                     {'loss': 0.0081, 'learning_rate': 0.0002666666666666667, 'epoch': 3.46}
 97%|█████████▋| 1460/1500 [5:38:45<09:16, 13.92s/it] 97%|█████████▋| 1461/1500 [5:38:59<09:02, 13.92s/it] 97%|█████████▋| 1462/1500 [5:39:12<08:48, 13.92s/it] 98%|█████████▊| 1463/1500 [5:39:26<08:34, 13.91s/it] 98%|█████████▊| 1464/1500 [5:39:40<08:20, 13.92s/it] 98%|█████████▊| 1465/1500 [5:39:54<08:07, 13.91s/it] 98%|█████████▊| 1466/1500 [5:40:08<07:53, 13.92s/it] 98%|█████████▊| 1467/1500 [5:40:22<07:39, 13.92s/it] 98%|█████████▊| 1468/1500 [5:40:36<07:25, 13.92s/it] 98%|█████████▊| 1469/1500 [5:40:50<07:11, 13.92s/it] 98%|█████████▊| 1470/1500 [5:41:04<06:57, 13.92s/it]                                                     {'loss': 0.0073, 'learning_rate': 0.0002, 'epoch': 3.49}
 98%|█████████▊| 1470/1500 [5:41:04<06:57, 13.92s/it] 98%|█████████▊| 1471/1500 [5:41:18<06:43, 13.92s/it] 98%|█████████▊| 1472/1500 [5:41:32<06:29, 13.92s/it] 98%|█████████▊| 1473/1500 [5:41:46<06:15, 13.92s/it] 98%|█████████▊| 1474/1500 [5:41:59<06:01, 13.92s/it] 98%|█████████▊| 1475/1500 [5:42:13<05:47, 13.92s/it] 98%|█████████▊| 1476/1500 [5:42:27<05:33, 13.91s/it] 98%|█████████▊| 1477/1500 [5:42:41<05:20, 13.92s/it] 99%|█████████▊| 1478/1500 [5:42:55<05:06, 13.92s/it] 99%|█████████▊| 1479/1500 [5:43:09<04:52, 13.92s/it] 99%|█████████▊| 1480/1500 [5:43:23<04:38, 13.92s/it]                                                     {'loss': 0.0065, 'learning_rate': 0.00013333333333333334, 'epoch': 3.51}
 99%|█████████▊| 1480/1500 [5:43:23<04:38, 13.92s/it] 99%|█████████▊| 1481/1500 [5:43:37<04:24, 13.92s/it] 99%|█████████▉| 1482/1500 [5:43:51<04:10, 13.92s/it] 99%|█████████▉| 1483/1500 [5:44:05<03:56, 13.92s/it] 99%|█████████▉| 1484/1500 [5:44:19<03:42, 13.92s/it] 99%|█████████▉| 1485/1500 [5:44:33<03:28, 13.92s/it] 99%|█████████▉| 1486/1500 [5:44:46<03:14, 13.92s/it] 99%|█████████▉| 1487/1500 [5:45:00<03:00, 13.92s/it] 99%|█████████▉| 1488/1500 [5:45:14<02:47, 13.92s/it] 99%|█████████▉| 1489/1500 [5:45:28<02:33, 13.92s/it] 99%|█████████▉| 1490/1500 [5:45:42<02:19, 13.92s/it]                                                     {'loss': 0.0068, 'learning_rate': 6.666666666666667e-05, 'epoch': 3.53}
 99%|█████████▉| 1490/1500 [5:45:42<02:19, 13.92s/it] 99%|█████████▉| 1491/1500 [5:45:56<02:05, 13.92s/it] 99%|█████████▉| 1492/1500 [5:46:10<01:51, 13.92s/it]100%|█████████▉| 1493/1500 [5:46:24<01:37, 13.92s/it]100%|█████████▉| 1494/1500 [5:46:38<01:23, 13.92s/it]100%|█████████▉| 1495/1500 [5:46:52<01:09, 13.92s/it]100%|█████████▉| 1496/1500 [5:47:06<00:55, 13.92s/it]100%|█████████▉| 1497/1500 [5:47:20<00:41, 13.92s/it]100%|█████████▉| 1498/1500 [5:47:34<00:27, 13.92s/it]100%|█████████▉| 1499/1500 [5:47:47<00:13, 13.93s/it]100%|██████████| 1500/1500 [5:48:01<00:00, 13.93s/it]                                                     {'loss': 0.0083, 'learning_rate': 0.0, 'epoch': 3.56}
100%|██████████| 1500/1500 [5:48:01<00:00, 13.93s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:458] 2023-08-27 09:35:14,905 >> Configuration saved in ../../model/classifier/checkpoint-1500/config.json
[INFO|configuration_utils.py:364] 2023-08-27 09:35:14,905 >> Configuration saved in ../../model/classifier/checkpoint-1500/generation_config.json
[INFO|modeling_utils.py:1853] 2023-08-27 09:35:14,910 >> Model weights saved in ../../model/classifier/checkpoint-1500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2194] 2023-08-27 09:35:14,910 >> tokenizer config file saved in ../../model/classifier/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2201] 2023-08-27 09:35:14,910 >> Special tokens file saved in ../../model/classifier/checkpoint-1500/special_tokens_map.json
[INFO|trainer.py:2053] 2023-08-27 09:35:14,922 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 20881.9636, 'train_samples_per_second': 2.299, 'train_steps_per_second': 0.072, 'train_loss': 0.022365952173868817, 'epoch': 3.56}
100%|██████████| 1500/1500 [5:48:01<00:00, 13.93s/it]100%|██████████| 1500/1500 [5:48:01<00:00, 13.92s/it]
***** train metrics *****
  epoch                    =       3.56
  train_loss               =     0.0224
  train_runtime            = 5:48:01.96
  train_samples            =      13486
  train_samples_per_second =      2.299
  train_steps_per_second   =      0.072
